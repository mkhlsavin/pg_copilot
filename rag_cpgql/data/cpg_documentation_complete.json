{
  "methods": [
    {
      "method_name": "brinhandler",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 246,
      "comment": "/*\n * BRIN handler function: return IndexAmRoutine with access method parameters\n * and callbacks.\n */",
      "description": "BRIN handler function: return IndexAmRoutine with access method parameters    and callbacks."
    },
    {
      "method_name": "initialize_brin_insertstate",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 305,
      "comment": "/*\n * Initialize a BrinInsertState to maintain state to be used across multiple\n * tuple inserts, within the same command.\n */",
      "description": "Initialize a BrinInsertState to maintain state to be used across multiple    tuple inserts, within the same command."
    },
    {
      "method_name": "brininsert",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 334,
      "comment": "/*\n * A tuple in the heap is being inserted.  To keep a brin index up to date,\n * we need to obtain the relevant index tuple and compare its stored values\n * with those of the new tuple.  If the tuple values are not consistent with\n * the summary tuple, we need to update the index tuple.\n *\n * If autosummarization is enabled, check if we need to summarize the previous\n * page range.\n *\n * If the range is not currently summarized (i.e. the revmap returns NULL for\n * it), there's nothing to do for this tuple.\n */",
      "description": "A tuple in the heap is being inserted."
    },
    {
      "method_name": "brininsertcleanup",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 502,
      "comment": "/*\n * Callback to clean up the BrinInsertState once all tuple inserts are done.\n */",
      "description": "Callback to clean up the BrinInsertState once all tuple inserts are done."
    },
    {
      "method_name": "brinbeginscan",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 529,
      "comment": "/*\n * Initialize state for a BRIN index scan.\n *\n * We read the metapage here to determine the pages-per-range number that this\n * index was built with.  Note that since this cannot be changed while we're\n * holding lock on index, it's not necessary to recompute it during brinrescan.\n */",
      "description": "Initialize state for a BRIN index scan."
    },
    {
      "method_name": "bringetbitmap",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 557,
      "comment": "/*\n * Execute the index scan.\n *\n * This works by reading index TIDs from the revmap, and obtaining the index\n * tuples pointed to by them; the summary values in the index tuples are\n * compared to the scan keys.  We return into the TID bitmap all the pages in\n * ranges corresponding to index tuples that match the scan keys.\n *\n * If a TID from the revmap is read as InvalidTID, we know that range is\n * unsummarized.  Pages in those ranges need to be returned regardless of scan\n * keys.\n */",
      "description": "Execute the index scan."
    },
    {
      "method_name": "brinrescan",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 947,
      "comment": "/*\n * Re-initialize state for a BRIN index scan\n */",
      "description": "Re-initialize state for a BRIN index scan"
    },
    {
      "method_name": "brinendscan",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 967,
      "comment": "/*\n * Close down a BRIN index scan\n */",
      "description": "Close down a BRIN index scan"
    },
    {
      "method_name": "brinbuildCallback",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 984,
      "comment": "/*\n * Per-heap-tuple callback for table_index_build_scan.\n *\n * Note we don't worry about the page range at the end of the table here; it is\n * present in the build state struct after we're called the last time, but not\n * inserted into the index.  Caller must ensure to do so, if appropriate.\n */",
      "description": "Per-heap-tuple callback for table_index_build_scan."
    },
    {
      "method_name": "brinbuildCallbackParallel",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 1035,
      "comment": "/*\n * Per-heap-tuple callback for table_index_build_scan with parallelism.\n *\n * A version of the callback used by parallel index builds. The main difference\n * is that instead of writing the BRIN tuples into the index, we write them\n * into a shared tuplesort, and leave the insertion up to the leader (which may\n * reorder them a bit etc.). The callback also does not generate empty ranges,\n * those will be added by the leader when merging results from workers.\n */",
      "description": "Per-heap-tuple callback for table_index_build_scan with parallelism."
    },
    {
      "method_name": "brinbuild",
      "file_path": "backend/access/brin/brin.c",
      "line_number": 1094,
      "comment": "/*\n * brinbuild() -- build a new BRIN index.\n */",
      "description": "brinbuild() -- build a new BRIN index."
    },
    {
      "method_name": "brin_minmax_multi_distance_date",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2079,
      "comment": "/*\n * Compute the approximate distance between two dates.\n */",
      "description": "Compute the approximate distance between two dates."
    },
    {
      "method_name": "brin_minmax_multi_distance_time",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2098,
      "comment": "/*\n * Compute the approximate distance between two time (without tz) values.\n *\n * TimeADT is just an int64, so we simply subtract the values directly.\n */",
      "description": "Compute the approximate distance between two time (without tz) values.       TimeADT is just an int64, so we simply subtract the values directly."
    },
    {
      "method_name": "brin_minmax_multi_distance_timetz",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2118,
      "comment": "/*\n * Compute the approximate distance between two timetz values.\n *\n * Simply subtracts the TimeADT (int64) values embedded in TimeTzADT.\n */",
      "description": "Compute the approximate distance between two timetz values.       Simply subtracts the TimeADT (int64) values embedded in TimeTzADT."
    },
    {
      "method_name": "brin_minmax_multi_distance_timestamp",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2136,
      "comment": "/*\n * Compute the distance between two timestamp values.\n */",
      "description": "Compute the distance between two timestamp values."
    },
    {
      "method_name": "brin_minmax_multi_distance_interval",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2154,
      "comment": "/*\n * Compute the distance between two interval values.\n */",
      "description": "Compute the distance between two interval values."
    },
    {
      "method_name": "brin_minmax_multi_distance_pg_lsn",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2190,
      "comment": "/*\n * Compute the distance between two pg_lsn values.\n *\n * LSN is just an int64 encoding position in the stream, so just subtract\n * those int64 values directly.\n */",
      "description": "Compute the distance between two pg_lsn values.       LSN is just an int64 encoding position in the stream, so just subtract    those int64 values directly."
    },
    {
      "method_name": "brin_minmax_multi_distance_macaddr",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2211,
      "comment": "/*\n * Compute the distance between two macaddr values.\n *\n * mac addresses are treated as 6 unsigned chars, so do the same thing we\n * already do for UUID values.\n */",
      "description": "Compute the distance between two macaddr values.       mac addresses are treated as 6 unsigned chars, so do the same thing we    already do for UUID values."
    },
    {
      "method_name": "brin_minmax_multi_distance_macaddr8",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2248,
      "comment": "/*\n * Compute the distance between two macaddr8 values.\n *\n * macaddr8 addresses are 8 unsigned chars, so do the same thing we\n * already do for UUID values.\n */",
      "description": "Compute the distance between two macaddr8 values.       macaddr8 addresses are 8 unsigned chars, so do the same thing we    already do for UUID values."
    },
    {
      "method_name": "brin_minmax_multi_distance_inet",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2296,
      "comment": "/*\n * Compute the distance between two inet values.\n *\n * The distance is defined as the difference between 32-bit/128-bit values,\n * depending on the IP version. The distance is computed by subtracting\n * the bytes and normalizing it to [0,1] range for each IP family.\n * Addresses from different families are considered to be in maximum\n * distance, which is 1.0.\n *\n * XXX Does this need to consider the mask (bits)?  For now, it's ignored.\n */",
      "description": "Compute the distance between two inet values."
    },
    {
      "method_name": "brin_minmax_multi_add_value",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2411,
      "comment": "/*\n * Examine the given index tuple (which contains the partial status of a\n * certain page range) by comparing it to the given value that comes from\n * another heap tuple.  If the new value is outside the min/max range\n * specified by the existing tuple values, update the index tuple and return\n * true.  Otherwise, return false and do not modify in this case.\n */",
      "description": "Examine the given index tuple (which contains the partial status of a    certain page range) by comparing it to the given value that comes from    another heap tuple."
    },
    {
      "method_name": "brin_minmax_multi_consistent",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2548,
      "comment": "/*\n * Given an index tuple corresponding to a certain page range and a scan key,\n * return whether the scan key is consistent with the index tuple's min/max\n * values.  Return true if so, false otherwise.\n */",
      "description": "Given an index tuple corresponding to a certain page range and a scan key,    return whether the scan key is consistent with the index tuple's min/max    values.  Return true if so, false otherwise."
    },
    {
      "method_name": "brin_minmax_multi_union",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2734,
      "comment": "/*\n * Given two BrinValues, update the first of them as a union of the summary\n * values contained in both.  The second one is untouched.\n */",
      "description": "Given two BrinValues, update the first of them as a union of the summary    values contained in both.  The second one is untouched."
    },
    {
      "method_name": "minmax_multi_get_procinfo",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2862,
      "comment": "/*\n * Cache and return minmax multi opclass support procedure\n *\n * Return the procedure corresponding to the given function support number\n * or null if it does not exist.\n */",
      "description": "Cache and return minmax multi opclass support procedure       Return the procedure corresponding to the given function support number    or null if it does not exist."
    },
    {
      "method_name": "minmax_multi_get_strategy_procinfo",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2898,
      "comment": "/*\n * Cache and return the procedure for the given strategy.\n *\n * Note: this function mirrors minmax_multi_get_strategy_procinfo; see notes\n * there.  If changes are made here, see that function too.\n */",
      "description": "Cache and return the procedure for the given strategy.       Note: this function mirrors minmax_multi_get_strategy_procinfo; see notes    there.  If changes are made here, see that function too."
    },
    {
      "method_name": "brin_minmax_multi_summary_in",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2975,
      "comment": "/*\n * brin_minmax_multi_summary_in\n *\t\t- input routine for type brin_minmax_multi_summary.\n *\n * brin_minmax_multi_summary is only used internally to represent summaries\n * in BRIN minmax-multi indexes, so it has no operations of its own, and we\n * disallow input too.\n */",
      "description": "brin_minmax_multi_summary_in   \t\t- input routine for type brin_minmax_multi_summary."
    },
    {
      "method_name": "brin_minmax_multi_summary_out",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 2997,
      "comment": "/*\n * brin_minmax_multi_summary_out\n *\t\t- output routine for type brin_minmax_multi_summary.\n *\n * BRIN minmax-multi summaries are serialized into a bytea value, but we\n * want to output something nicer humans can understand.\n */",
      "description": "brin_minmax_multi_summary_out   \t\t- output routine for type brin_minmax_multi_summary."
    },
    {
      "method_name": "brin_minmax_multi_summary_recv",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 3116,
      "comment": "/*\n * brin_minmax_multi_summary_recv\n *\t\t- binary input routine for type brin_minmax_multi_summary.\n */",
      "description": "brin_minmax_multi_summary_recv   \t\t- binary input routine for type brin_minmax_multi_summary."
    },
    {
      "method_name": "brin_minmax_multi_summary_send",
      "file_path": "backend/access/brin/brin_minmax_multi.c",
      "line_number": 3133,
      "comment": "/*\n * brin_minmax_multi_summary_send\n *\t\t- binary output routine for type brin_minmax_multi_summary.\n *\n * BRIN minmax-multi summaries are serialized in a bytea value (although\n * the type is named differently), so let's just send that.\n */",
      "description": "brin_minmax_multi_summary_send   \t\t- binary output routine for type brin_minmax_multi_summary."
    },
    {
      "method_name": "brin_doupdate",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 52,
      "comment": "/*\n * Update tuple origtup (size origsz), located in offset oldoff of buffer\n * oldbuf, to newtup (size newsz) as summary tuple for the page range starting\n * at heapBlk.  oldbuf must not be locked on entry, and is not locked at exit.\n *\n * If samepage is true, attempt to put the new tuple in the same page, but if\n * there's no room, use some other one.\n *\n * If the update is successful, return true; the revmap is updated to point to\n * the new tuple.  If the update is not done for whatever reason, return false.\n * Caller may retry the update if this happens.\n */",
      "description": "Update tuple origtup (size origsz), located in offset oldoff of buffer    oldbuf, to newtup (size newsz) as summary tuple for the page range starting    at heapBlk."
    },
    {
      "method_name": "brin_can_do_samepage_update",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 322,
      "comment": "/*\n * Return whether brin_doupdate can do a samepage update.\n */",
      "description": "Return whether brin_doupdate can do a samepage update."
    },
    {
      "method_name": "brin_doinsert",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 341,
      "comment": "/*\n * Insert an index tuple into the index relation.  The revmap is updated to\n * mark the range containing the given page as pointing to the inserted entry.\n * A WAL record is written.\n *\n * The buffer, if valid, is first checked for free space to insert the new\n * entry; if there isn't enough, a new buffer is obtained and pinned.  No\n * buffer lock must be held on entry, no buffer lock is held on exit.\n *\n * Return value is the offset number where the tuple was inserted.\n */",
      "description": "Insert an index tuple into the index relation."
    },
    {
      "method_name": "brin_page_init",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 474,
      "comment": "/*\n * Initialize a page with the given type.\n *\n * Caller is responsible for marking it dirty, as appropriate.\n */",
      "description": "Initialize a page with the given type.       Caller is responsible for marking it dirty, as appropriate."
    },
    {
      "method_name": "brin_metapage_init",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 485,
      "comment": "/*\n * Initialize a new BRIN index's metapage.\n */",
      "description": "Initialize a new BRIN index's metapage."
    },
    {
      "method_name": "brin_start_evacuating_page",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 523,
      "comment": "/*\n * Initiate page evacuation protocol.\n *\n * The page must be locked in exclusive mode by the caller.\n *\n * If the page is not yet initialized or empty, return false without doing\n * anything; it can be used for revmap without any further changes.  If it\n * contains tuples, mark it for evacuation and return true.\n */",
      "description": "Initiate page evacuation protocol."
    },
    {
      "method_name": "brin_evacuate_page",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 563,
      "comment": "/*\n * Move all tuples out of a page.\n *\n * The caller must hold lock on the page. The lock and pin are released.\n */",
      "description": "Move all tuples out of a page.       The caller must hold lock on the page. The lock and pin are released."
    },
    {
      "method_name": "brin_page_cleanup",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 623,
      "comment": "/*\n * Given a BRIN index page, initialize it if necessary, and record its\n * current free space in the FSM.\n *\n * The main use for this is when, during vacuuming, an uninitialized page is\n * found, which could be the result of relation extension followed by a crash\n * before the page can be used.\n *\n * Here, we don't bother to update upper FSM pages, instead expecting that our\n * caller (brin_vacuum_scan) will fix them at the end of the scan.  Elsewhere\n * in this file, it's generally a good idea to propagate additions of free\n * space into the upper FSM pages immediately.\n */",
      "description": "Given a BRIN index page, initialize it if necessary, and record its    current free space in the FSM."
    },
    {
      "method_name": "brin_getinsertbuffer",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 689,
      "comment": "/*\n * Return a pinned and exclusively locked buffer which can be used to insert an\n * index item of size itemsz (caller must ensure not to request sizes\n * impossible to fulfill).  If oldbuf is a valid buffer, it is also locked (in\n * an order determined to avoid deadlocks).\n *\n * If we find that the old page is no longer a regular index page (because\n * of a revmap extension), the old buffer is unlocked and we return\n * InvalidBuffer.\n *\n * If there's no existing page with enough free space to accommodate the new\n * item, the relation is extended.  If this happens, *extended is set to true,\n * and it is the caller's responsibility to initialize the page (and WAL-log\n * that fact) prior to use.  The caller should also update the FSM with the\n * page's remaining free space after the insertion.\n *\n * Note that the caller is not expected to update FSM unless *extended is set\n * true.  This policy means that we'll update FSM when a page is created, and\n * when it's found to have too little space for a desired tuple insertion,\n * but not every single time we add a tuple to the page.\n *\n * Note that in some corner cases it is possible for this routine to extend\n * the relation and then not return the new page.  It is this routine's\n * responsibility to WAL-log the page initialization and to record the page in\n * FSM if that happens, since the caller certainly can't do it.\n */",
      "description": "Return a pinned and exclusively locked buffer which can be used to insert an    index item of size itemsz (caller must ensure not to request sizes    impossible to fulfill)."
    },
    {
      "method_name": "brin_initialize_empty_new_buffer",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 883,
      "comment": "/*\n * Initialize a page as an empty regular BRIN page, WAL-log this, and record\n * the page in FSM.\n *\n * There are several corner situations in which we extend the relation to\n * obtain a new page and later find that we cannot use it immediately.  When\n * that happens, we don't want to leave the page go unrecorded in FSM, because\n * there is no mechanism to get the space back and the index would bloat.\n * Also, because we would not WAL-log the action that would initialize the\n * page, the page would go uninitialized in a standby (or after recovery).\n *\n * While we record the page in FSM here, caller is responsible for doing FSM\n * upper-page update if that seems appropriate.\n */",
      "description": "Initialize a page as an empty regular BRIN page, WAL-log this, and record    the page in FSM."
    },
    {
      "method_name": "br_page_get_freespace",
      "file_path": "backend/access/brin/brin_pageops.c",
      "line_number": 915,
      "comment": "/*\n * Return the amount of free space on a regular BRIN index page.\n *\n * If the page is not a regular page, or has been marked with the\n * BRIN_EVACUATE_PAGE flag, returns 0.\n */",
      "description": "Return the amount of free space on a regular BRIN index page.       If the page is not a regular page, or has been marked with the    BRIN_EVACUATE_PAGE flag, returns 0."
    },
    {
      "method_name": "brinRevmapInitialize",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 69,
      "comment": "/*\n * Initialize an access object for a range map.  This must be freed by\n * brinRevmapTerminate when caller is done with it.\n */",
      "description": "Initialize an access object for a range map.  This must be freed by    brinRevmapTerminate when caller is done with it."
    },
    {
      "method_name": "brinRevmapTerminate",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 99,
      "comment": "/*\n * Release resources associated with a revmap access object.\n */",
      "description": "Release resources associated with a revmap access object."
    },
    {
      "method_name": "brinRevmapExtend",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 111,
      "comment": "/*\n * Extend the revmap to cover the given heap block number.\n */",
      "description": "Extend the revmap to cover the given heap block number."
    },
    {
      "method_name": "brinLockRevmapPageForUpdate",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 133,
      "comment": "/*\n * Prepare to insert an entry into the revmap; the revmap buffer in which the\n * entry is to reside is locked and returned.  Most callers should call\n * brinRevmapExtend beforehand, as this routine does not extend the revmap if\n * it's not long enough.\n *\n * The returned buffer is also recorded in the revmap struct; finishing that\n * releases the buffer, therefore the caller needn't do it explicitly.\n */",
      "description": "Prepare to insert an entry into the revmap; the revmap buffer in which the    entry is to reside is locked and returned."
    },
    {
      "method_name": "brinSetHeapBlockItemptr",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 154,
      "comment": "/*\n * In the given revmap buffer (locked appropriately by caller), which is used\n * in a BRIN index of pagesPerRange pages per range, set the element\n * corresponding to heap block number heapBlk to the given TID.\n *\n * Once the operation is complete, the caller must update the LSN on the\n * returned buffer.\n *\n * This is used both in regular operation and during WAL replay.\n */",
      "description": "In the given revmap buffer (locked appropriately by caller), which is used    in a BRIN index of pagesPerRange pages per range, set the element    corresponding to heap block number heapBlk to the given TID."
    },
    {
      "method_name": "brinGetTupleForHeapBlock",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 193,
      "comment": "/*\n * Fetch the BrinTuple for a given heap block.\n *\n * The buffer containing the tuple is locked, and returned in *buf.  The\n * returned tuple points to the shared buffer and must not be freed; if caller\n * wants to use it after releasing the buffer lock, it must create its own\n * palloc'ed copy.  As an optimization, the caller can pass a pinned buffer\n * *buf on entry, which will avoid a pin-unpin cycle when the next tuple is on\n * the same page as a previous one.\n *\n * If no tuple is found for the given heap range, returns NULL. In that case,\n * *buf might still be updated (and pin must be released by caller), but it's\n * not locked.\n *\n * The output tuple offset within the buffer is returned in *off, and its size\n * is returned in *size.\n */",
      "description": "Fetch the BrinTuple for a given heap block."
    },
    {
      "method_name": "brinRevmapDesummarizeRange",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 322,
      "comment": "/*\n * Delete an index tuple, marking a page range as unsummarized.\n *\n * Index must be locked in ShareUpdateExclusiveLock mode.\n *\n * Return false if caller should retry.\n */",
      "description": "Delete an index tuple, marking a page range as unsummarized.       Index must be locked in ShareUpdateExclusiveLock mode.       Return false if caller should retry."
    },
    {
      "method_name": "revmap_get_blkno",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 441,
      "comment": "/*\n * Given a heap block number, find the corresponding physical revmap block\n * number and return it.  If the revmap page hasn't been allocated yet, return\n * InvalidBlockNumber.\n */",
      "description": "Given a heap block number, find the corresponding physical revmap block    number and return it.  If the revmap page hasn't been allocated yet, return    InvalidBlockNumber."
    },
    {
      "method_name": "revmap_get_buffer",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 462,
      "comment": "/*\n * Obtain and return a buffer containing the revmap page for the given heap\n * page.  The revmap must have been previously extended to cover that page.\n * The returned buffer is also recorded in the revmap struct; finishing that\n * releases the buffer, therefore the caller needn't do it explicitly.\n */",
      "description": "Obtain and return a buffer containing the revmap page for the given heap    page."
    },
    {
      "method_name": "revmap_extend_and_get_blkno",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 499,
      "comment": "/*\n * Given a heap block number, find the corresponding physical revmap block\n * number and return it. If the revmap page hasn't been allocated yet, extend\n * the revmap until it is.\n */",
      "description": "Given a heap block number, find the corresponding physical revmap block    number and return it. If the revmap page hasn't been allocated yet, extend    the revmap until it is."
    },
    {
      "method_name": "revmap_physical_extend",
      "file_path": "backend/access/brin/brin_revmap.c",
      "line_number": 521,
      "comment": "/*\n * Try to extend the revmap by one page.  This might not happen for a number of\n * reasons; caller is expected to retry until the expected outcome is obtained.\n */",
      "description": "Try to extend the revmap by one page.  This might not happen for a number of    reasons; caller is expected to retry until the expected outcome is obtained."
    },
    {
      "method_name": "brtuple_disk_tupdesc",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 60,
      "comment": "/*\n * Return a tuple descriptor used for on-disk storage of BRIN tuples.\n */",
      "description": "Return a tuple descriptor used for on-disk storage of BRIN tuples."
    },
    {
      "method_name": "brin_form_tuple",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 98,
      "comment": "/*\n * Generate a new on-disk tuple to be inserted in a BRIN index.\n *\n * See brin_form_placeholder_tuple if you touch this.\n */",
      "description": "Generate a new on-disk tuple to be inserted in a BRIN index.       See brin_form_placeholder_tuple if you touch this."
    },
    {
      "method_name": "brin_form_placeholder_tuple",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 387,
      "comment": "/*\n * Generate a new on-disk tuple with no data values, marked as placeholder.\n *\n * This is a cut-down version of brin_form_tuple.\n */",
      "description": "Generate a new on-disk tuple with no data values, marked as placeholder.       This is a cut-down version of brin_form_tuple."
    },
    {
      "method_name": "brin_free_tuple",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 432,
      "comment": "/*\n * Free a tuple created by brin_form_tuple\n */",
      "description": "Free a tuple created by brin_form_tuple"
    },
    {
      "method_name": "brin_copy_tuple",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 445,
      "comment": "/*\n * Given a brin tuple of size len, create a copy of it.  If 'dest' is not\n * NULL, its size is destsz, and can be used as output buffer; if the tuple\n * to be copied does not fit, it is enlarged by repalloc, and the size is\n * updated to match.  This avoids palloc/free cycles when many brin tuples\n * are being processed in loops.\n */",
      "description": "Given a brin tuple of size len, create a copy of it."
    },
    {
      "method_name": "brin_tuples_equal",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 464,
      "comment": "/*\n * Return whether two BrinTuples are bitwise identical.\n */",
      "description": "Return whether two BrinTuples are bitwise identical."
    },
    {
      "method_name": "brin_new_memtuple",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 481,
      "comment": "/*\n * Create a new BrinMemTuple from scratch, and initialize it to an empty\n * state.\n *\n * Note: we don't provide any means to free a deformed tuple, so make sure to\n * use a temporary memory context.\n */",
      "description": "Create a new BrinMemTuple from scratch, and initialize it to an empty    state.       Note: we don't provide any means to free a deformed tuple, so make sure to    use a temporary memory context."
    },
    {
      "method_name": "brin_memtuple_initialize",
      "file_path": "backend/access/brin/brin_tuple.c",
      "line_number": 510,
      "comment": "/*\n * Reset a BrinMemTuple to initial state.  We return the same tuple, for\n * notational convenience.\n */",
      "description": "Reset a BrinMemTuple to initial state.  We return the same tuple, for    notational convenience."
    },
    {
      "method_name": "heap_copy_minimal_tuple",
      "file_path": "backend/access/common/heaptuple.c",
      "line_number": 1534,
      "comment": "/*\n * heap_copy_minimal_tuple\n *\t\tcopy a MinimalTuple\n *\n * The result is allocated in the current memory context.\n */",
      "description": "heap_copy_minimal_tuple   \t\tcopy a MinimalTuple       The result is allocated in the current memory context."
    },
    {
      "method_name": "heap_tuple_from_minimal_tuple",
      "file_path": "backend/access/common/heaptuple.c",
      "line_number": 1553,
      "comment": "/*\n * heap_tuple_from_minimal_tuple\n *\t\tcreate a HeapTuple by copying from a MinimalTuple;\n *\t\tsystem columns are filled with zeroes\n *\n * The result is allocated in the current memory context.\n * The HeapTuple struct, tuple header, and tuple data are all allocated\n * as a single palloc() block.\n */",
      "description": "heap_tuple_from_minimal_tuple   \t\tcreate a HeapTuple by copying from a MinimalTuple;   \t\tsystem columns are filled with zeroes       The result is allocated in the current memory context."
    },
    {
      "method_name": "minimal_tuple_from_heap_tuple",
      "file_path": "backend/access/common/heaptuple.c",
      "line_number": 1575,
      "comment": "/*\n * minimal_tuple_from_heap_tuple\n *\t\tcreate a MinimalTuple by copying from a HeapTuple\n *\n * The result is allocated in the current memory context.\n */",
      "description": "minimal_tuple_from_heap_tuple   \t\tcreate a MinimalTuple by copying from a HeapTuple       The result is allocated in the current memory context."
    },
    {
      "method_name": "varsize_any",
      "file_path": "backend/access/common/heaptuple.c",
      "line_number": 1593,
      "comment": "/*\n * This mainly exists so JIT can inline the definition, but it's also\n * sometimes useful in debugging sessions.\n */",
      "description": "This mainly exists so JIT can inline the definition, but it's also    sometimes useful in debugging sessions."
    },
    {
      "method_name": "index_form_tuple",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 43,
      "comment": "/* ----------------\n  *\t\tindex_form_tuple\n  *\n  *\t\tAs index_form_tuple_context, but allocates the returned tuple in the\n  *\t\tCurrentMemoryContext.\n  * ----------------\n  */",
      "description": "----------------    \t\tindex_form_tuple        \t\tAs index_form_tuple_context, but allocates the returned tuple in the    \t\tCurrentMemoryContext.     ----------------"
    },
    {
      "method_name": "index_form_tuple_context",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 64,
      "comment": "/* ----------------\n *\t\tindex_form_tuple_context\n *\n *\t\tThis shouldn't leak any memory; otherwise, callers such as\n *\t\ttuplesort_putindextuplevalues() will be very unhappy.\n *\n *\t\tThis shouldn't perform external table access provided caller\n *\t\tdoes not pass values that are stored EXTERNAL.\n *\n *\t\tAllocates returned tuple in provided 'context'.\n * ----------------\n */",
      "description": "----------------   \t\tindex_form_tuple_context      \t\tThis shouldn't leak any memory; otherwise, callers such as   \t\ttuplesort_putindextuplevalues() will be very unhappy."
    },
    {
      "method_name": "nocache_index_getattr",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 240,
      "comment": "/* ----------------\n *\t\tnocache_index_getattr\n *\n *\t\tThis gets called from index_getattr() macro, and only in cases\n *\t\twhere we can't use cacheoffset and the value is not null.\n *\n *\t\tThis caches attribute offsets in the attribute descriptor.\n *\n *\t\tAn alternative way to speed things up would be to cache offsets\n *\t\twith the tuple, but that seems more difficult unless you take\n *\t\tthe storage hit of actually putting those offsets into the\n *\t\ttuple you send to disk.  Yuck.\n *\n *\t\tThis scheme will be slightly slower than that, but should\n *\t\tperform well for queries which hit large #'s of tuples.  After\n *\t\tyou cache the offsets once, examining all the other tuples using\n *\t\tthe same attribute descriptor will go much quicker. -cim 5/4/91\n * ----------------\n */",
      "description": "----------------   \t\tnocache_index_getattr      \t\tThis gets called from index_getattr() macro, and only in cases   \t\twhere we can't use cacheoffset and the value is not null."
    },
    {
      "method_name": "index_deform_tuple",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 455,
      "comment": "/*\n * Convert an index tuple into Datum/isnull arrays.\n *\n * The caller must allocate sufficient storage for the output arrays.\n * (INDEX_MAX_KEYS entries should be enough.)\n *\n * This is nearly the same as heap_deform_tuple(), but for IndexTuples.\n * One difference is that the tuple should never have any missing columns.\n */",
      "description": "Convert an index tuple into Datum/isnull arrays."
    },
    {
      "method_name": "index_deform_tuple_internal",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 478,
      "comment": "/*\n * Convert an index tuple into Datum/isnull arrays,\n * without assuming any specific layout of the index tuple header.\n *\n * Caller must supply pointer to data area, pointer to nulls bitmap\n * (which can be NULL if !hasnulls), and hasnulls flag.\n */",
      "description": "Convert an index tuple into Datum/isnull arrays,    without assuming any specific layout of the index tuple header."
    },
    {
      "method_name": "CopyIndexTuple",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 546,
      "comment": "/*\n * Create a palloc'd copy of an index tuple.\n */",
      "description": "Create a palloc'd copy of an index tuple."
    },
    {
      "method_name": "index_truncate_tuple",
      "file_path": "backend/access/common/indextuple.c",
      "line_number": 575,
      "comment": "/*\n * Create a palloc'd copy of an index tuple, leaving only the first\n * leavenatts attributes remaining.\n *\n * Truncation is guaranteed to result in an index tuple that is no\n * larger than the original.  It is safe to use the IndexTuple with\n * the original tuple descriptor, but caller must avoid actually\n * accessing truncated attributes from returned tuple!  In practice\n * this means that index_getattr() must be called with special care,\n * and that the truncated tuple should only ever be accessed by code\n * under caller's direct control.\n *\n * It's safe to call this function with a buffer lock held, since it\n * never performs external table access.  If it ever became possible\n * for index tuples to contain EXTERNAL TOAST values, then this would\n * have to be revisited.\n */",
      "description": "Create a palloc'd copy of an index tuple, leaving only the first    leavenatts attributes remaining."
    },
    {
      "method_name": "printsimple_startup",
      "file_path": "backend/access/common/printsimple.c",
      "line_number": 30,
      "comment": "/*\n * At startup time, send a RowDescription message.\n */",
      "description": "At startup time, send a RowDescription message."
    },
    {
      "method_name": "printsimple",
      "file_path": "backend/access/common/printsimple.c",
      "line_number": 58,
      "comment": "/*\n * For each tuple, send a DataRow message.\n */",
      "description": "For each tuple, send a DataRow message."
    },
    {
      "method_name": "printtup_create_DR",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 70,
      "comment": "/* ----------------\n *\t\tInitialize: create a DestReceiver for printtup\n * ----------------\n */",
      "description": "----------------   \t\tInitialize: create a DestReceiver for printtup    ----------------"
    },
    {
      "method_name": "SetRemoteDestReceiverParams",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 99,
      "comment": "/*\n * Set parameters for a DestRemote (or DestRemoteExecute) receiver\n */",
      "description": "Set parameters for a DestRemote (or DestRemoteExecute) receiver"
    },
    {
      "method_name": "printtup_startup",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 110,
      "comment": "/*\n * Set parameters for a DestRemote (or DestRemoteExecute) receiver\n */",
      "description": "Set parameters for a DestRemote (or DestRemoteExecute) receiver"
    },
    {
      "method_name": "SendRowDescriptionMessage",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 165,
      "comment": "/*\n * SendRowDescriptionMessage --- send a RowDescription message to the frontend\n *\n * Notes: the TupleDesc has typically been manufactured by ExecTypeFromTL()\n * or some similar function; it does not contain a full set of fields.\n * The targetlist will be NIL when executing a utility function that does\n * not have a plan.  If the targetlist isn't NIL then it is a Query node's\n * targetlist; it is up to us to ignore resjunk columns in it.  The formats[]\n * array pointer might be NULL (if we are doing Describe on a prepared stmt);\n * send zeroes for the format codes in that case.\n */",
      "description": "SendRowDescriptionMessage --- send a RowDescription message to the frontend       Notes: the TupleDesc has typically been manufactured by ExecTypeFromTL()    or some similar function; it does not contain a full set of fields."
    },
    {
      "method_name": "printtup_prepare_info",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 249,
      "comment": "/*\n * Get the lookup info that printtup() needs\n */",
      "description": "Get the lookup info that printtup() needs"
    },
    {
      "method_name": "printtup",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 303,
      "comment": "/* ----------------\n *\t\tprinttup --- send a tuple to the client\n *\n * Note: if you change this function, see also serializeAnalyzeReceive\n * in explain.c, which is meant to replicate the computations done here.\n * ----------------\n */",
      "description": "----------------   \t\tprinttup --- send a tuple to the client       Note: if you change this function, see also serializeAnalyzeReceive    in explain.c, which is meant to replicate the computations done here."
    },
    {
      "method_name": "printtup_shutdown",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 388,
      "comment": "/* ----------------\n *\t\tprinttup_shutdown\n * ----------------\n */",
      "description": "----------------   \t\tprinttup_shutdown    ----------------"
    },
    {
      "method_name": "printtup_destroy",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 412,
      "comment": "/* ----------------\n *\t\tprinttup_destroy\n * ----------------\n */",
      "description": "----------------   \t\tprinttup_destroy    ----------------"
    },
    {
      "method_name": "printatt",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 422,
      "comment": "/* ----------------\n *\t\tprintatt\n * ----------------\n */",
      "description": "----------------   \t\tprintatt    ----------------"
    },
    {
      "method_name": "debugStartup",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 443,
      "comment": "/* ----------------\n *\t\tdebugStartup - prepare to print tuples for an interactive backend\n * ----------------\n */",
      "description": "----------------   \t\tdebugStartup - prepare to print tuples for an interactive backend    ----------------"
    },
    {
      "method_name": "debugtup",
      "file_path": "backend/access/common/printtup.c",
      "line_number": 461,
      "comment": "/* ----------------\n *\t\tdebugtup - print one tuple for an interactive backend\n * ----------------\n */",
      "description": "----------------   \t\tdebugtup - print one tuple for an interactive backend    ----------------"
    },
    {
      "method_name": "tidstore_iter_extract_tids",
      "file_path": "backend/access/common/tidstore.c",
      "line_number": 579,
      "comment": "/* Extract TIDs from the given key-value pair */",
      "description": "Extract TIDs from the given key-value pair"
    },
    {
      "method_name": "pglz_compress_datum",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 39,
      "comment": "/*\n * Compress a varlena using PGLZ.\n *\n * Returns the compressed varlena, or NULL if compression fails.\n */",
      "description": "Compress a varlena using PGLZ.       Returns the compressed varlena, or NULL if compression fails."
    },
    {
      "method_name": "pglz_decompress_datum",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 81,
      "comment": "/*\n * Decompress a varlena that was compressed using PGLZ.\n */",
      "description": "Decompress a varlena that was compressed using PGLZ."
    },
    {
      "method_name": "pglz_decompress_datum_slice",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 108,
      "comment": "/*\n * Decompress part of a varlena that was compressed using PGLZ.\n */",
      "description": "Decompress part of a varlena that was compressed using PGLZ."
    },
    {
      "method_name": "lz4_compress_datum",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 138,
      "comment": "/*\n * Compress a varlena using LZ4.\n *\n * Returns the compressed varlena, or NULL if compression fails.\n */",
      "description": "Compress a varlena using LZ4.       Returns the compressed varlena, or NULL if compression fails."
    },
    {
      "method_name": "lz4_decompress_datum",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 181,
      "comment": "/*\n * Decompress a varlena that was compressed using LZ4.\n */",
      "description": "Decompress a varlena that was compressed using LZ4."
    },
    {
      "method_name": "lz4_decompress_datum_slice",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 214,
      "comment": "/*\n * Decompress part of a varlena that was compressed using LZ4.\n */",
      "description": "Decompress part of a varlena that was compressed using LZ4."
    },
    {
      "method_name": "toast_get_compression_id",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 253,
      "comment": "/*\n * Extract compression ID from a varlena.\n *\n * Returns TOAST_INVALID_COMPRESSION_ID if the varlena is not compressed.\n */",
      "description": "Extract compression ID from a varlena.       Returns TOAST_INVALID_COMPRESSION_ID if the varlena is not compressed."
    },
    {
      "method_name": "CompressionNameToMethod",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 284,
      "comment": "/*\n * CompressionNameToMethod - Get compression method from compression name\n *\n * Search in the available built-in methods.  If the compression not found\n * in the built-in methods then return InvalidCompressionMethod.\n */",
      "description": "CompressionNameToMethod - Get compression method from compression name       Search in the available built-in methods."
    },
    {
      "method_name": "GetCompressionMethodName",
      "file_path": "backend/access/common/toast_compression.c",
      "line_number": 303,
      "comment": "/*\n * GetCompressionMethodName - Get compression method name\n */",
      "description": "GetCompressionMethodName - Get compression method name"
    },
    {
      "method_name": "toast_compress_datum",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 45,
      "comment": "/* ----------\n * toast_compress_datum -\n *\n *\tCreate a compressed version of a varlena datum\n *\n *\tIf we fail (ie, compressed result is actually bigger than original)\n *\tthen return NULL.  We must not use compressed data if it'd expand\n *\tthe tuple!\n *\n *\tWe use VAR{SIZE,DATA}_ANY so we can handle short varlenas here without\n *\tcopying them.  But we can't handle external or compressed datums.\n * ----------\n */",
      "description": "----------    toast_compress_datum -      \tCreate a compressed version of a varlena datum      \tIf we fail (ie, compressed result is actually bigger than original)   \tthen return NULL."
    },
    {
      "method_name": "toast_save_datum",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 118,
      "comment": "/* ----------\n * toast_save_datum -\n *\n *\tSave one single datum into the secondary relation and return\n *\ta Datum reference for it.\n *\n * rel: the main relation we're working with (not the toast rel!)\n * value: datum to be pushed to toast storage\n * oldexternal: if not NULL, toast pointer previously representing the datum\n * options: options to be passed to heap_insert() for toast rows\n * ----------\n */",
      "description": "----------    toast_save_datum -      \tSave one single datum into the secondary relation and return   \ta Datum reference for it."
    },
    {
      "method_name": "toast_delete_datum",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 384,
      "comment": "/* ----------\n * toast_delete_datum -\n *\n *\tDelete a single external stored value.\n * ----------\n */",
      "description": "----------    toast_delete_datum -      \tDelete a single external stored value.    ----------"
    },
    {
      "method_name": "toastrel_valueid_exists",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 460,
      "comment": "/* ----------\n * toastrel_valueid_exists -\n *\n *\tTest whether a toast value with the given ID exists in the toast relation.\n *\tFor safety, we consider a value to exist if there are either live or dead\n *\ttoast rows with that ID; see notes for GetNewOidWithIndex().\n * ----------\n */",
      "description": "----------    toastrel_valueid_exists -      \tTest whether a toast value with the given ID exists in the toast relation."
    },
    {
      "method_name": "toastid_valueid_exists",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 508,
      "comment": "/* ----------\n * toastid_valueid_exists -\n *\n *\tAs above, but work from toast rel's OID not an open relation\n * ----------\n */",
      "description": "----------    toastid_valueid_exists -      \tAs above, but work from toast rel's OID not an open relation    ----------"
    },
    {
      "method_name": "toast_get_valid_index",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 529,
      "comment": "/* ----------\n * toast_get_valid_index\n *\n *\tGet OID of valid index associated to given toast relation. A toast\n *\trelation can have only one valid index at the same time.\n */",
      "description": "----------    toast_get_valid_index      \tGet OID of valid index associated to given toast relation. A toast   \trelation can have only one valid index at the same time."
    },
    {
      "method_name": "toast_open_indexes",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 563,
      "comment": "/* ----------\n * toast_open_indexes\n *\n *\tGet an array of the indexes associated to the given toast relation\n *\tand return as well the position of the valid index used by the toast\n *\trelation in this array. It is the responsibility of the caller of this\n *\tfunction to close the indexes as well as free them.\n */",
      "description": "----------    toast_open_indexes      \tGet an array of the indexes associated to the given toast relation   \tand return as well the position of the valid index used by the toast   \trelation in this array."
    },
    {
      "method_name": "toast_close_indexes",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 622,
      "comment": "/* ----------\n * toast_close_indexes\n *\n *\tClose an array of indexes for a toast relation and free it. This should\n *\tbe called for a set of indexes opened previously with toast_open_indexes.\n */",
      "description": "----------    toast_close_indexes      \tClose an array of indexes for a toast relation and free it. This should   \tbe called for a set of indexes opened previously with toast_open_indexes."
    },
    {
      "method_name": "init_toast_snapshot",
      "file_path": "backend/access/common/toast_internals.c",
      "line_number": 640,
      "comment": "/* ----------\n * init_toast_snapshot\n *\n *\tInitialize an appropriate TOAST snapshot.  We must use an MVCC snapshot\n *\tto initialize the TOAST snapshot; since we don't know which one to use,\n *\tjust use the oldest one.\n */",
      "description": "----------    init_toast_snapshot      \tInitialize an appropriate TOAST snapshot."
    },
    {
      "method_name": "convert_tuples_by_position",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 58,
      "comment": "/*\n * Set up for tuple conversion, matching input and output columns by\n * position.  (Dropped columns are ignored in both input and output.)\n */",
      "description": "Set up for tuple conversion, matching input and output columns by    position.  (Dropped columns are ignored in both input and output.)"
    },
    {
      "method_name": "convert_tuples_by_name",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 101,
      "comment": "/*\n * Set up for tuple conversion, matching input and output columns by name.\n * (Dropped columns are ignored in both input and output.)\tThis is intended\n * for use when the rowtypes are related by inheritance, so we expect an exact\n * match of both type and typmod.  The error messages will be a bit unhelpful\n * unless both rowtypes are named composite types.\n */",
      "description": "Set up for tuple conversion, matching input and output columns by name."
    },
    {
      "method_name": "convert_tuples_by_name_attrmap",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 123,
      "comment": "/*\n * Set up tuple conversion for input and output TupleDescs using the given\n * AttrMap.\n */",
      "description": "Set up tuple conversion for input and output TupleDescs using the given    AttrMap."
    },
    {
      "method_name": "execute_attr_map_tuple",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 153,
      "comment": "/*\n * Perform conversion of a tuple according to the map.\n */",
      "description": "Perform conversion of a tuple according to the map."
    },
    {
      "method_name": "execute_attr_map_slot",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 191,
      "comment": "/*\n * Perform conversion of a tuple slot according to the map.\n */",
      "description": "Perform conversion of a tuple slot according to the map."
    },
    {
      "method_name": "execute_attr_map_cols",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 251,
      "comment": "/*\n * Perform conversion of bitmap of columns according to the map.\n *\n * The input and output bitmaps are offset by\n * FirstLowInvalidHeapAttributeNumber to accommodate system cols, like the\n * column-bitmaps in RangeTblEntry.\n */",
      "description": "Perform conversion of bitmap of columns according to the map."
    },
    {
      "method_name": "free_conversion_map",
      "file_path": "backend/access/common/tupconvert.c",
      "line_number": 298,
      "comment": "/*\n * Free a TupleConversionMap structure.\n */",
      "description": "Free a TupleConversionMap structure."
    },
    {
      "method_name": "ResourceOwnerRememberTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 47,
      "comment": "/* Convenience wrappers over ResourceOwnerRemember/Forget */",
      "description": "Convenience wrappers over ResourceOwnerRemember/Forget"
    },
    {
      "method_name": "ResourceOwnerForgetTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 53,
      "comment": "/* Convenience wrappers over ResourceOwnerRemember/Forget */",
      "description": "Convenience wrappers over ResourceOwnerRemember/Forget"
    },
    {
      "method_name": "CreateTemplateTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 66,
      "comment": "/*\n * CreateTemplateTupleDesc\n *\t\tThis function allocates an empty tuple descriptor structure.\n *\n * Tuple type ID information is initially set for an anonymous record type;\n * caller can overwrite this if needed.\n */",
      "description": "CreateTemplateTupleDesc   \t\tThis function allocates an empty tuple descriptor structure."
    },
    {
      "method_name": "CreateTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 111,
      "comment": "/*\n * CreateTupleDesc\n *\t\tThis function allocates a new TupleDesc by copying a given\n *\t\tForm_pg_attribute array.\n *\n * Tuple type ID information is initially set for an anonymous record type;\n * caller can overwrite this if needed.\n */",
      "description": "CreateTupleDesc   \t\tThis function allocates a new TupleDesc by copying a given   \t\tForm_pg_attribute array."
    },
    {
      "method_name": "CreateTupleDescCopy",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 132,
      "comment": "/*\n * CreateTupleDescCopy\n *\t\tThis function creates a new TupleDesc by copying from an existing\n *\t\tTupleDesc.\n *\n * !!! Constraints and defaults are not copied !!!\n */",
      "description": "CreateTupleDescCopy   \t\tThis function creates a new TupleDesc by copying from an existing   \t\tTupleDesc.       !!! Constraints and defaults are not copied !!!"
    },
    {
      "method_name": "CreateTupleDescCopyConstr",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 172,
      "comment": "/*\n * CreateTupleDescCopyConstr\n *\t\tThis function creates a new TupleDesc by copying from an existing\n *\t\tTupleDesc (including its constraints and defaults).\n */",
      "description": "CreateTupleDescCopyConstr   \t\tThis function creates a new TupleDesc by copying from an existing   \t\tTupleDesc (including its constraints and defaults)."
    },
    {
      "method_name": "TupleDescCopy",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 250,
      "comment": "/*\n * TupleDescCopy\n *\t\tCopy a tuple descriptor into caller-supplied memory.\n *\t\tThe memory may be shared memory mapped at any address, and must\n *\t\tbe sufficient to hold TupleDescSize(src) bytes.\n *\n * !!! Constraints and defaults are not copied !!!\n */",
      "description": "TupleDescCopy   \t\tCopy a tuple descriptor into caller-supplied memory."
    },
    {
      "method_name": "TupleDescCopyEntry",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 288,
      "comment": "/*\n * TupleDescCopyEntry\n *\t\tThis function copies a single attribute structure from one tuple\n *\t\tdescriptor to another.\n *\n * !!! Constraints and defaults are not copied !!!\n */",
      "description": "TupleDescCopyEntry   \t\tThis function copies a single attribute structure from one tuple   \t\tdescriptor to another.       !!! Constraints and defaults are not copied !!!"
    },
    {
      "method_name": "FreeTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 330,
      "comment": "/*\n * Free a TupleDesc including all substructure\n */",
      "description": "Free a TupleDesc including all substructure"
    },
    {
      "method_name": "IncrTupleDescRefCount",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 387,
      "comment": "/*\n * Increment the reference count of a tupdesc, and log the reference in\n * CurrentResourceOwner.\n *\n * Do not apply this to tupdescs that are not being refcounted.  (Use the\n * macro PinTupleDesc for tupdescs of uncertain status.)\n */",
      "description": "Increment the reference count of a tupdesc, and log the reference in    CurrentResourceOwner."
    },
    {
      "method_name": "DecrTupleDescRefCount",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 405,
      "comment": "/*\n * Decrement the reference count of a tupdesc, remove the corresponding\n * reference from CurrentResourceOwner, and free the tupdesc if no more\n * references remain.\n *\n * Do not apply this to tupdescs that are not being refcounted.  (Use the\n * macro ReleaseTupleDesc for tupdescs of uncertain status.)\n */",
      "description": "Decrement the reference count of a tupdesc, remove the corresponding    reference from CurrentResourceOwner, and free the tupdesc if no more    references remain."
    },
    {
      "method_name": "equalTupleDescs",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 418,
      "comment": "/*\n * Compare two TupleDesc structures for logical equality\n */",
      "description": "Compare two TupleDesc structures for logical equality"
    },
    {
      "method_name": "equalRowTypes",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 585,
      "comment": "/*\n * equalRowTypes\n *\n * This determines whether two tuple descriptors have equal row types.  This\n * only checks those fields in pg_attribute that are applicable for row types,\n * while ignoring those fields that define the physical row storage or those\n * that define table column metadata.\n *\n * Specifically, this checks:\n *\n * - same number of attributes\n * - same composite type ID (but could both be zero)\n * - corresponding attributes (in order) have same the name, type, typmod,\n *   collation\n *\n * This is used to check whether two record types are compatible, whether\n * function return row types are the same, and other similar situations.\n *\n * (XXX There was some discussion whether attndims should be checked here, but\n * for now it has been decided not to.)\n *\n * Note: We deliberately do not check the tdtypmod field.  This allows\n * typcache.c to use this routine to see if a cached record type matches a\n * requested type.\n */",
      "description": "equalRowTypes       This determines whether two tuple descriptors have equal row types."
    },
    {
      "method_name": "hashRowType",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 621,
      "comment": "/*\n * hashRowType\n *\n * If two tuple descriptors would be considered equal by equalRowTypes()\n * then their hash value will be equal according to this function.\n */",
      "description": "hashRowType       If two tuple descriptors would be considered equal by equalRowTypes()    then their hash value will be equal according to this function."
    },
    {
      "method_name": "TupleDescInitEntry",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 650,
      "comment": "/*\n * TupleDescInitEntry\n *\t\tThis function initializes a single attribute structure in\n *\t\ta previously allocated tuple descriptor.\n *\n * If attributeName is NULL, the attname field is set to an empty string\n * (this is for cases where we don't know or need a name for the field).\n * Also, some callers use this function to change the datatype-related fields\n * in an existing tupdesc; they pass attributeName = NameStr(att->attname)\n * to indicate that the attname field shouldn't be modified.\n *\n * Note that attcollation is set to the default for the specified datatype.\n * If a nondefault collation is needed, insert it afterwards using\n * TupleDescInitEntryCollation.\n */",
      "description": "TupleDescInitEntry   \t\tThis function initializes a single attribute structure in   \t\ta previously allocated tuple descriptor."
    },
    {
      "method_name": "TupleDescInitBuiltinEntry",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 725,
      "comment": "/*\n * TupleDescInitBuiltinEntry\n *\t\tInitialize a tuple descriptor without catalog access.  Only\n *\t\ta limited range of builtin types are supported.\n */",
      "description": "TupleDescInitBuiltinEntry   \t\tInitialize a tuple descriptor without catalog access.  Only   \t\ta limited range of builtin types are supported."
    },
    {
      "method_name": "TupleDescInitEntryCollation",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 832,
      "comment": "/*\n * TupleDescInitEntryCollation\n *\n * Assign a nondefault collation to a previously initialized tuple descriptor\n * entry.\n */",
      "description": "TupleDescInitEntryCollation       Assign a nondefault collation to a previously initialized tuple descriptor    entry."
    },
    {
      "method_name": "BuildDescFromLists",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 857,
      "comment": "/*\n * BuildDescFromLists\n *\n * Build a TupleDesc given lists of column names (as String nodes),\n * column type OIDs, typmods, and collation OIDs.\n *\n * No constraints are generated.\n *\n * This is for use with functions returning RECORD.\n */",
      "description": "BuildDescFromLists       Build a TupleDesc given lists of column names (as String nodes),    column type OIDs, typmods, and collation OIDs."
    },
    {
      "method_name": "TupleDescGetDefault",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 898,
      "comment": "/*\n * Get default expression (or NULL if none) for the given attribute number.\n */",
      "description": "Get default expression (or NULL if none) for the given attribute number."
    },
    {
      "method_name": "ResOwnerReleaseTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 922,
      "comment": "/* ResourceOwner callbacks */",
      "description": "ResourceOwner callbacks"
    },
    {
      "method_name": "ResOwnerPrintTupleDesc",
      "file_path": "backend/access/common/tupdesc.c",
      "line_number": 933,
      "comment": "/* ResourceOwner callbacks */",
      "description": "ResourceOwner callbacks"
    },
    {
      "method_name": "ginarrayextract",
      "file_path": "backend/access/gin/ginarrayproc.c",
      "line_number": 32,
      "comment": "/*\n * extractValue support function\n */",
      "description": "extractValue support function"
    },
    {
      "method_name": "ginarrayextract_2args",
      "file_path": "backend/access/gin/ginarrayproc.c",
      "line_number": 67,
      "comment": "/*\n * Formerly, ginarrayextract had only two arguments.  Now it has three,\n * but we still need a pg_proc entry with two args to support reloading\n * pre-9.1 contrib/intarray opclass declarations.  This compatibility\n * function should go away eventually.\n */",
      "description": "Formerly, ginarrayextract had only two arguments."
    },
    {
      "method_name": "ginqueryarrayextract",
      "file_path": "backend/access/gin/ginarrayproc.c",
      "line_number": 78,
      "comment": "/*\n * extractQuery support function\n */",
      "description": "extractQuery support function"
    },
    {
      "method_name": "ginarrayconsistent",
      "file_path": "backend/access/gin/ginarrayproc.c",
      "line_number": 141,
      "comment": "/*\n * consistent support function\n */",
      "description": "consistent support function"
    },
    {
      "method_name": "ginarraytriconsistent",
      "file_path": "backend/access/gin/ginarrayproc.c",
      "line_number": 225,
      "comment": "/*\n * triconsistent support function\n */",
      "description": "triconsistent support function"
    },
    {
      "method_name": "ginTraverseLock",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 38,
      "comment": "/*\n * Lock buffer by needed method for search.\n */",
      "description": "Lock buffer by needed method for search."
    },
    {
      "method_name": "ginFindLeafPage",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 82,
      "comment": "/*\n * Descend the tree to the leaf page that contains or would contain the key\n * we're searching for. The key should already be filled in 'btree', in\n * tree-type specific manner. If btree->fullScan is true, descends to the\n * leftmost leaf page.\n *\n * If 'searchmode' is false, on return stack->buffer is exclusively locked,\n * and the stack represents the full path to the root. Otherwise stack->buffer\n * is share-locked, and stack->parent is NULL.\n *\n * If 'rootConflictCheck' is true, tree root is checked for serialization\n * conflict.\n */",
      "description": "Descend the tree to the leaf page that contains or would contain the key    we're searching for."
    },
    {
      "method_name": "ginStepRight",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 176,
      "comment": "/*\n * Step right from current page.\n *\n * The next page is locked first, before releasing the current page. This is\n * crucial to prevent concurrent VACUUM from deleting a page that we are about\n * to step to. (The lock-coupling isn't strictly necessary when we are\n * traversing the tree to find an insert location, because page deletion grabs\n * a cleanup lock on the root to prevent any concurrent inserts. See Page\n * deletion section in the README. But there's no harm in doing it always.)\n */",
      "description": "Step right from current page."
    },
    {
      "method_name": "freeGinBtreeStack",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 197,
      "comment": "/*\n * Step right from current page.\n *\n * The next page is locked first, before releasing the current page. This is\n * crucial to prevent concurrent VACUUM from deleting a page that we are about\n * to step to. (The lock-coupling isn't strictly necessary when we are\n * traversing the tree to find an insert location, because page deletion grabs\n * a cleanup lock on the root to prevent any concurrent inserts. See Page\n * deletion section in the README. But there's no harm in doing it always.)\n */",
      "description": "Step right from current page."
    },
    {
      "method_name": "ginFindParents",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 217,
      "comment": "/*\n * Try to find parent for current stack position. Returns correct parent and\n * child's offset in stack->parent. The root page is never released, to\n * prevent conflict with vacuum process.\n */",
      "description": "Try to find parent for current stack position. Returns correct parent and    child's offset in stack->parent. The root page is never released, to    prevent conflict with vacuum process."
    },
    {
      "method_name": "ginPlaceToPage",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 336,
      "comment": "/*\n * Insert a new item to a page.\n *\n * Returns true if the insertion was finished. On false, the page was split and\n * the parent needs to be updated. (A root split returns true as it doesn't\n * need any further action by the caller to complete.)\n *\n * When inserting a downlink to an internal page, 'childbuf' contains the\n * child page that was split. Its GIN_INCOMPLETE_SPLIT flag will be cleared\n * atomically with the insert. Also, the existing item at offset stack->off\n * in the target page is updated to point to updateblkno.\n *\n * stack->buffer is locked on entry, and is kept locked.\n * Likewise for childbuf, if given.\n */",
      "description": "Insert a new item to a page."
    },
    {
      "method_name": "ginFinishSplit",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 671,
      "comment": "/*\n * Finish a split by inserting the downlink for the new page to parent.\n *\n * On entry, stack->buffer is exclusively locked.\n *\n * If freestack is true, all the buffers are released and unlocked as we\n * crawl up the tree, and 'stack' is freed. Otherwise stack->buffer is kept\n * locked, and stack is unmodified, except for possibly moving right to find\n * the correct parent of page.\n */",
      "description": "Finish a split by inserting the downlink for the new page to parent."
    },
    {
      "method_name": "ginFinishOldSplit",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 778,
      "comment": "/*\n * An entry point to ginFinishSplit() that is used when we stumble upon an\n * existing incompletely split page in the tree, as opposed to completing a\n * split that we just made ourselves. The difference is that stack->buffer may\n * be merely share-locked on entry, and will be upgraded to exclusive mode.\n *\n * Note: Upgrading the lock momentarily releases it. Doing that in a scan\n * would not be OK, because a concurrent VACUUM might delete the page while\n * we're not holding the lock. It's OK in an insert, though, because VACUUM\n * has a different mechanism that prevents it from running concurrently with\n * inserts. (Namely, it holds a cleanup lock on the root.)\n */",
      "description": "An entry point to ginFinishSplit() that is used when we stumble upon an    existing incompletely split page in the tree, as opposed to completing a    split that we just made ourselves."
    },
    {
      "method_name": "ginInsertValue",
      "file_path": "backend/access/gin/ginbtree.c",
      "line_number": 815,
      "comment": "/*\n * Insert a value to tree described by stack.\n *\n * The value to be inserted is given in 'insertdata'. Its format depends\n * on whether this is an entry or data tree, ginInsertValue just passes it\n * through to the tree-specific callback function.\n *\n * During an index build, buildStats is non-null and the counters it contains\n * are incremented as needed.\n *\n * NB: the passed-in stack is freed, as though by freeGinBtreeStack.\n */",
      "description": "Insert a value to tree described by stack."
    },
    {
      "method_name": "ginCombineData",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 29,
      "comment": "/* Combiner function for rbtree.c */",
      "description": "Combiner function for rbtree.c"
    },
    {
      "method_name": "cmpEntryAccumulator",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 71,
      "comment": "/* Comparator function for rbtree.c */",
      "description": "Comparator function for rbtree.c"
    },
    {
      "method_name": "ginAllocEntryAccumulator",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 84,
      "comment": "/* Allocator function for rbtree.c */",
      "description": "Allocator function for rbtree.c"
    },
    {
      "method_name": "ginInitBA",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 108,
      "comment": "/* accum->ginstate is intentionally not set here */",
      "description": "accum->ginstate is intentionally not set here"
    },
    {
      "method_name": "getDatumCopy",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 127,
      "comment": "/*\n * This is basically the same as datumCopy(), but extended to count\n * palloc'd space in accum->allocatedMemory.\n */",
      "description": "This is basically the same as datumCopy(), but extended to count    palloc'd space in accum->allocatedMemory."
    },
    {
      "method_name": "ginInsertBAEntry",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 147,
      "comment": "/*\n * Find/store one entry from indexed value.\n */",
      "description": "Find/store one entry from indexed value."
    },
    {
      "method_name": "ginInsertBAEntries",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 209,
      "comment": "/*\n * Insert the entries for one heap pointer.\n *\n * Since the entries are being inserted into a balanced binary tree, you\n * might think that the order of insertion wouldn't be critical, but it turns\n * out that inserting the entries in sorted order results in a lot of\n * rebalancing operations and is slow.  To prevent this, we attempt to insert\n * the nodes in an order that will produce a nearly-balanced tree if the input\n * is in fact sorted.\n *\n * We do this as follows.  First, we imagine that we have an array whose size\n * is the smallest power of two greater than or equal to the actual array\n * size.  Second, we insert the middle entry of our virtual array into the\n * tree; then, we insert the middles of each half of our virtual array, then\n * middles of quarters, etc.\n */",
      "description": "Insert the entries for one heap pointer."
    },
    {
      "method_name": "ginBeginBAScan",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 256,
      "comment": "/* Prepare to read out the rbtree contents using ginGetBAEntry */",
      "description": "Prepare to read out the rbtree contents using ginGetBAEntry"
    },
    {
      "method_name": "ginGetBAEntry",
      "file_path": "backend/access/gin/ginbulk.c",
      "line_number": 267,
      "comment": "/*\n * Get the next entry in sequence from the BuildAccumulator's rbtree.\n * This consists of a single key datum and a list (array) of one or more\n * heap TIDs in which that key is found.  The list is guaranteed sorted.\n */",
      "description": "Get the next entry in sequence from the BuildAccumulator's rbtree."
    },
    {
      "method_name": "GinDataLeafPageGetItems",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 134,
      "comment": "/*\n * Read TIDs from leaf data page to single uncompressed array. The TIDs are\n * returned in ascending order.\n *\n * advancePast is a hint, indicating that the caller is only interested in\n * TIDs > advancePast. To return all items, use ItemPointerSetMin.\n *\n * Note: This function can still return items smaller than advancePast that\n * are in the same posting list as the items of interest, so the caller must\n * still check all the returned items. But passing it allows this function to\n * skip whole posting lists.\n */",
      "description": "Read TIDs from leaf data page to single uncompressed array."
    },
    {
      "method_name": "GinDataLeafPageGetItemsToTbm",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 181,
      "comment": "/*\n * Places all TIDs from leaf data page to bitmap.\n */",
      "description": "Places all TIDs from leaf data page to bitmap."
    },
    {
      "method_name": "dataLeafPageGetUncompressed",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 210,
      "comment": "/*\n * Get pointer to the uncompressed array of items on a pre-9.4 format\n * uncompressed leaf page. The number of items in the array is returned in\n * *nitems.\n */",
      "description": "Get pointer to the uncompressed array of items on a pre-9.4 format    uncompressed leaf page. The number of items in the array is returned in     nitems."
    },
    {
      "method_name": "dataIsMoveRight",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 233,
      "comment": "/*\n * Check if we should follow the right link to find the item we're searching\n * for.\n *\n * Compares inserting item pointer with the right bound of the current page.\n */",
      "description": "Check if we should follow the right link to find the item we're searching    for.       Compares inserting item pointer with the right bound of the current page."
    },
    {
      "method_name": "dataLocateItem",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 251,
      "comment": "/*\n * Find correct PostingItem in non-leaf page. It is assumed that this is\n * the correct page, and the searched value SHOULD be on the page.\n */",
      "description": "Find correct PostingItem in non-leaf page. It is assumed that this is    the correct page, and the searched value SHOULD be on the page."
    },
    {
      "method_name": "dataFindChildPtr",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 318,
      "comment": "/*\n * Find link to blkno on non-leaf page, returns offset of PostingItem\n */",
      "description": "Find link to blkno on non-leaf page, returns offset of PostingItem"
    },
    {
      "method_name": "dataGetLeftMostPage",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 363,
      "comment": "/*\n * Return blkno of leftmost child\n */",
      "description": "Return blkno of leftmost child"
    },
    {
      "method_name": "GinDataPageAddPostingItem",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 379,
      "comment": "/*\n * Add PostingItem to a non-leaf page.\n */",
      "description": "Add PostingItem to a non-leaf page."
    },
    {
      "method_name": "GinPageDeletePostingItem",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 416,
      "comment": "/*\n * Delete posting item from non-leaf page\n */",
      "description": "Delete posting item from non-leaf page"
    },
    {
      "method_name": "dataBeginPlaceToPageLeaf",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 447,
      "comment": "/*\n * Prepare to insert data on a leaf data page.\n *\n * If it will fit, return GPTP_INSERT after doing whatever setup is needed\n * before we enter the insertion critical section.  *ptp_workspace can be\n * set to pass information along to the execPlaceToPage function.\n *\n * If it won't fit, perform a page split and return two temporary page\n * images into *newlpage and *newrpage, with result GPTP_SPLIT.\n *\n * In neither case should the given page buffer be modified here.\n */",
      "description": "Prepare to insert data on a leaf data page."
    },
    {
      "method_name": "dataExecPlaceToPageLeaf",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 715,
      "comment": "/*\n * Perform data insertion after beginPlaceToPage has decided it will fit.\n *\n * This is invoked within a critical section, and XLOG record creation (if\n * needed) is already started.  The target buffer is registered in slot 0.\n */",
      "description": "Perform data insertion after beginPlaceToPage has decided it will fit."
    },
    {
      "method_name": "ginVacuumPostingTreeLeaf",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 737,
      "comment": "/*\n * Vacuum a posting tree leaf page.\n */",
      "description": "Vacuum a posting tree leaf page."
    },
    {
      "method_name": "computeLeafRecompressWALData",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 871,
      "comment": "/*\n * Construct a ginxlogRecompressDataLeaf record representing the changes\n * in *leaf.  (Because this requires a palloc, we have to do it before\n * we enter the critical section that actually updates the page.)\n */",
      "description": "Construct a ginxlogRecompressDataLeaf record representing the changes    in  leaf."
    },
    {
      "method_name": "dataPlaceToPageLeafRecompress",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 977,
      "comment": "/*\n * Assemble a disassembled posting tree leaf page back to a buffer.\n *\n * This just updates the target buffer; WAL stuff is caller's responsibility.\n *\n * NOTE: The segment pointers must not point directly to the same buffer,\n * except for segments that have not been modified and whose preceding\n * segments have not been modified either.\n */",
      "description": "Assemble a disassembled posting tree leaf page back to a buffer."
    },
    {
      "method_name": "dataPlaceToPageLeafSplit",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1033,
      "comment": "/*\n * Like dataPlaceToPageLeafRecompress, but writes the disassembled leaf\n * segments to two pages instead of one.\n *\n * This is different from the non-split cases in that this does not modify\n * the original page directly, but writes to temporary in-memory copies of\n * the new left and right pages.\n */",
      "description": "Like dataPlaceToPageLeafRecompress, but writes the disassembled leaf    segments to two pages instead of one."
    },
    {
      "method_name": "dataBeginPlaceToPageInternal",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1118,
      "comment": "/*\n * Prepare to insert data on an internal data page.\n *\n * If it will fit, return GPTP_INSERT after doing whatever setup is needed\n * before we enter the insertion critical section.  *ptp_workspace can be\n * set to pass information along to the execPlaceToPage function.\n *\n * If it won't fit, perform a page split and return two temporary page\n * images into *newlpage and *newrpage, with result GPTP_SPLIT.\n *\n * In neither case should the given page buffer be modified here.\n *\n * Note: on insertion to an internal node, in addition to inserting the given\n * item, the downlink of the existing item at stack->off will be updated to\n * point to updateblkno.\n */",
      "description": "Prepare to insert data on an internal data page."
    },
    {
      "method_name": "dataExecPlaceToPageInternal",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1144,
      "comment": "/*\n * Perform data insertion after beginPlaceToPage has decided it will fit.\n *\n * This is invoked within a critical section, and XLOG record creation (if\n * needed) is already started.  The target buffer is registered in slot 0.\n */",
      "description": "Perform data insertion after beginPlaceToPage has decided it will fit."
    },
    {
      "method_name": "dataBeginPlaceToPage",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1200,
      "comment": "/*\n * Prepare to insert data on a posting-tree data page.\n *\n * If it will fit, return GPTP_INSERT after doing whatever setup is needed\n * before we enter the insertion critical section.  *ptp_workspace can be\n * set to pass information along to the execPlaceToPage function.\n *\n * If it won't fit, perform a page split and return two temporary page\n * images into *newlpage and *newrpage, with result GPTP_SPLIT.\n *\n * In neither case should the given page buffer be modified here.\n *\n * Note: on insertion to an internal node, in addition to inserting the given\n * item, the downlink of the existing item at stack->off will be updated to\n * point to updateblkno.\n *\n * Calls relevant function for internal or leaf page because they are handled\n * very differently.\n */",
      "description": "Prepare to insert data on a posting-tree data page."
    },
    {
      "method_name": "dataExecPlaceToPage",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1230,
      "comment": "/*\n * Perform data insertion after beginPlaceToPage has decided it will fit.\n *\n * This is invoked within a critical section, and XLOG record creation (if\n * needed) is already started.  The target buffer is registered in slot 0.\n *\n * Calls relevant function for internal or leaf page because they are handled\n * very differently.\n */",
      "description": "Perform data insertion after beginPlaceToPage has decided it will fit."
    },
    {
      "method_name": "dataSplitPageInternal",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1251,
      "comment": "/*\n * Split internal page and insert new data.\n *\n * Returns new temp pages to *newlpage and *newrpage.\n * The original buffer is left untouched.\n */",
      "description": "Split internal page and insert new data.       Returns new temp pages to  newlpage and  newrpage.    The original buffer is left untouched."
    },
    {
      "method_name": "dataPrepareDownlink",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1332,
      "comment": "/*\n * Construct insertion payload for inserting the downlink for given buffer.\n */",
      "description": "Construct insertion payload for inserting the downlink for given buffer."
    },
    {
      "method_name": "ginDataFillRoot",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1348,
      "comment": "/*\n * Fills new root by right bound values from child.\n * Also called from ginxlog, should not use btree\n */",
      "description": "Fills new root by right bound values from child.    Also called from ginxlog, should not use btree"
    },
    {
      "method_name": "disassembleLeaf",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1369,
      "comment": "/*\n * Disassemble page into a disassembledLeaf struct.\n */",
      "description": "Disassemble page into a disassembledLeaf struct."
    },
    {
      "method_name": "addItemsToLeaf",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1443,
      "comment": "/*\n * Distribute newItems to the segments.\n *\n * Any segments that acquire new items are decoded, and the new items are\n * merged with the old items.\n *\n * Returns true if any new items were added. False means they were all\n * duplicates of existing items on the page.\n */",
      "description": "Distribute newItems to the segments."
    },
    {
      "method_name": "leafRepackItems",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1570,
      "comment": "/*\n * Recompresses all segments that have been modified.\n *\n * If not all the items fit on two pages (ie. after split), we store as\n * many items as fit, and set *remaining to the first item that didn't fit.\n * If all items fit, *remaining is set to invalid.\n *\n * Returns true if the page has to be split.\n */",
      "description": "Recompresses all segments that have been modified."
    },
    {
      "method_name": "createPostingTree",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1774,
      "comment": "/*\n * Creates new posting tree containing the given TIDs. Returns the page\n * number of the root of the new posting tree.\n *\n * items[] must be in sorted order with no duplicates.\n */",
      "description": "Creates new posting tree containing the given TIDs. Returns the page    number of the root of the new posting tree.       items[] must be in sorted order with no duplicates."
    },
    {
      "method_name": "ginInsertItemPointers",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1907,
      "comment": "/*\n * Inserts array of item pointers, may execute several tree scan (very rare)\n */",
      "description": "Inserts array of item pointers, may execute several tree scan (very rare)"
    },
    {
      "method_name": "ginScanBeginPostingTree",
      "file_path": "backend/access/gin/gindatapage.c",
      "line_number": 1935,
      "comment": "/*\n * Starts a new scan on a posting tree.\n */",
      "description": "Starts a new scan on a posting tree."
    },
    {
      "method_name": "GinFormTuple",
      "file_path": "backend/access/gin/ginentrypage.c",
      "line_number": 43,
      "comment": "/*\n * Form a tuple for entry tree.\n *\n * If the tuple would be too big to be stored, function throws a suitable\n * error if errorTooBig is true, or returns NULL if errorTooBig is false.\n *\n * See src/backend/access/gin/README for a description of the index tuple\n * format that is being built here.  We build on the assumption that we\n * are making a leaf-level key entry containing a posting list of nipd items.\n * If the caller is actually trying to make a posting-tree entry, non-leaf\n * entry, or pending-list entry, it should pass dataSize = 0 and then overwrite\n * the t_tid fields as necessary.  In any case, 'data' can be NULL to skip\n * filling in the posting list; the caller is responsible for filling it\n * afterwards if data = NULL and nipd > 0.\n */",
      "description": "Form a tuple for entry tree."
    },
    {
      "method_name": "ginReadTuple",
      "file_path": "backend/access/gin/ginentrypage.c",
      "line_number": 161,
      "comment": "/*\n * Read item pointers from leaf entry tuple.\n *\n * Returns a palloc'd array of ItemPointers. The number of items is returned\n * in *nitems.\n */",
      "description": "Read item pointers from leaf entry tuple.       Returns a palloc'd array of ItemPointers. The number of items is returned    in  nitems."
    },
    {
      "method_name": "GinFormInteriorTuple",
      "file_path": "backend/access/gin/ginentrypage.c",
      "line_number": 200,
      "comment": "/*\n * Form a non-leaf entry tuple by copying the key data from the given tuple,\n * which can be either a leaf or non-leaf entry tuple.\n *\n * Any posting list in the source tuple is not copied.  The specified child\n * block number is inserted into t_tid.\n */",
      "description": "Form a non-leaf entry tuple by copying the key data from the given tuple,    which can be either a leaf or non-leaf entry tuple."
    },
    {
      "method_name": "gistfixsplit",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1194,
      "comment": "/*\n * Complete the incomplete split of state->stack->page.\n */",
      "description": "Complete the incomplete split of state->stack->page."
    },
    {
      "method_name": "gistinserttuple",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1254,
      "comment": "/*\n * Insert or replace a tuple in stack->buffer. If 'oldoffnum' is valid, the\n * tuple at 'oldoffnum' is replaced, otherwise the tuple is inserted as new.\n * 'stack' represents the path from the root to the page being updated.\n *\n * The caller must hold an exclusive lock on stack->buffer.  The lock is still\n * held on return, but the page might not contain the inserted tuple if the\n * page was split. The function returns true if the page was split, false\n * otherwise.\n */",
      "description": "Insert or replace a tuple in stack->buffer."
    },
    {
      "method_name": "gistinserttuples",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1288,
      "comment": "/* ----------------\n * An extended workhorse version of gistinserttuple(). This version allows\n * inserting multiple tuples, or replacing a single tuple with multiple tuples.\n * This is used to recursively update the downlinks in the parent when a page\n * is split.\n *\n * If leftchild and rightchild are valid, we're inserting/replacing the\n * downlink for rightchild, and leftchild is its left sibling. We clear the\n * F_FOLLOW_RIGHT flag and update NSN on leftchild, atomically with the\n * insertion of the downlink.\n *\n * To avoid holding locks for longer than necessary, when recursing up the\n * tree to update the parents, the locking is a bit peculiar here. On entry,\n * the caller must hold an exclusive lock on stack->buffer, as well as\n * leftchild and rightchild if given. On return:\n *\n *\t- Lock on stack->buffer is released, if 'unlockbuf' is true. The page is\n *\t  always kept pinned, however.\n *\t- Lock on 'leftchild' is released, if 'unlockleftchild' is true. The page\n *\t  is kept pinned.\n *\t- Lock and pin on 'rightchild' are always released.\n *\n * Returns 'true' if the page had to be split. Note that if the page was\n * split, the inserted/updated tuples might've been inserted to a right\n * sibling of stack->buffer instead of stack->buffer itself.\n */",
      "description": "----------------    An extended workhorse version of gistinserttuple()."
    },
    {
      "method_name": "gistfinishsplit",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1348,
      "comment": "/*\n * Finish an incomplete split by inserting/updating the downlinks in parent\n * page. 'splitinfo' contains all the child pages involved in the split,\n * from left-to-right.\n *\n * On entry, the caller must hold a lock on stack->buffer and all the child\n * pages in 'splitinfo'. If 'unlockbuf' is true, the lock on stack->buffer is\n * released on return. The child pages are always unlocked and unpinned.\n */",
      "description": "Finish an incomplete split by inserting/updating the downlinks in parent    page."
    },
    {
      "method_name": "gistSplit",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1444,
      "comment": "/*\n * gistSplit -- split a page in the tree and fill struct\n * used for XLOG and real writes buffers. Function is recursive, ie\n * it will split page until keys will fit in every page.\n */",
      "description": "gistSplit -- split a page in the tree and fill struct    used for XLOG and real writes buffers. Function is recursive, ie    it will split page until keys will fit in every page."
    },
    {
      "method_name": "initGISTstate",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1531,
      "comment": "/*\n * Create a GISTSTATE and fill it with information about the index\n */",
      "description": "Create a GISTSTATE and fill it with information about the index"
    },
    {
      "method_name": "freeGISTstate",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1659,
      "comment": "/* It's sufficient to delete the scanCxt */",
      "description": "It's sufficient to delete the scanCxt"
    },
    {
      "method_name": "gistprunepage",
      "file_path": "backend/access/gist/gist.c",
      "line_number": 1670,
      "comment": "/*\n * gistprunepage() -- try to remove LP_DEAD items from the given page.\n * Function assumes that buffer is exclusively locked.\n */",
      "description": "gistprunepage() -- try to remove LP_DEAD items from the given page.    Function assumes that buffer is exclusively locked."
    },
    {
      "method_name": "<clinit>",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 123,
      "comment": "/*\n * In sorted build, we use a stack of these structs, one for each level,\n * to hold an in-memory buffer of last pages at the level.\n *\n * Sorting GiST build requires good linearization of the sort opclass. This is\n * not always the case in multidimensional data. To tackle the anomalies, we\n * buffer index tuples and apply picksplit that can be multidimension-aware.\n */",
      "description": "In sorted build, we use a stack of these structs, one for each level,    to hold an in-memory buffer of last pages at the level."
    },
    {
      "method_name": "gistbuild",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 178,
      "comment": "/*\n * Main entry point to GiST index build.\n */",
      "description": "Main entry point to GiST index build."
    },
    {
      "method_name": "gistSortedBuildCallback",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 365,
      "comment": "/*\n * Per-tuple callback for table_index_build_scan.\n */",
      "description": "Per-tuple callback for table_index_build_scan."
    },
    {
      "method_name": "gist_indexsortbuild",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 399,
      "comment": "/*\n * Build GiST index from bottom up from pre-sorted tuples.\n */",
      "description": "Build GiST index from bottom up from pre-sorted tuples."
    },
    {
      "method_name": "gist_indexsortbuild_levelstate_add",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 460,
      "comment": "/*\n * Add tuple to a page. If the pages are full, write them out and re-initialize\n * a new page first.\n */",
      "description": "Add tuple to a page. If the pages are full, write them out and re-initialize    a new page first."
    },
    {
      "method_name": "gistInitBuffering",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 625,
      "comment": "/*\n * Attempt to switch to buffering mode.\n *\n * If there is not enough memory for buffering build, sets bufferingMode\n * to GIST_BUFFERING_DISABLED, so that we don't bother to try the switch\n * anymore. Otherwise initializes the build buffers, and sets bufferingMode to\n * GIST_BUFFERING_ACTIVE.\n */",
      "description": "Attempt to switch to buffering mode."
    },
    {
      "method_name": "calculatePagesPerBuffer",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 786,
      "comment": "/*\n * Calculate pagesPerBuffer parameter for the buffering algorithm.\n *\n * Buffer size is chosen so that assuming that tuples are distributed\n * randomly, emptying half a buffer fills on average one page in every buffer\n * at the next lower level.\n */",
      "description": "Calculate pagesPerBuffer parameter for the buffering algorithm."
    },
    {
      "method_name": "gistBuildCallback",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 819,
      "comment": "/*\n * Per-tuple callback for table_index_build_scan.\n */",
      "description": "Per-tuple callback for table_index_build_scan."
    },
    {
      "method_name": "gistBufferingBuildInsert",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 906,
      "comment": "/*\n * Insert function for buffering index build.\n */",
      "description": "Insert function for buffering index build."
    },
    {
      "method_name": "gistProcessItup",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 922,
      "comment": "/*\n * Process an index tuple. Runs the tuple down the tree until we reach a leaf\n * page or node buffer, and inserts the tuple there. Returns true if we have\n * to stop buffer emptying process (because one of child buffers can't take\n * index tuples anymore).\n */",
      "description": "Process an index tuple."
    },
    {
      "method_name": "gistbufferinginserttuples",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1053,
      "comment": "/*\n * Insert tuples to a given page.\n *\n * This is analogous with gistinserttuples() in the regular insertion code.\n *\n * Returns the block number of the page where the (first) new or updated tuple\n * was inserted. Usually that's the original page, but might be a sibling page\n * if the original page was split.\n *\n * Caller should hold a lock on 'buffer' on entry. This function will unlock\n * and unpin it.\n */",
      "description": "Insert tuples to a given page."
    },
    {
      "method_name": "gistBufferingFindCorrectParent",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1222,
      "comment": "/*\n * Find the downlink pointing to a child page.\n *\n * 'childblkno' indicates the child page to find the parent for. 'level' is\n * the level of the child. On entry, *parentblkno and *downlinkoffnum can\n * point to a location where the downlink used to be - we will check that\n * location first, and save some cycles if it hasn't moved. The function\n * returns a buffer containing the downlink, exclusively-locked, and\n * *parentblkno and *downlinkoffnum are set to the real location of the\n * downlink.\n *\n * If the child page is a leaf (level == 0), the caller must supply a correct\n * parentblkno. Otherwise we use the parent map hash table to find the parent\n * block.\n *\n * This function serves the same purpose as gistFindCorrectParent() during\n * normal index inserts, but this is simpler because we don't need to deal\n * with concurrent inserts.\n */",
      "description": "Find the downlink pointing to a child page."
    },
    {
      "method_name": "gistProcessEmptyingQueue",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1296,
      "comment": "/*\n * Process buffers emptying stack. Emptying of one buffer can cause emptying\n * of other buffers. This function iterates until this cascading emptying\n * process finished, e.g. until buffers emptying stack is empty.\n */",
      "description": "Process buffers emptying stack."
    },
    {
      "method_name": "gistEmptyAllBuffers",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1369,
      "comment": "/*\n * Empty all node buffers, from top to bottom. This is done at the end of\n * index build to flush all remaining tuples to the index.\n *\n * Note: This destroys the buffersOnLevels lists, so the buffers should not\n * be inserted to after this call.\n */",
      "description": "Empty all node buffers, from top to bottom."
    },
    {
      "method_name": "gistGetMaxLevel",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1424,
      "comment": "/*\n * Get the depth of the GiST index.\n */",
      "description": "Get the depth of the GiST index."
    },
    {
      "method_name": "gistMemorizeAllDownlinks",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1543,
      "comment": "/*\n * Scan all downlinks on a page, and memorize their parent.\n */",
      "description": "Scan all downlinks on a page, and memorize their parent."
    },
    {
      "method_name": "gistGetParent",
      "file_path": "backend/access/gist/gistbuild.c",
      "line_number": 1564,
      "comment": "/*\n * Scan all downlinks on a page, and memorize their parent.\n */",
      "description": "Scan all downlinks on a page, and memorize their parent."
    },
    {
      "method_name": "gistInitBuildBuffers",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 43,
      "comment": "/*\n * Initialize GiST build buffers.\n */",
      "description": "Initialize GiST build buffers."
    },
    {
      "method_name": "gistGetNodeBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 112,
      "comment": "/*\n * Returns a node buffer for given block. The buffer is created if it\n * doesn't exist yet.\n */",
      "description": "Returns a node buffer for given block. The buffer is created if it    doesn't exist yet."
    },
    {
      "method_name": "gistAllocateNewPageBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 180,
      "comment": "/*\n * Allocate memory for a buffer page.\n */",
      "description": "Allocate memory for a buffer page."
    },
    {
      "method_name": "gistAddLoadedBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 197,
      "comment": "/*\n * Add specified buffer into loadedBuffers array.\n */",
      "description": "Add specified buffer into loadedBuffers array."
    },
    {
      "method_name": "gistLoadNodeBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 220,
      "comment": "/*\n * Load last page of node buffer into main memory.\n */",
      "description": "Load last page of node buffer into main memory."
    },
    {
      "method_name": "gistUnloadNodeBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 245,
      "comment": "/*\n * Write last page of node buffer to the disk.\n */",
      "description": "Write last page of node buffer to the disk."
    },
    {
      "method_name": "gistUnloadNodeBuffers",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 271,
      "comment": "/*\n * Write last pages of all node buffers to the disk.\n */",
      "description": "Write last pages of all node buffers to the disk."
    },
    {
      "method_name": "gistPlaceItupToPage",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 287,
      "comment": "/*\n * Add index tuple to buffer page.\n */",
      "description": "Add index tuple to buffer page."
    },
    {
      "method_name": "gistGetItupFromPage",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 310,
      "comment": "/*\n * Get last item from buffer page and remove it from page.\n */",
      "description": "Get last item from buffer page and remove it from page."
    },
    {
      "method_name": "gistPushItupToNodeBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 335,
      "comment": "/*\n * Push an index tuple to node buffer.\n */",
      "description": "Push an index tuple to node buffer."
    },
    {
      "method_name": "gistPopItupFromNodeBuffer",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 405,
      "comment": "/*\n * Removes one index tuple from node buffer. Returns true if success and false\n * if node buffer is empty.\n */",
      "description": "Removes one index tuple from node buffer. Returns true if success and false    if node buffer is empty."
    },
    {
      "method_name": "gistBuffersGetFreeBlock",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 467,
      "comment": "/*\n * Select a currently unused block for writing to.\n */",
      "description": "Select a currently unused block for writing to."
    },
    {
      "method_name": "gistBuffersReleaseBlock",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 484,
      "comment": "/*\n * Return a block# to the freelist.\n */",
      "description": "Return a block# to the freelist."
    },
    {
      "method_name": "gistFreeBuildBuffers",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 506,
      "comment": "/*\n * Free buffering build data structure.\n */",
      "description": "Free buffering build data structure."
    },
    {
      "method_name": "<clinit>",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 519,
      "comment": "/*\n * Data structure representing information about node buffer for index tuples\n * relocation from split node buffer.\n */",
      "description": "Data structure representing information about node buffer for index tuples    relocation from split node buffer."
    },
    {
      "method_name": "gistRelocateBuildBuffersOnSplit",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 532,
      "comment": "/*\n * At page split, distribute tuples from the buffer of the split page to\n * new buffers for the created page halves. This also adjusts the downlinks\n * in 'splitinfo' to include the tuples in the buffers.\n */",
      "description": "At page split, distribute tuples from the buffer of the split page to    new buffers for the created page halves."
    },
    {
      "method_name": "ReadTempFileBlock",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 749,
      "comment": "/*\n * Wrappers around BufFile operations. The main difference is that these\n * wrappers report errors with ereport(), so that the callers don't need\n * to check the return code.\n */",
      "description": "Wrappers around BufFile operations. The main difference is that these    wrappers report errors with ereport(), so that the callers don't need    to check the return code."
    },
    {
      "method_name": "WriteTempFileBlock",
      "file_path": "backend/access/gist/gistbuildbuffers.c",
      "line_number": 757,
      "comment": "/*\n * Wrappers around BufFile operations. The main difference is that these\n * wrappers report errors with ereport(), so that the callers don't need\n * to check the return code.\n */",
      "description": "Wrappers around BufFile operations. The main difference is that these    wrappers report errors with ereport(), so that the callers don't need    to check the return code."
    },
    {
      "method_name": "gistkillitems",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 37,
      "comment": "/*\n * gistkillitems() -- set LP_DEAD state for items an indexscan caller has\n * told us were killed.\n *\n * We re-read page here, so it's important to check page LSN. If the page\n * has been modified since the last read (as determined by LSN), we cannot\n * flag any entries because it is possible that the old entry was vacuumed\n * away and the TID was re-used by a completely different heap tuple.\n */",
      "description": "gistkillitems() -- set LP_DEAD state for items an indexscan caller has    told us were killed."
    },
    {
      "method_name": "gistindex_keytest",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 124,
      "comment": "/*\n * gistindex_keytest() -- does this index tuple satisfy the scan key(s)?\n *\n * The index tuple might represent either a heap tuple or a lower index page,\n * depending on whether the containing page is a leaf page or not.\n *\n * On success return for a heap tuple, *recheck_p is set to indicate whether\n * the quals need to be rechecked.  We recheck if any of the consistent()\n * functions request it.  recheck is not interesting when examining a non-leaf\n * entry, since we must visit the lower index page if there's any doubt.\n * Similarly, *recheck_distances_p is set to indicate whether the distances\n * need to be rechecked, and it is also ignored for non-leaf entries.\n *\n * If we are doing an ordered scan, so->distances[] is filled with distance\n * data from the distance() functions before returning success.\n *\n * We must decompress the key in the IndexTuple before passing it to the\n * sk_funcs (which actually are the opclass Consistent or Distance methods).\n *\n * Note that this function is always invoked in a short-lived memory context,\n * so we don't need to worry about cleaning up allocated memory, either here\n * or in the implementation of any Consistent or Distance methods.\n */",
      "description": "gistindex_keytest() -- does this index tuple satisfy the scan key(s)?       The index tuple might represent either a heap tuple or a lower index page,    depending on whether the containing page is a leaf page or not."
    },
    {
      "method_name": "gistScanPage",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 327,
      "comment": "/*\n * Scan all items on the GiST index page identified by *pageItem, and insert\n * them into the queue (or directly to output areas)\n *\n * scan: index scan we are executing\n * pageItem: search queue item identifying an index page to scan\n * myDistances: distances array associated with pageItem, or NULL at the root\n * tbm: if not NULL, gistgetbitmap's output bitmap\n * ntids: if not NULL, gistgetbitmap's output tuple counter\n *\n * If tbm/ntids aren't NULL, we are doing an amgetbitmap scan, and heap\n * tuples should be reported directly into the bitmap.  If they are NULL,\n * we're doing a plain or ordered indexscan.  For a plain indexscan, heap\n * tuple TIDs are returned into so->pageData[].  For an ordered indexscan,\n * heap tuple TIDs are pushed into individual search queue items.  In an\n * index-only scan, reconstructed index tuples are returned along with the\n * TIDs.\n *\n * If we detect that the index page has split since we saw its downlink\n * in the parent, we push its new right sibling onto the queue so the\n * sibling will be processed next.\n */",
      "description": "Scan all items on the GiST index page identified by  pageItem, and insert    them into the queue (or directly to output areas)       scan: index scan we are executing    pageItem: search queue item identifying an index page to scan    myDistances: distances array associated with pageItem, or NULL at the root    tbm: if not NULL, gistgetbitmap's output bitmap    ntids: if not NULL, gistgetbitmap's output tuple counter       If tbm/ntids aren't NULL, we are doing an amgetbitmap scan, and heap    tuples should be reported directly into the bitmap."
    },
    {
      "method_name": "getNextGISTSearchItem",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 537,
      "comment": "/*\n * Extract next item (in order) from search queue\n *\n * Returns a GISTSearchItem or NULL.  Caller must pfree item when done with it.\n */",
      "description": "Extract next item (in order) from search queue       Returns a GISTSearchItem or NULL.  Caller must pfree item when done with it."
    },
    {
      "method_name": "getNextNearest",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 559,
      "comment": "/*\n * Fetch next heap tuple in an ordered search\n */",
      "description": "Fetch next heap tuple in an ordered search"
    },
    {
      "method_name": "gistgettuple",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 611,
      "comment": "/*\n * gistgettuple() -- Get the next tuple in the scan\n */",
      "description": "gistgettuple() -- Get the next tuple in the scan"
    },
    {
      "method_name": "gistgetbitmap",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 742,
      "comment": "/*\n * gistgetbitmap() -- Get a bitmap of all heap tuple locations\n */",
      "description": "gistgetbitmap() -- Get a bitmap of all heap tuple locations"
    },
    {
      "method_name": "gistcanreturn",
      "file_path": "backend/access/gist/gistget.c",
      "line_number": 792,
      "comment": "/*\n * Can we do index-only scans on the given index column?\n *\n * Opclasses that implement a fetch function support index-only scans.\n * Opclasses without compression functions also support index-only scans.\n * Included attributes always can be fetched for index-only scans.\n */",
      "description": "Can we do index-only scans on the given index column?       Opclasses that implement a fetch function support index-only scans."
    },
    {
      "method_name": "rt_box_union",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 54,
      "comment": "/*\n * Calculates union of two boxes, a and b. The result is stored in *n.\n */",
      "description": "Calculates union of two boxes, a and b. The result is stored in  n."
    },
    {
      "method_name": "size_box",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 67,
      "comment": "/*\n * Size of a BOX for penalty-calculation purposes.\n * The result can be +Infinity, but not NaN.\n */",
      "description": "Size of a BOX for penalty-calculation purposes.    The result can be +Infinity, but not NaN."
    },
    {
      "method_name": "box_penalty",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 96,
      "comment": "/*\n * Return amount by which the union of the two boxes is larger than\n * the original BOX's area.  The result can be +Infinity, but not NaN.\n */",
      "description": "Return amount by which the union of the two boxes is larger than    the original BOX's area.  The result can be +Infinity, but not NaN."
    },
    {
      "method_name": "gist_box_consistent",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 112,
      "comment": "/*\n * The GiST Consistent method for boxes\n *\n * Should return false if for all data items x below entry,\n * the predicate x op query must be false, where op is the oper\n * corresponding to strategy in the pg_amop table.\n */",
      "description": "The GiST Consistent method for boxes       Should return false if for all data items x below entry,    the predicate x op query must be false, where op is the oper    corresponding to strategy in the pg_amop table.."
    },
    {
      "method_name": "adjustBox",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 145,
      "comment": "/*\n * Increase BOX b to include addon.\n */",
      "description": "Increase BOX b to include addon."
    },
    {
      "method_name": "gist_box_union",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 163,
      "comment": "/*\n * The GiST Union method for boxes\n *\n * returns the minimal bounding box that encloses all the entries in entryvec\n */",
      "description": "The GiST Union method for boxes       returns the minimal bounding box that encloses all the entries in entryvec"
    },
    {
      "method_name": "gist_box_penalty",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 198,
      "comment": "/*\n * The GiST Penalty method for boxes (also used for points)\n *\n * As in the R-tree paper, we use change in area as our penalty metric\n */",
      "description": "The GiST Penalty method for boxes (also used for points)       As in the R-tree paper, we use change in area as our penalty metric"
    },
    {
      "method_name": "fallbackSplit",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 215,
      "comment": "/*\n * Trivial split: half of entries will be placed on one page\n * and another half - to another\n */",
      "description": "Trivial split: half of entries will be placed on one page    and another half - to another"
    },
    {
      "method_name": "interval_cmp_lower",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 314,
      "comment": "/*\n * Interval comparison function by lower bound of the interval;\n */",
      "description": "Interval comparison function by lower bound of the interval;"
    },
    {
      "method_name": "interval_cmp_upper",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 326,
      "comment": "/*\n * Interval comparison function by upper bound of the interval;\n */",
      "description": "Interval comparison function by upper bound of the interval;"
    },
    {
      "method_name": "non_negative",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 338,
      "comment": "/*\n * Replace negative (or NaN) value with zero.\n */",
      "description": "Replace negative (or NaN) value with zero."
    },
    {
      "method_name": "g_box_consider_split",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 350,
      "comment": "/*\n * Consider replacement of currently selected split with the better one.\n */",
      "description": "Consider replacement of currently selected split with the better one."
    },
    {
      "method_name": "common_entry_cmp",
      "file_path": "backend/access/gist/gistproc.c",
      "line_number": 459,
      "comment": "/*\n * Compare common entries by their deltas.\n */",
      "description": "Compare common entries by their deltas."
    },
    {
      "method_name": "gistextractpage",
      "file_path": "backend/access/gist/gistutil.c",
      "line_number": 93,
      "comment": "/*\n * Read buffer into itup vector\n */",
      "description": "Read buffer into itup vector"
    },
    {
      "method_name": "gistjoinvector",
      "file_path": "backend/access/gist/gistutil.c",
      "line_number": 112,
      "comment": "/*\n * join two vectors into one\n */",
      "description": "join two vectors into one"
    },
    {
      "method_name": "gistfillitupvec",
      "file_path": "backend/access/gist/gistutil.c",
      "line_number": 125,
      "comment": "/*\n * make plain IndexTuple vector\n */",
      "description": "make plain IndexTuple vector"
    },
    {
      "method_name": "gistMakeUnionItVec",
      "file_path": "backend/access/gist/gistutil.c",
      "line_number": 153,
      "comment": "/*\n * Make unions of keys in IndexTuple vector (one union datum per index column).\n * Union Datums are returned into the attr/isnull arrays.\n * Resulting Datums aren't compressed.\n */",
      "description": "Make unions of keys in IndexTuple vector (one union datum per index column).    Union Datums are returned into the attr/isnull arrays.    Resulting Datums aren't compressed."
    },
    {
      "method_name": "_hash_pageinit",
      "file_path": "backend/access/hash/hashpage.c",
      "line_number": 595,
      "comment": "/*\n *\t_hash_pageinit() -- Initialize a new hash index page.\n */",
      "description": "_hash_pageinit() -- Initialize a new hash index page."
    },
    {
      "method_name": "_hash_expandtable",
      "file_path": "backend/access/hash/hashpage.c",
      "line_number": 613,
      "comment": "/*\n * Attempt to expand the hash table by creating one new bucket.\n *\n * This will silently do nothing if we don't get cleanup lock on old or\n * new bucket.\n *\n * Complete the pending splits and remove the tuples from old bucket,\n * if there are any left over from the previous split.\n *\n * The caller must hold a pin, but no lock, on the metapage buffer.\n * The buffer is returned in the same state.\n */",
      "description": "Attempt to expand the hash table by creating one new bucket."
    },
    {
      "method_name": "heap_tuple_needs_eventual_freeze",
      "file_path": "backend/access/heap/heapam.c",
      "line_number": 7786,
      "comment": "/*\n * heap_tuple_needs_eventual_freeze\n *\n * Check to see whether any of the XID fields of a tuple (xmin, xmax, xvac)\n * will eventually require freezing (if tuple isn't removed by pruning first).\n */",
      "description": "heap_tuple_needs_eventual_freeze       Check to see whether any of the XID fields of a tuple (xmin, xmax, xvac)    will eventually require freezing (if tuple isn't removed by pruning first)."
    },
    {
      "method_name": "heap_tuple_should_freeze",
      "file_path": "backend/access/heap/heapam.c",
      "line_number": 7841,
      "comment": "/*\n * heap_tuple_should_freeze\n *\n * Return value indicates if heap_prepare_freeze_tuple sibling function would\n * (or should) force freezing of the heap page that contains caller's tuple.\n * Tuple header XIDs/MXIDs < FreezeLimit/MultiXactCutoff trigger freezing.\n * This includes (xmin, xmax, xvac) fields, as well as MultiXact member XIDs.\n *\n * The *NoFreezePageRelfrozenXid and *NoFreezePageRelminMxid input/output\n * arguments help VACUUM track the oldest extant XID/MXID remaining in rel.\n * Our working assumption is that caller won't decide to freeze this tuple.\n * It's up to caller to only ratchet back its own top-level trackers after the\n * point that it fully commits to not freezing the tuple/page in question.\n */",
      "description": "heap_tuple_should_freeze       Return value indicates if heap_prepare_freeze_tuple sibling function would    (or should) force freezing of the heap page that contains caller's tuple."
    },
    {
      "method_name": "logical_rewrite_log_mapping",
      "file_path": "backend/access/heap/rewriteheap.c",
      "line_number": 934,
      "comment": "/*\n * Log a single (old->new) mapping for 'xid'.\n */",
      "description": "Log a single (old->new) mapping for 'xid'."
    },
    {
      "method_name": "logical_rewrite_heap_tuple",
      "file_path": "backend/access/heap/rewriteheap.c",
      "line_number": 998,
      "comment": "/*\n * Perform logical remapping for a tuple that's mapped from old_tid to\n * new_tuple->t_self by rewrite_heap_tuple() if necessary for the tuple.\n */",
      "description": "Perform logical remapping for a tuple that's mapped from old_tid to    new_tuple->t_self by rewrite_heap_tuple() if necessary for the tuple."
    },
    {
      "method_name": "heap_xlog_logical_rewrite",
      "file_path": "backend/access/heap/rewriteheap.c",
      "line_number": 1072,
      "comment": "/*\n * Replay XLOG_HEAP2_REWRITE records\n */",
      "description": "Replay XLOG_HEAP2_REWRITE records"
    },
    {
      "method_name": "CheckPointLogicalRewriteHeap",
      "file_path": "backend/access/heap/rewriteheap.c",
      "line_number": 1154,
      "comment": "/* ---\n * Perform a checkpoint for logical rewrite mappings\n *\n * This serves two tasks:\n * 1) Remove all mappings not needed anymore based on the logical restart LSN\n * 2) Flush all remaining mappings to disk, so that replay after a checkpoint\n *\t  only has to deal with the parts of a mapping that have been written out\n *\t  after the checkpoint started.\n * ---\n */",
      "description": "---    Perform a checkpoint for logical rewrite mappings       This serves two tasks:    1) Remove all mappings not needed anymore based on the logical restart LSN    2) Flush all remaining mappings to disk, so that replay after a checkpoint   \t  only has to deal with the parts of a mapping that have been written out   \t  after the checkpoint started."
    },
    {
      "method_name": "heap_vacuum_rel",
      "file_path": "backend/access/heap/vacuumlazy.c",
      "line_number": 294,
      "comment": "/*\n *\theap_vacuum_rel() -- perform VACUUM for one heap relation\n *\n *\t\tThis routine sets things up for and then calls lazy_scan_heap, where\n *\t\talmost all work actually takes place.  Finalizes everything after call\n *\t\treturns by managing relation truncation and updating rel's pg_class\n *\t\tentry. (Also updates pg_class entries for any indexes that need it.)\n *\n *\t\tAt entry, we have already established a transaction and opened\n *\t\tand locked the relation.\n */",
      "description": "heap_vacuum_rel() -- perform VACUUM for one heap relation      \t\tThis routine sets things up for and then calls lazy_scan_heap, where   \t\talmost all work actually takes place."
    },
    {
      "method_name": "_bt_spooldestroy",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 514,
      "comment": "/*\n * clean up a spool structure and its substructures.\n */",
      "description": "clean up a spool structure and its substructures."
    },
    {
      "method_name": "_bt_spool",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 524,
      "comment": "/*\n * spool an index entry into the sort file.\n */",
      "description": "spool an index entry into the sort file."
    },
    {
      "method_name": "_bt_leafbuild",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 535,
      "comment": "/*\n * given a spool loaded by successive calls to _bt_spool,\n * create an entire btree.\n */",
      "description": "given a spool loaded by successive calls to _bt_spool,    create an entire btree."
    },
    {
      "method_name": "_bt_build_callback",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 576,
      "comment": "/*\n * Per-tuple callback for table_index_build_scan\n */",
      "description": "Per-tuple callback for table_index_build_scan"
    },
    {
      "method_name": "_bt_blnewpage",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 605,
      "comment": "/*\n * allocate workspace for a new, clean btree page, not linked to any siblings.\n */",
      "description": "allocate workspace for a new, clean btree page, not linked to any siblings."
    },
    {
      "method_name": "_bt_blwritepage",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 634,
      "comment": "/*\n * emit a completed btree page, and release the working storage.\n */",
      "description": "emit a completed btree page, and release the working storage."
    },
    {
      "method_name": "_bt_pagestate",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 645,
      "comment": "/*\n * allocate and initialize a new BTPageState.  the returned structure\n * is suitable for immediate use by _bt_buildadd.\n */",
      "description": "allocate and initialize a new BTPageState.  the returned structure    is suitable for immediate use by _bt_buildadd."
    },
    {
      "method_name": "_bt_slideleft",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 682,
      "comment": "/*\n * Slide the array of ItemIds from the page back one slot (from P_FIRSTKEY to\n * P_HIKEY, overwriting P_HIKEY).\n *\n * _bt_blnewpage() makes the P_HIKEY line pointer appear allocated, but the\n * rightmost page on its level is not supposed to get a high key.  Now that\n * it's clear that this page is a rightmost page, remove the unneeded empty\n * P_HIKEY line pointer space.\n */",
      "description": "Slide the array of ItemIds from the page back one slot (from P_FIRSTKEY to    P_HIKEY, overwriting P_HIKEY)."
    },
    {
      "method_name": "_bt_sortaddtup",
      "file_path": "backend/access/nbtree/nbtsort.c",
      "line_number": 713,
      "comment": "/*\n * Add an item to a page being built.\n *\n * This is very similar to nbtinsert.c's _bt_pgaddtup(), but this variant\n * raises an error directly.\n *\n * Note that our nbtsort.c caller does not know yet if the page will be\n * rightmost.  Offset P_FIRSTKEY is always assumed to be the first data key by\n * caller.  Page that turns out to be the rightmost on its level is fixed by\n * calling _bt_slideleft().\n */",
      "description": "Add an item to a page being built."
    },
    {
      "method_name": "relmap_desc",
      "file_path": "backend/access/rmgrdesc/relmapdesc.c",
      "line_number": 19,
      "comment": "/*-------------------------------------------------------------------------\n *\n * relmapdesc.c\n *\t  rmgr descriptor routines for utils/cache/relmapper.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/relmapdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       relmapdesc.c   \t  rmgr descriptor routines for utils/cache/relmapper.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/relmapdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "relmap_identify",
      "file_path": "backend/access/rmgrdesc/relmapdesc.c",
      "line_number": 34,
      "comment": "/*-------------------------------------------------------------------------\n *\n * relmapdesc.c\n *\t  rmgr descriptor routines for utils/cache/relmapper.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/relmapdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       relmapdesc.c   \t  rmgr descriptor routines for utils/cache/relmapper.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/relmapdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "replorigin_desc",
      "file_path": "backend/access/rmgrdesc/replorigindesc.c",
      "line_number": 18,
      "comment": "/*-------------------------------------------------------------------------\n *\n * replorigindesc.c\n *\t  rmgr descriptor routines for replication/logical/origin.c\n *\n * Portions Copyright (c) 2015-2024, PostgreSQL Global Development Group\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/replorigindesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       replorigindesc.c   \t  rmgr descriptor routines for replication/logical/origin.c       Portions Copyright (c) 2015-2024, PostgreSQL Global Development Group          IDENTIFICATION   \t  src/backend/access/rmgrdesc/replorigindesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "array_desc",
      "file_path": "backend/access/rmgrdesc/rmgrdesc_utils.c",
      "line_number": 23,
      "comment": "/*\n * Helper function to print an array, in the format described in the\n * README.\n */",
      "description": "Helper function to print an array, in the format described in the    README."
    },
    {
      "method_name": "offset_elem_desc",
      "file_path": "backend/access/rmgrdesc/rmgrdesc_utils.c",
      "line_number": 43,
      "comment": "/*\n * Helper function to print an array, in the format described in the\n * README.\n */",
      "description": "Helper function to print an array, in the format described in the    README."
    },
    {
      "method_name": "redirect_elem_desc",
      "file_path": "backend/access/rmgrdesc/rmgrdesc_utils.c",
      "line_number": 49,
      "comment": "/*\n * Helper function to print an array, in the format described in the\n * README.\n */",
      "description": "Helper function to print an array, in the format described in the    README."
    },
    {
      "method_name": "seq_desc",
      "file_path": "backend/access/rmgrdesc/seqdesc.c",
      "line_number": 20,
      "comment": "/*-------------------------------------------------------------------------\n *\n * seqdesc.c\n *\t  rmgr descriptor routines for commands/sequence.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/seqdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       seqdesc.c   \t  rmgr descriptor routines for commands/sequence.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/seqdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "seq_identify",
      "file_path": "backend/access/rmgrdesc/seqdesc.c",
      "line_number": 33,
      "comment": "/*-------------------------------------------------------------------------\n *\n * seqdesc.c\n *\t  rmgr descriptor routines for commands/sequence.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/seqdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       seqdesc.c   \t  rmgr descriptor routines for commands/sequence.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/seqdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "smgr_desc",
      "file_path": "backend/access/rmgrdesc/smgrdesc.c",
      "line_number": 20,
      "comment": "/*-------------------------------------------------------------------------\n *\n * smgrdesc.c\n *\t  rmgr descriptor routines for catalog/storage.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/smgrdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       smgrdesc.c   \t  rmgr descriptor routines for catalog/storage.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/smgrdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "spg_desc",
      "file_path": "backend/access/rmgrdesc/spgdesc.c",
      "line_number": 19,
      "comment": "/*-------------------------------------------------------------------------\n *\n * spgdesc.c\n *\t  rmgr descriptor routines for access/spgist/spgxlog.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/spgdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       spgdesc.c   \t  rmgr descriptor routines for access/spgist/spgxlog.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/spgdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "standby_desc_running_xacts",
      "file_path": "backend/access/rmgrdesc/standbydesc.c",
      "line_number": 19,
      "comment": "/*-------------------------------------------------------------------------\n *\n * standbydesc.c\n *\t  rmgr descriptor routines for storage/ipc/standby.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/standbydesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       standbydesc.c   \t  rmgr descriptor routines for storage/ipc/standby.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/standbydesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "standby_desc_invalidations",
      "file_path": "backend/access/rmgrdesc/standbydesc.c",
      "line_number": 104,
      "comment": "/*\n * This routine is used by both standby_desc and xact_desc, because\n * transaction commits and XLOG_INVALIDATIONS messages contain invalidations;\n * it seems pointless to duplicate the code.\n */",
      "description": "This routine is used by both standby_desc and xact_desc, because    transaction commits and XLOG_INVALIDATIONS messages contain invalidations;    it seems pointless to duplicate the code."
    },
    {
      "method_name": "tblspc_desc",
      "file_path": "backend/access/rmgrdesc/tblspcdesc.c",
      "line_number": 20,
      "comment": "/*-------------------------------------------------------------------------\n *\n * tblspcdesc.c\n *\t  rmgr descriptor routines for commands/tablespace.c\n *\n * Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group\n * Portions Copyright (c) 1994, Regents of the University of California\n *\n *\n * IDENTIFICATION\n *\t  src/backend/access/rmgrdesc/tblspcdesc.c\n *\n *-------------------------------------------------------------------------\n */",
      "description": "-------------------------------------------------------------------------       tblspcdesc.c   \t  rmgr descriptor routines for commands/tablespace.c       Portions Copyright (c) 1996-2024, PostgreSQL Global Development Group    Portions Copyright (c) 1994, Regents of the University of California          IDENTIFICATION   \t  src/backend/access/rmgrdesc/tblspcdesc.c      -------------------------------------------------------------------------."
    },
    {
      "method_name": "ParseCommitRecord",
      "file_path": "backend/access/rmgrdesc/xactdesc.c",
      "line_number": 34,
      "comment": "/*\n * Parse the WAL format of an xact commit and abort records into an easier to\n * understand format.\n *\n * These routines are in xactdesc.c because they're accessed in backend (when\n * replaying WAL) and frontend (pg_waldump) code. This file is the only xact\n * specific one shared between both. They're complicated enough that\n * duplication would be bothersome.\n */",
      "description": "Parse the WAL format of an xact commit and abort records into an easier to    understand format."
    },
    {
      "method_name": "ParsePrepareRecord",
      "file_path": "backend/access/rmgrdesc/xactdesc.c",
      "line_number": 238,
      "comment": "/*\n * ParsePrepareRecord\n */",
      "description": "ParsePrepareRecord"
    },
    {
      "method_name": "get_wal_level_string",
      "file_path": "backend/access/rmgrdesc/xlogdesc.c",
      "line_number": 39,
      "comment": "/*\n * Find a string representation for wal_level\n */",
      "description": "Find a string representation for wal_level"
    },
    {
      "method_name": "xlog_desc",
      "file_path": "backend/access/rmgrdesc/xlogdesc.c",
      "line_number": 57,
      "comment": "/*\n * Find a string representation for wal_level\n */",
      "description": "Find a string representation for wal_level"
    },
    {
      "method_name": "XLogRecGetBlockRefInfo",
      "file_path": "backend/access/rmgrdesc/xlogdesc.c",
      "line_number": 230,
      "comment": "/*\n * Returns a string giving information about all the blocks in an\n * XLogRecord.\n */",
      "description": "Returns a string giving information about all the blocks in an    XLogRecord."
    },
    {
      "method_name": "sequence_open",
      "file_path": "backend/access/sequence/sequence.c",
      "line_number": 36,
      "comment": "/* ----------------\n *\t\tsequence_open - open a sequence relation by relation OID\n *\n *\t\tThis is essentially relation_open plus check that the relation\n *\t\tis a sequence.\n * ----------------\n */",
      "description": "----------------   \t\tsequence_open - open a sequence relation by relation OID      \t\tThis is essentially relation_open plus check that the relation   \t\tis a sequence.    ----------------"
    },
    {
      "method_name": "spgClearPendingList",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 88,
      "comment": "/*\n * Clear pendingList\n */",
      "description": "Clear pendingList"
    },
    {
      "method_name": "vacuumLeafPage",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 124,
      "comment": "/*\n * Vacuum a regular (non-root) leaf page\n *\n * We must delete tuples that are targeted for deletion by the VACUUM,\n * but not move any tuples that are referenced by outside links; we assume\n * those are the ones that are heads of chains.\n *\n * If we find a REDIRECT that was made by a concurrently-running transaction,\n * we must add its target TID to pendingList.  (We don't try to visit the\n * target immediately, first because we don't want VACUUM locking more than\n * one buffer at a time, and second because the duplicate-filtering logic\n * in spgAddPendingTID is useful to ensure we can't get caught in an infinite\n * loop in the face of continuous concurrent insertions.)\n *\n * If forPending is true, we are examining the page as a consequence of\n * chasing a redirect link, not as part of the normal sequential scan.\n * We still vacuum the page normally, but we don't increment the stats\n * about live tuples; else we'd double-count those tuples, since the page\n * has been or will be visited in the sequential scan as well.\n */",
      "description": "Vacuum a regular (non-root) leaf page       We must delete tuples that are targeted for deletion by the VACUUM,    but not move any tuples that are referenced by outside links; we assume    those are the ones that are heads of chains."
    },
    {
      "method_name": "vacuumLeafRoot",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 407,
      "comment": "/*\n * Vacuum a root page when it is also a leaf\n *\n * On the root, we just delete any dead leaf tuples; no fancy business\n */",
      "description": "Vacuum a root page when it is also a leaf       On the root, we just delete any dead leaf tuples; no fancy business"
    },
    {
      "method_name": "vacuumRedirectAndPlaceholder",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 492,
      "comment": "/*\n * Clean up redirect and placeholder tuples on the given page\n *\n * Redirect tuples can be marked placeholder once they're old enough.\n * Placeholder tuples can be removed if it won't change the offsets of\n * non-placeholder ones.\n *\n * Unlike the routines above, this works on both leaf and inner pages.\n */",
      "description": "Clean up redirect and placeholder tuples on the given page       Redirect tuples can be marked placeholder once they're old enough."
    },
    {
      "method_name": "spgvacuumpage",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 620,
      "comment": "/*\n * Process one page during a bulkdelete scan\n */",
      "description": "Process one page during a bulkdelete scan"
    },
    {
      "method_name": "spgprocesspending",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 691,
      "comment": "/*\n * Process the pending-TID list between pages of the main scan\n */",
      "description": "Process the pending-TID list between pages of the main scan"
    },
    {
      "method_name": "spgvacuumscan",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 803,
      "comment": "/*\n * Perform a bulkdelete scan\n */",
      "description": "Perform a bulkdelete scan"
    },
    {
      "method_name": "spgbulkdelete",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 915,
      "comment": "/*\n * Bulk deletion of all index entries pointing to a set of heap tuples.\n * The set of target tuples is specified via a callback routine that tells\n * whether any given heap tuple (identified by ItemPointer) is being deleted.\n *\n * Result: a palloc'd struct containing statistical info for VACUUM displays.\n */",
      "description": "Bulk deletion of all index entries pointing to a set of heap tuples."
    },
    {
      "method_name": "dummy_callback",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 935,
      "comment": "/* Dummy callback to delete no tuples during spgvacuumcleanup */",
      "description": "Dummy callback to delete no tuples during spgvacuumcleanup"
    },
    {
      "method_name": "spgvacuumcleanup",
      "file_path": "backend/access/spgist/spgvacuum.c",
      "line_number": 946,
      "comment": "/*\n * Post-VACUUM cleanup.\n *\n * Result: a palloc'd struct containing statistical info for VACUUM displays.\n */",
      "description": "Post-VACUUM cleanup.       Result: a palloc'd struct containing statistical info for VACUUM displays."
    },
    {
      "method_name": "spgvalidate",
      "file_path": "backend/access/spgist/spgvalidate.c",
      "line_number": 38,
      "comment": "/*\n * Validator for an SP-GiST opclass.\n *\n * Some of the checks done here cover the whole opfamily, and therefore are\n * redundant when checking each opclass in a family.  But they don't run long\n * enough to be much of a problem, so we accept the duplication rather than\n * complicate the amvalidate API.\n */",
      "description": "Validator for an SP-GiST opclass."
    },
    {
      "method_name": "spgadjustmembers",
      "file_path": "backend/access/spgist/spgvalidate.c",
      "line_number": 331,
      "comment": "/*\n * Prechecking function for adding operators/functions to an SP-GiST opfamily.\n */",
      "description": "Prechecking function for adding operators/functions to an SP-GiST opfamily."
    },
    {
      "method_name": "fillFakeState",
      "file_path": "backend/access/spgist/spgxlog.c",
      "line_number": 34,
      "comment": "/*\n * Prepare a dummy SpGistState, with just the minimum info needed for replay.\n *\n * At present, all we need is enough info to support spgFormDeadTuple(),\n * plus the isBuild flag.\n */",
      "description": "Prepare a dummy SpGistState, with just the minimum info needed for replay.       At present, all we need is enough info to support spgFormDeadTuple(),    plus the isBuild flag."
    },
    {
      "method_name": "addOrReplaceTuple",
      "file_path": "backend/access/spgist/spgxlog.c",
      "line_number": 49,
      "comment": "/*\n * Add a leaf tuple, or replace an existing placeholder tuple.  This is used\n * to replay SpGistPageAddNewItem() operations.  If the offset points at an\n * existing tuple, it had better be a placeholder tuple.\n */",
      "description": "Add a leaf tuple, or replace an existing placeholder tuple."
    },
    {
      "method_name": "spgRedoAddLeaf",
      "file_path": "backend/access/spgist/spgxlog.c",
      "line_number": 73,
      "comment": "/*\n * Add a leaf tuple, or replace an existing placeholder tuple.  This is used\n * to replay SpGistPageAddNewItem() operations.  If the offset points at an\n * existing tuple, it had better be a placeholder tuple.\n */",
      "description": "Add a leaf tuple, or replace an existing placeholder tuple."
    },
    {
      "method_name": "spg_mask",
      "file_path": "backend/access/spgist/spgxlog.c",
      "line_number": 993,
      "comment": "/*\n * Mask a SpGist page before performing consistency checks on it.\n */",
      "description": "Mask a SpGist page before performing consistency checks on it."
    },
    {
      "method_name": "table_open",
      "file_path": "backend/access/table/table.c",
      "line_number": 39,
      "comment": "/* ----------------\n *\t\ttable_open - open a table relation by relation OID\n *\n *\t\tThis is essentially relation_open plus check that the relation\n *\t\tis not an index nor a composite type.  (The caller should also\n *\t\tcheck that it's not a view or foreign table before assuming it has\n *\t\tstorage.)\n * ----------------\n */",
      "description": "----------------   \t\ttable_open - open a table relation by relation OID      \t\tThis is essentially relation_open plus check that the relation   \t\tis not an index nor a composite type."
    },
    {
      "method_name": "try_table_open",
      "file_path": "backend/access/table/table.c",
      "line_number": 59,
      "comment": "/* ----------------\n *\t\ttry_table_open - open a table relation by relation OID\n *\n *\t\tSame as table_open, except return NULL instead of failing\n *\t\tif the relation does not exist.\n * ----------------\n */",
      "description": "----------------   \t\ttry_table_open - open a table relation by relation OID      \t\tSame as table_open, except return NULL instead of failing   \t\tif the relation does not exist.    ----------------"
    },
    {
      "method_name": "table_openrv",
      "file_path": "backend/access/table/table.c",
      "line_number": 82,
      "comment": "/* ----------------\n *\t\ttable_openrv - open a table relation specified\n *\t\tby a RangeVar node\n *\n *\t\tAs above, but relation is specified by a RangeVar.\n * ----------------\n */",
      "description": "----------------   \t\ttable_openrv - open a table relation specified   \t\tby a RangeVar node      \t\tAs above, but relation is specified by a RangeVar.    ----------------"
    },
    {
      "method_name": "table_openrv_extended",
      "file_path": "backend/access/table/table.c",
      "line_number": 102,
      "comment": "/* ----------------\n *\t\ttable_openrv_extended - open a table relation specified\n *\t\tby a RangeVar node\n *\n *\t\tAs above, but optionally return NULL instead of failing for\n *\t\trelation-not-found.\n * ----------------\n */",
      "description": "----------------   \t\ttable_openrv_extended - open a table relation specified   \t\tby a RangeVar node      \t\tAs above, but optionally return NULL instead of failing for   \t\trelation-not-found."
    },
    {
      "method_name": "CommitTsParameterChange",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 663,
      "comment": "/*\n * Activate or deactivate CommitTs' upon reception of a XLOG_PARAMETER_CHANGE\n * XLog record during recovery.\n */",
      "description": "Activate or deactivate CommitTs' upon reception of a XLOG_PARAMETER_CHANGE    XLog record during recovery."
    },
    {
      "method_name": "ActivateCommitTs",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 704,
      "comment": "/*\n * Activate this module whenever necessary.\n *\t\tThis must happen during postmaster or standalone-backend startup,\n *\t\tor during WAL replay anytime the track_commit_timestamp setting is\n *\t\tchanged in the primary.\n *\n * The reason why this SLRU needs separate activation/deactivation functions is\n * that it can be enabled/disabled during start and the activation/deactivation\n * on the primary is propagated to the standby via replay. Other SLRUs don't\n * have this property and they can be just initialized during normal startup.\n *\n * This is in charge of creating the currently active segment, if it's not\n * already there.  The reason for this is that the server might have been\n * running with this module disabled for a while and thus might have skipped\n * the normal creation point.\n */",
      "description": "Activate this module whenever necessary."
    },
    {
      "method_name": "DeactivateCommitTs",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 784,
      "comment": "/*\n * Deactivate this module.\n *\n * This must be called when the track_commit_timestamp parameter is turned off.\n * This happens during postmaster or standalone-backend startup, or during WAL\n * replay.\n *\n * Resets CommitTs into invalid state to make sure we don't hand back\n * possibly-invalid data; also removes segments of old data.\n */",
      "description": "Deactivate this module."
    },
    {
      "method_name": "CheckPointCommitTs",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 826,
      "comment": "/*\n * Perform a checkpoint --- either during shutdown, or on-the-fly\n */",
      "description": "Perform a checkpoint --- either during shutdown, or on-the-fly"
    },
    {
      "method_name": "ExtendCommitTs",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 848,
      "comment": "/*\n * Make sure that CommitTs has room for a newly-allocated XID.\n *\n * NB: this is called while holding XidGenLock.  We want it to be very fast\n * most of the time; even when it's not so fast, no actual I/O need happen\n * unless we're forced to write out a dirty CommitTs or xlog page to make room\n * in shared memory.\n *\n * NB: the current implementation relies on track_commit_timestamp being\n * PGC_POSTMASTER.\n */",
      "description": "Make sure that CommitTs has room for a newly-allocated XID."
    },
    {
      "method_name": "TruncateCommitTs",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 889,
      "comment": "/*\n * Remove all CommitTs segments before the one holding the passed\n * transaction ID.\n *\n * Note that we don't need to flush XLOG here.\n */",
      "description": "Remove all CommitTs segments before the one holding the passed    transaction ID.       Note that we don't need to flush XLOG here."
    },
    {
      "method_name": "SetCommitTsLimit",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 915,
      "comment": "/*\n * Set the limit values between which commit TS can be consulted.\n */",
      "description": "Set the limit values between which commit TS can be consulted."
    },
    {
      "method_name": "AdvanceOldestCommitTsXid",
      "file_path": "backend/access/transam/commit_ts.c",
      "line_number": 942,
      "comment": "/*\n * Move forwards the oldest commitTS value that can be consulted\n */",
      "description": "Move forwards the oldest commitTS value that can be consulted"
    },
    {
      "method_name": "WaitForParallelWorkersToAttach",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 688,
      "comment": "/*\n * Wait for all workers to attach to their error queues, and throw an error if\n * any worker fails to do this.\n *\n * Callers can assume that if this function returns successfully, then the\n * number of workers given by pcxt->nworkers_launched have initialized and\n * attached to their error queues.  Whether or not these workers are guaranteed\n * to still be running depends on what code the caller asked them to run;\n * this function does not guarantee that they have not exited.  However, it\n * does guarantee that any workers which exited must have done so cleanly and\n * after successfully performing the work with which they were tasked.\n *\n * If this function is not called, then some of the workers that were launched\n * may not have been started due to a fork() failure, or may have exited during\n * early startup prior to attaching to the error queue, so nworkers_launched\n * cannot be viewed as completely reliable.  It will never be less than the\n * number of workers which actually started, but it might be more.  Any workers\n * that failed to start will still be discovered by\n * WaitForParallelWorkersToFinish and an error will be thrown at that time,\n * provided that function is eventually reached.\n *\n * In general, the leader process should do as much work as possible before\n * calling this function.  fork() failures and other early-startup failures\n * are very uncommon, and having the leader sit idle when it could be doing\n * useful work is undesirable.  However, if the leader needs to wait for\n * all of its workers or for a specific worker, it may want to call this\n * function before doing so.  If not, it must make some other provision for\n * the failure-to-start case, lest it wait forever.  On the other hand, a\n * leader which never waits for a worker that might not be started yet, or\n * at least never does so prior to WaitForParallelWorkersToFinish(), need not\n * call this function at all.\n */",
      "description": "Wait for all workers to attach to their error queues, and throw an error if    any worker fails to do this."
    },
    {
      "method_name": "WaitForParallelWorkersToFinish",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 791,
      "comment": "/*\n * Wait for all workers to finish computing.\n *\n * Even if the parallel operation seems to have completed successfully, it's\n * important to call this function afterwards.  We must not miss any errors\n * the workers may have thrown during the parallel operation, or any that they\n * may yet throw while shutting down.\n *\n * Also, we want to update our notion of XactLastRecEnd based on worker\n * feedback.\n */",
      "description": "Wait for all workers to finish computing."
    },
    {
      "method_name": "WaitForParallelWorkersToExit",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 905,
      "comment": "/*\n * Wait for all workers to exit.\n *\n * This function ensures that workers have been completely shutdown.  The\n * difference between WaitForParallelWorkersToFinish and this function is\n * that the former just ensures that last message sent by a worker backend is\n * received by the leader backend whereas this ensures the complete shutdown.\n */",
      "description": "Wait for all workers to exit."
    },
    {
      "method_name": "DestroyParallelContext",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 945,
      "comment": "/*\n * Destroy a parallel context.\n *\n * If expecting a clean exit, you should use WaitForParallelWorkersToFinish()\n * first, before calling this function.  When this function is invoked, any\n * remaining workers are forcibly killed; the dynamic shared memory segment\n * is unmapped; and we then wait (uninterruptibly) for the workers to exit.\n */",
      "description": "Destroy a parallel context."
    },
    {
      "method_name": "ParallelContextActive",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1019,
      "comment": "/*\n * Are there any parallel contexts currently active?\n */",
      "description": "Are there any parallel contexts currently active?"
    },
    {
      "method_name": "HandleParallelMessageInterrupt",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1032,
      "comment": "/*\n * Handle receipt of an interrupt indicating a parallel worker message.\n *\n * Note: this is called within a signal handler!  All we can do is set\n * a flag that will cause the next CHECK_FOR_INTERRUPTS() to invoke\n * HandleParallelMessages().\n */",
      "description": "Handle receipt of an interrupt indicating a parallel worker message."
    },
    {
      "method_name": "HandleParallelMessages",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1043,
      "comment": "/*\n * Handle any queued protocol messages received from parallel workers.\n */",
      "description": "Handle any queued protocol messages received from parallel workers."
    },
    {
      "method_name": "HandleParallelMessage",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1132,
      "comment": "/*\n * Handle a single protocol message received from a single parallel worker.\n */",
      "description": "Handle a single protocol message received from a single parallel worker."
    },
    {
      "method_name": "AtEOSubXact_Parallel",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1249,
      "comment": "/*\n * End-of-subtransaction cleanup for parallel contexts.\n *\n * Here we remove only parallel contexts initiated within the current\n * subtransaction.\n */",
      "description": "End-of-subtransaction cleanup for parallel contexts.       Here we remove only parallel contexts initiated within the current    subtransaction."
    },
    {
      "method_name": "AtEOXact_Parallel",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1270,
      "comment": "/*\n * End-of-transaction cleanup for parallel contexts.\n *\n * We nuke all remaining parallel contexts.\n */",
      "description": "End-of-transaction cleanup for parallel contexts.       We nuke all remaining parallel contexts."
    },
    {
      "method_name": "ParallelWorkerMain",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1287,
      "comment": "/*\n * Main entrypoint for parallel workers.\n */",
      "description": "Main entrypoint for parallel workers."
    },
    {
      "method_name": "ParallelWorkerReportLastRecEnd",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1572,
      "comment": "/*\n * Update shared memory with the ending location of the last WAL record we\n * wrote, if it's greater than the value already stored there.\n */",
      "description": "Update shared memory with the ending location of the last WAL record we    wrote, if it's greater than the value already stored there."
    },
    {
      "method_name": "ParallelWorkerShutdown",
      "file_path": "backend/access/transam/parallel.c",
      "line_number": 1600,
      "comment": "/*\n * Make sure the leader tries to read from our error queue one more time.\n * This guards against the case where we exit uncleanly without sending an\n * ErrorResponse to the leader, for example because some code calls proc_exit\n * directly.\n *\n * Also explicitly detach from dsm segment so that subsystems using\n * on_dsm_detach() have a chance to send stats before the stats subsystem is\n * shut down as part of a before_shmem_exit() hook.\n *\n * One might think this could instead be solved by carefully ordering the\n * attaching to dsm segments, so that the pgstats segments get detached from\n * later than the parallel query one. That turns out to not work because the\n * stats hash might need to grow which can cause new segments to be allocated,\n * which then will be detached from earlier.\n */",
      "description": "Make sure the leader tries to read from our error queue one more time."
    },
    {
      "method_name": "pg_prepared_xact",
      "file_path": "backend/access/transam/twophase.c",
      "line_number": 710,
      "comment": "/*\n * pg_prepared_xact\n *\t\tProduce a view with one row per prepared transaction.\n *\n * This function is here so we don't have to export the\n * GlobalTransactionData struct definition.\n */",
      "description": "pg_prepared_xact   \t\tProduce a view with one row per prepared transaction.       This function is here so we don't have to export the    GlobalTransactionData struct definition."
    },
    {
      "method_name": "TwoPhaseGetGXact",
      "file_path": "backend/access/transam/twophase.c",
      "line_number": 799,
      "comment": "/*\n * TwoPhaseGetGXact\n *\t\tGet the GlobalTransaction struct for a prepared transaction\n *\t\tspecified by XID\n *\n * If lock_held is set to true, TwoPhaseStateLock will not be taken, so the\n * caller had better hold it.\n */",
      "description": "TwoPhaseGetGXact   \t\tGet the GlobalTransaction struct for a prepared transaction   \t\tspecified by XID       If lock_held is set to true, TwoPhaseStateLock will not be taken, so the    caller had better hold it.."
    },
    {
      "method_name": "AbortCurrentTransaction",
      "file_path": "backend/access/transam/xact.c",
      "line_number": 3386,
      "comment": "/*\n *\tAbortCurrentTransaction -- a wrapper function handling the\n *\t\tloop over subtransactions to avoid potentially dangerous recursion in\n *\t\tAbortCurrentTransactionInternal().\n */",
      "description": "AbortCurrentTransaction -- a wrapper function handling the   \t\tloop over subtransactions to avoid potentially dangerous recursion in   \t\tAbortCurrentTransactionInternal()."
    },
    {
      "method_name": "AbortCurrentTransactionInternal",
      "file_path": "backend/access/transam/xact.c",
      "line_number": 3404,
      "comment": "/*\n *\tAbortCurrentTransactionInternal - a function doing an iteration of work\n *\t\tregarding handling the current transaction abort.  In the case of\n *\t\tsubtransactions more than one iterations could be required.  Returns\n *\t\ttrue when no more iterations required, false otherwise.\n */",
      "description": "AbortCurrentTransactionInternal - a function doing an iteration of work   \t\tregarding handling the current transaction abort."
    },
    {
      "method_name": "PreventInTransactionBlock",
      "file_path": "backend/access/transam/xact.c",
      "line_number": 3583,
      "comment": "/*\n *\tPreventInTransactionBlock\n *\n *\tThis routine is to be called by statements that must not run inside\n *\ta transaction block, typically because they have non-rollback-able\n *\tside effects or do internal commits.\n *\n *\tIf this routine completes successfully, then the calling statement is\n *\tguaranteed that if it completes without error, its results will be\n *\tcommitted immediately.\n *\n *\tIf we have already started a transaction block, issue an error; also issue\n *\tan error if we appear to be running inside a user-defined function (which\n *\tcould issue more commands and possibly cause a failure after the statement\n *\tcompletes).  Subtransactions are verboten too.\n *\n *\tWe must also set XACT_FLAGS_NEEDIMMEDIATECOMMIT in MyXactFlags, to ensure\n *\tthat postgres.c follows through by committing after the statement is done.\n *\n *\tisTopLevel: passed down from ProcessUtility to determine whether we are\n *\tinside a function.  (We will always fail if this is false, but it's\n *\tconvenient to centralize the check here instead of making callers do it.)\n *\tstmtType: statement type name, for error messages.\n */",
      "description": "PreventInTransactionBlock      \tThis routine is to be called by statements that must not run inside   \ta transaction block, typically because they have non-rollback-able   \tside effects or do internal commits."
    },
    {
      "method_name": "WarnNoTransactionBlock",
      "file_path": "backend/access/transam/xact.c",
      "line_number": 3655,
      "comment": "/*\n *\tWarnNoTransactionBlock\n *\tRequireTransactionBlock\n *\n *\tThese two functions allow for warnings or errors if a command is executed\n *\toutside of a transaction block.  This is useful for commands that have no\n *\teffects that persist past transaction end (and so calling them outside a\n *\ttransaction block is presumably an error).  DECLARE CURSOR is an example.\n *\tWhile top-level transaction control commands (BEGIN/COMMIT/ABORT) and SET\n *\tthat have no effect issue warnings, all other no-effect commands generate\n *\terrors.\n *\n *\tIf we appear to be running inside a user-defined function, we do not\n *\tissue anything, since the function could issue more commands that make\n *\tuse of the current statement's results.  Likewise subtransactions.\n *\tThus these are inverses for PreventInTransactionBlock.\n *\n *\tisTopLevel: passed down from ProcessUtility to determine whether we are\n *\tinside a function.\n *\tstmtType: statement type name, for warning or error messages.\n */",
      "description": "WarnNoTransactionBlock   \tRequireTransactionBlock      \tThese two functions allow for warnings or errors if a command is executed   \toutside of a transaction block."
    },
    {
      "method_name": "RequireTransactionBlock",
      "file_path": "backend/access/transam/xact.c",
      "line_number": 3661,
      "comment": "/*\n *\tWarnNoTransactionBlock\n *\tRequireTransactionBlock\n *\n *\tThese two functions allow for warnings or errors if a command is executed\n *\toutside of a transaction block.  This is useful for commands that have no\n *\teffects that persist past transaction end (and so calling them outside a\n *\ttransaction block is presumably an error).  DECLARE CURSOR is an example.\n *\tWhile top-level transaction control commands (BEGIN/COMMIT/ABORT) and SET\n *\tthat have no effect issue warnings, all other no-effect commands generate\n *\terrors.\n *\n *\tIf we appear to be running inside a user-defined function, we do not\n *\tissue anything, since the function could issue more commands that make\n *\tuse of the current statement's results.  Likewise subtransactions.\n *\tThus these are inverses for PreventInTransactionBlock.\n *\n *\tisTopLevel: passed down from ProcessUtility to determine whether we are\n *\tinside a function.\n *\tstmtType: statement type name, for warning or error messages.\n */",
      "description": "WarnNoTransactionBlock   \tRequireTransactionBlock      \tThese two functions allow for warnings or errors if a command is executed   \toutside of a transaction block."
    },
    {
      "method_name": "CheckTransactionBlock",
      "file_path": "backend/access/transam/xact.c",
      "line_number": 3670,
      "comment": "/*\n * This is the implementation of the above two.\n */",
      "description": "This is the implementation of the above two."
    },
    {
      "method_name": "check_wal_consistency_checking",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4626,
      "comment": "/*\n * GUC check_hook for wal_consistency_checking\n */",
      "description": "GUC check_hook for wal_consistency_checking"
    },
    {
      "method_name": "assign_wal_consistency_checking",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4711,
      "comment": "/*\n * GUC assign_hook for wal_consistency_checking\n */",
      "description": "GUC assign_hook for wal_consistency_checking"
    },
    {
      "method_name": "InitializeWalConsistencyChecking",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4738,
      "comment": "/*\n * InitializeWalConsistencyChecking: run after loading custom resource managers\n *\n * If any unknown resource managers were specified in the\n * wal_consistency_checking GUC, processing was deferred.  Now that\n * shared_preload_libraries have been loaded, process wal_consistency_checking\n * again.\n */",
      "description": "InitializeWalConsistencyChecking: run after loading custom resource managers       If any unknown resource managers were specified in the    wal_consistency_checking GUC, processing was deferred."
    },
    {
      "method_name": "show_archive_command",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4764,
      "comment": "/*\n * GUC show_hook for archive_command\n */",
      "description": "GUC show_hook for archive_command"
    },
    {
      "method_name": "show_in_hot_standby",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4776,
      "comment": "/*\n * GUC show_hook for in_hot_standby\n */",
      "description": "GUC show_hook for in_hot_standby"
    },
    {
      "method_name": "LocalProcessControlFile",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4800,
      "comment": "/*\n * Read the control file, set respective GUCs.\n *\n * This is to be called during startup, including a crash recovery cycle,\n * unless in bootstrap mode, where no control file yet exists.  As there's no\n * usable shared memory yet (its sizing can depend on the contents of the\n * control file!), first store the contents in local memory. XLOGShmemInit()\n * will then copy it to shared memory later.\n *\n * reset just controls whether previous contents are to be expected (in the\n * reset case, there's a dangling pointer into old shared memory), or not.\n */",
      "description": "Read the control file, set respective GUCs."
    },
    {
      "method_name": "GetActiveWalLevelOnStandby",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4813,
      "comment": "/*\n * Get the wal_level from the control file. For a standby, this value should be\n * considered as its active wal_level, because it may be different from what\n * was originally configured on standby.\n */",
      "description": "Get the wal_level from the control file. For a standby, this value should be    considered as its active wal_level, because it may be different from what    was originally configured on standby."
    },
    {
      "method_name": "XLOGShmemSize",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4822,
      "comment": "/*\n * Initialization of shared memory for XLOG\n */",
      "description": "Initialization of shared memory for XLOG"
    },
    {
      "method_name": "BootStrapXLOG",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 4987,
      "comment": "/*\n * This func must be called ONCE on system install.  It creates pg_control\n * and the initial XLOG segment.\n */",
      "description": "This func must be called ONCE on system install.  It creates pg_control    and the initial XLOG segment."
    },
    {
      "method_name": "XLogInitNewTimeline",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 5168,
      "comment": "/*\n * Initialize the first WAL segment on new timeline.\n */",
      "description": "Initialize the first WAL segment on new timeline."
    },
    {
      "method_name": "CleanupAfterArchiveRecovery",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 5243,
      "comment": "/*\n * Perform cleanup actions at the conclusion of archive recovery.\n */",
      "description": "Perform cleanup actions at the conclusion of archive recovery."
    },
    {
      "method_name": "CheckRequiredParameterValues",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 5339,
      "comment": "/*\n * Check to see if required parameters are set high enough on this server\n * for various aspects of recovery operation.\n *\n * Note that all the parameters which this function tests need to be\n * listed in Administrator's Overview section in high-availability.sgml.\n * If you change them, don't forget to update the list.\n */",
      "description": "Check to see if required parameters are set high enough on this server    for various aspects of recovery operation."
    },
    {
      "method_name": "StartupXLOG",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 5383,
      "comment": "/*\n * This must be called ONCE during postmaster or standalone-backend startup\n */",
      "description": "This must be called ONCE during postmaster or standalone-backend startup"
    },
    {
      "method_name": "SwitchIntoArchiveRecovery",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 6187,
      "comment": "/*\n * Callback from PerformWalRecovery(), called when we switch from crash\n * recovery to archive recovery mode.  Updates the control file accordingly.\n */",
      "description": "Callback from PerformWalRecovery(), called when we switch from crash    recovery to archive recovery mode.  Updates the control file accordingly."
    },
    {
      "method_name": "ReachedEndOfBackup",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 6225,
      "comment": "/*\n * Callback from PerformWalRecovery(), called when we reach the end of backup.\n * Updates the control file accordingly.\n */",
      "description": "Callback from PerformWalRecovery(), called when we reach the end of backup.    Updates the control file accordingly."
    },
    {
      "method_name": "PerformRecoveryXLogAction",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 6262,
      "comment": "/*\n * Perform whatever XLOG actions are necessary at end of REDO.\n *\n * The goal here is to make sure that we'll be able to recover properly if\n * we crash again. If we choose to write a checkpoint, we'll write a shutdown\n * checkpoint rather than an on-line one. This is not particularly critical,\n * but since we may be assigning a new TLI, using a shutdown checkpoint allows\n * us to have the rule that TLI only changes in shutdown checkpoints, which\n * allows some extra error checking in xlog_redo.\n */",
      "description": "Perform whatever XLOG actions are necessary at end of REDO."
    },
    {
      "method_name": "RecoveryInProgress",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 6312,
      "comment": "/*\n * Is the system still in recovery?\n *\n * Unlike testing InRecovery, this works in any process that's connected to\n * shared memory.\n */",
      "description": "Is the system still in recovery?       Unlike testing InRecovery, this works in any process that's connected to    shared memory."
    },
    {
      "method_name": "GetRecoveryState",
      "file_path": "backend/access/transam/xlog.c",
      "line_number": 6348,
      "comment": "/*\n * Returns current recovery state from shared memory.\n *\n * This returned state is kept consistent with the contents of the control\n * file.  See details about the possible values of RecoveryState in xlog.h.\n */",
      "description": "Returns current recovery state from shared memory."
    },
    {
      "method_name": "XLogRegisterBlock",
      "file_path": "backend/access/transam/xloginsert.c",
      "line_number": 308,
      "comment": "/*\n * Like XLogRegisterBuffer, but for registering a block that's not in the\n * shared buffer pool (i.e. when you don't have a Buffer for it).\n */",
      "description": "Like XLogRegisterBuffer, but for registering a block that's not in the    shared buffer pool (i.e. when you don't have a Buffer for it)."
    },
    {
      "method_name": "StartupRequestWalReceiverRestart",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4375,
      "comment": "/*\n * Set flag to signal the walreceiver to restart.  (The startup process calls\n * this on noticing a relevant configuration change.)\n */",
      "description": "Set flag to signal the walreceiver to restart.  (The startup process calls    this on noticing a relevant configuration change.)"
    },
    {
      "method_name": "PromoteIsTriggered",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4394,
      "comment": "/*\n * Has a standby promotion already been triggered?\n *\n * Unlike CheckForStandbyTrigger(), this works in any process\n * that's connected to shared memory.\n */",
      "description": "Has a standby promotion already been triggered?       Unlike CheckForStandbyTrigger(), this works in any process    that's connected to shared memory."
    },
    {
      "method_name": "SetPromoteIsTriggered",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4412,
      "comment": "/*\n * Has a standby promotion already been triggered?\n *\n * Unlike CheckForStandbyTrigger(), this works in any process\n * that's connected to shared memory.\n */",
      "description": "Has a standby promotion already been triggered?       Unlike CheckForStandbyTrigger(), this works in any process    that's connected to shared memory."
    },
    {
      "method_name": "CheckForStandbyTrigger",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4433,
      "comment": "/*\n * Check whether a promote request has arrived.\n */",
      "description": "Check whether a promote request has arrived."
    },
    {
      "method_name": "RemovePromoteSignalFiles",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4454,
      "comment": "/*\n * Remove the files signaling a standby promotion request.\n */",
      "description": "Remove the files signaling a standby promotion request."
    },
    {
      "method_name": "CheckPromoteSignal",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4463,
      "comment": "/*\n * Check to see if a promote request has arrived.\n */",
      "description": "Check to see if a promote request has arrived."
    },
    {
      "method_name": "WakeupRecovery",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4478,
      "comment": "/*\n * Wake up startup process to replay newly arrived WAL, or to notice that\n * failover has been requested.\n */",
      "description": "Wake up startup process to replay newly arrived WAL, or to notice that    failover has been requested."
    },
    {
      "method_name": "XLogRequestWalReceiverReply",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4487,
      "comment": "/*\n * Schedule a walreceiver wakeup in the main recovery loop.\n */",
      "description": "Schedule a walreceiver wakeup in the main recovery loop."
    },
    {
      "method_name": "HotStandbyActive",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4502,
      "comment": "/*\n * Is HotStandby active yet? This is only important in special backends\n * since normal backends won't ever be able to connect until this returns\n * true. Postmaster knows this by way of signal, not via shared memory.\n *\n * Unlike testing standbyState, this works in any process that's connected to\n * shared memory.  (And note that standbyState alone doesn't tell the truth\n * anyway.)\n */",
      "description": "Is HotStandby active yet? This is only important in special backends    since normal backends won't ever be able to connect until this returns    true."
    },
    {
      "method_name": "HotStandbyActiveInReplay",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4527,
      "comment": "/*\n * Like HotStandbyActive(), but to be used only in WAL replay code,\n * where we don't need to ask any other process what the state is.\n */",
      "description": "Like HotStandbyActive(), but to be used only in WAL replay code,    where we don't need to ask any other process what the state is."
    },
    {
      "method_name": "GetXLogReplayRecPtr",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4539,
      "comment": "/*\n * Get latest redo apply position.\n *\n * Exported to allow WALReceiver to read the pointer directly.\n */",
      "description": "Get latest redo apply position.       Exported to allow WALReceiver to read the pointer directly."
    },
    {
      "method_name": "GetCurrentReplayRecPtr",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4562,
      "comment": "/*\n * Get position of last applied, or the record being applied.\n *\n * This is different from GetXLogReplayRecPtr() in that if a WAL\n * record is currently being applied, this includes that record.\n */",
      "description": "Get position of last applied, or the record being applied.       This is different from GetXLogReplayRecPtr() in that if a WAL    record is currently being applied, this includes that record."
    },
    {
      "method_name": "SetLatestXTime",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4585,
      "comment": "/*\n * Save timestamp of latest processed commit/abort record.\n *\n * We keep this in XLogRecoveryCtl, not a simple static variable, so that it can be\n * seen by processes other than the startup process.  Note in particular\n * that CreateRestartPoint is executed in the checkpointer.\n */",
      "description": "Save timestamp of latest processed commit/abort record."
    },
    {
      "method_name": "GetLatestXTime",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4596,
      "comment": "/*\n * Fetch timestamp of latest processed commit/abort record.\n */",
      "description": "Fetch timestamp of latest processed commit/abort record."
    },
    {
      "method_name": "SetCurrentChunkStartTime",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4614,
      "comment": "/*\n * Save timestamp of the next chunk of WAL records to apply.\n *\n * We keep this in XLogRecoveryCtl, not a simple static variable, so that it can be\n * seen by all backends.\n */",
      "description": "Save timestamp of the next chunk of WAL records to apply.       We keep this in XLogRecoveryCtl, not a simple static variable, so that it can be    seen by all backends."
    },
    {
      "method_name": "GetCurrentChunkReplayStartTime",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4626,
      "comment": "/*\n * Fetch timestamp of latest processed commit/abort record.\n * Startup process maintains an accurate local copy in XLogReceiptTime\n */",
      "description": "Fetch timestamp of latest processed commit/abort record.    Startup process maintains an accurate local copy in XLogReceiptTime"
    },
    {
      "method_name": "GetXLogReceiptTime",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4642,
      "comment": "/*\n * Returns time of receipt of current chunk of XLOG data, as well as\n * whether it was received from streaming replication or from archives.\n */",
      "description": "Returns time of receipt of current chunk of XLOG data, as well as    whether it was received from streaming replication or from archives."
    },
    {
      "method_name": "RecoveryRequiresIntParameter",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4659,
      "comment": "/*\n * Note that text field supplied is a parameter name and does not require\n * translation\n */",
      "description": "Note that text field supplied is a parameter name and does not require    translation"
    },
    {
      "method_name": "check_primary_slot_name",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4740,
      "comment": "/*\n * GUC check_hook for primary_slot_name\n */",
      "description": "GUC check_hook for primary_slot_name"
    },
    {
      "method_name": "error_multiple_recovery_targets",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4768,
      "comment": "/*\n * Recovery target settings: Only one of the several recovery_target* settings\n * may be set.  Setting a second one results in an error.  The global variable\n * recoveryTarget tracks which kind of recovery target was chosen.  Other\n * variables store the actual target value (for example a string or a xid).\n * The assign functions of the parameters check whether a competing parameter\n * was already set.  But we want to allow setting the same parameter multiple\n * times.  We also want to allow unsetting a parameter and setting a different\n * one, so we unset recoveryTarget when the parameter is set to an empty\n * string.\n *\n * XXX this code is broken by design.  Throwing an error from a GUC assign\n * hook breaks fundamental assumptions of guc.c.  So long as all the variables\n * for which this can happen are PGC_POSTMASTER, the consequences are limited,\n * since we'd just abort postmaster startup anyway.  Nonetheless it's likely\n * that we have odd behaviors such as unexpected GUC ordering dependencies.\n */",
      "description": "Recovery target settings: Only one of the several recovery_target  settings    may be set."
    },
    {
      "method_name": "check_recovery_target",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4781,
      "comment": "/*\n * GUC check_hook for recovery_target\n */",
      "description": "GUC check_hook for recovery_target"
    },
    {
      "method_name": "assign_recovery_target",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4795,
      "comment": "/*\n * GUC assign_hook for recovery_target\n */",
      "description": "GUC assign_hook for recovery_target"
    },
    {
      "method_name": "check_recovery_target_lsn",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4811,
      "comment": "/*\n * GUC check_hook for recovery_target_lsn\n */",
      "description": "GUC check_hook for recovery_target_lsn"
    },
    {
      "method_name": "assign_recovery_target_lsn",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4834,
      "comment": "/*\n * GUC assign_hook for recovery_target_lsn\n */",
      "description": "GUC assign_hook for recovery_target_lsn"
    },
    {
      "method_name": "check_recovery_target_name",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4853,
      "comment": "/*\n * GUC check_hook for recovery_target_name\n */",
      "description": "GUC check_hook for recovery_target_name"
    },
    {
      "method_name": "assign_recovery_target_name",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4869,
      "comment": "/*\n * GUC assign_hook for recovery_target_name\n */",
      "description": "GUC assign_hook for recovery_target_name"
    },
    {
      "method_name": "check_recovery_target_time",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4894,
      "comment": "/*\n * GUC check_hook for recovery_target_time\n *\n * The interpretation of the recovery_target_time string can depend on the\n * time zone setting, so we need to wait until after all GUC processing is\n * done before we can do the final parsing of the string.  This check function\n * only does a parsing pass to catch syntax errors, but we store the string\n * and parse it again when we need to use it.\n */",
      "description": "GUC check_hook for recovery_target_time       The interpretation of the recovery_target_time string can depend on the    time zone setting, so we need to wait until after all GUC processing is    done before we can do the final parsing of the string."
    },
    {
      "method_name": "assign_recovery_target_time",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4949,
      "comment": "/*\n * GUC assign_hook for recovery_target_time\n */",
      "description": "GUC assign_hook for recovery_target_time"
    },
    {
      "method_name": "check_recovery_target_timeline",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4965,
      "comment": "/*\n * GUC check_hook for recovery_target_timeline\n */",
      "description": "GUC check_hook for recovery_target_timeline"
    },
    {
      "method_name": "assign_recovery_target_timeline",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 4998,
      "comment": "/*\n * GUC assign_hook for recovery_target_timeline\n */",
      "description": "GUC assign_hook for recovery_target_timeline"
    },
    {
      "method_name": "check_recovery_target_xid",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 5011,
      "comment": "/*\n * GUC check_hook for recovery_target_xid\n */",
      "description": "GUC check_hook for recovery_target_xid"
    },
    {
      "method_name": "assign_recovery_target_xid",
      "file_path": "backend/access/transam/xlogrecovery.c",
      "line_number": 5034,
      "comment": "/*\n * GUC assign_hook for recovery_target_xid\n */",
      "description": "GUC assign_hook for recovery_target_xid"
    },
    {
      "method_name": "XLogRecGetLen",
      "file_path": "backend/access/transam/xlogstats.c",
      "line_number": 21,
      "comment": "/*\n * Calculate the size of a record, split into !FPI and FPI parts.\n */",
      "description": "Calculate the size of a record, split into !FPI and FPI parts."
    },
    {
      "method_name": "XLogRecStoreStats",
      "file_path": "backend/access/transam/xlogstats.c",
      "line_number": 53,
      "comment": "/*\n * Store per-rmgr and per-record statistics for a given record.\n */",
      "description": "Store per-rmgr and per-record statistics for a given record."
    },
    {
      "method_name": "report_invalid_page",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 85,
      "comment": "/* Report a reference to an invalid page */",
      "description": "Report a reference to an invalid page"
    },
    {
      "method_name": "log_invalid_page",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 101,
      "comment": "/* Log a reference to an invalid page */",
      "description": "Log a reference to an invalid page"
    },
    {
      "method_name": "forget_invalid_pages",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 165,
      "comment": "/* Forget any invalid pages >= minblkno, because they've been dropped */",
      "description": "Forget any invalid pages >= minblkno, because they've been dropped"
    },
    {
      "method_name": "forget_invalid_pages_db",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 201,
      "comment": "/* Forget any invalid pages in a whole database */",
      "description": "Forget any invalid pages in a whole database"
    },
    {
      "method_name": "XLogHaveInvalidPages",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 234,
      "comment": "/* Are there any unresolved references to invalid pages? */",
      "description": "Are there any unresolved references to invalid pages?"
    },
    {
      "method_name": "XLogCheckInvalidPages",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 244,
      "comment": "/* Complain about any remaining invalid-page entries */",
      "description": "Complain about any remaining invalid-page entries"
    },
    {
      "method_name": "XLogReadBufferForRedo",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 313,
      "comment": "/*\n * XLogReadBufferForRedo\n *\t\tRead a page during XLOG replay\n *\n * Reads a block referenced by a WAL record into shared buffer cache, and\n * determines what needs to be done to redo the changes to it.  If the WAL\n * record includes a full-page image of the page, it is restored.\n *\n * 'record.EndRecPtr' is compared to the page's LSN to determine if the record\n * has already been replayed.  'block_id' is the ID number the block was\n * registered with, when the WAL record was created.\n *\n * Returns one of the following:\n *\n *\tBLK_NEEDS_REDO\t- changes from the WAL record need to be applied\n *\tBLK_DONE\t\t- block doesn't need replaying\n *\tBLK_RESTORED\t- block was restored from a full-page image included in\n *\t\t\t\t\t  the record\n *\tBLK_NOTFOUND\t- block was not found (because it was truncated away by\n *\t\t\t\t\t  an operation later in the WAL stream)\n *\n * On return, the buffer is locked in exclusive-mode, and returned in *buf.\n * Note that the buffer is locked and returned even if it doesn't need\n * replaying.  (Getting the buffer lock is not really necessary during\n * single-process crash recovery, but some subroutines such as MarkBufferDirty\n * will complain if we don't have the lock.  In hot standby mode it's\n * definitely necessary.)\n *\n * Note: when a backup block is available in XLOG with the BKPIMAGE_APPLY flag\n * set, we restore it, even if the page in the database appears newer.  This\n * is to protect ourselves against database pages that were partially or\n * incorrectly written during a crash.  We assume that the XLOG data must be\n * good because it has passed a CRC check, while the database page might not\n * be.  This will force us to replay all subsequent modifications of the page\n * that appear in XLOG, rather than possibly ignoring them as already\n * applied, but that's not a huge drawback.\n */",
      "description": "XLogReadBufferForRedo   \t\tRead a page during XLOG replay       Reads a block referenced by a WAL record into shared buffer cache, and    determines what needs to be done to redo the changes to it."
    },
    {
      "method_name": "XLogInitBufferForRedo",
      "file_path": "backend/access/transam/xlogutils.c",
      "line_number": 325,
      "comment": "/*\n * Pin and lock a buffer referenced by a WAL record, for the purpose of\n * re-initializing it.\n */",
      "description": "Pin and lock a buffer referenced by a WAL record, for the purpose of    re-initializing it."
    },
    {
      "method_name": "AppendIncrementalManifestData",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 195,
      "comment": "/*\n * Before taking an incremental backup, the caller must supply the backup\n * manifest from a prior backup. Each chunk of manifest data received\n * from the client should be passed to this function.\n */",
      "description": "Before taking an incremental backup, the caller must supply the backup    manifest from a prior backup. Each chunk of manifest data received    from the client should be passed to this function."
    },
    {
      "method_name": "FinalizeIncrementalManifest",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 228,
      "comment": "/*\n * Finalize an IncrementalBackupInfo object after all manifest data has\n * been supplied via calls to AppendIncrementalManifestData.\n */",
      "description": "Finalize an IncrementalBackupInfo object after all manifest data has    been supplied via calls to AppendIncrementalManifestData."
    },
    {
      "method_name": "PrepareForIncrementalBackup",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 264,
      "comment": "/*\n * Prepare to take an incremental backup.\n *\n * Before this function is called, AppendIncrementalManifestData and\n * FinalizeIncrementalManifest should have already been called to pass all\n * the manifest data to this object.\n *\n * This function performs sanity checks on the data extracted from the\n * manifest and figures out for which WAL ranges we need summaries, and\n * whether those summaries are available. Then, it reads and combines the\n * data from those summary files. It also updates the backup_state with the\n * reference TLI and LSN for the prior backup.\n */",
      "description": "Prepare to take an incremental backup."
    },
    {
      "method_name": "GetIncrementalFilePath",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 626,
      "comment": "/*\n * Get the pathname that should be used when a file is sent incrementally.\n *\n * The result is a palloc'd string.\n */",
      "description": "Get the pathname that should be used when a file is sent incrementally.       The result is a palloc'd string."
    },
    {
      "method_name": "GetFileBackupMethod",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 666,
      "comment": "/*\n * How should we back up a particular file as part of an incremental backup?\n *\n * If the return value is BACK_UP_FILE_FULLY, caller should back up the whole\n * file just as if this were not an incremental backup.  The contents of the\n * relative_block_numbers array are unspecified in this case.\n *\n * If the return value is BACK_UP_FILE_INCREMENTALLY, caller should include\n * an incremental file in the backup instead of the entire file. On return,\n * *num_blocks_required will be set to the number of blocks that need to be\n * sent, and the actual block numbers will have been stored in\n * relative_block_numbers, which should be an array of at least RELSEG_SIZE.\n * In addition, *truncation_block_length will be set to the value that should\n * be included in the incremental file.\n */",
      "description": "How should we back up a particular file as part of an incremental backup?       If the return value is BACK_UP_FILE_FULLY, caller should back up the whole    file just as if this were not an incremental backup."
    },
    {
      "method_name": "GetIncrementalHeaderSize",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 870,
      "comment": "/*\n * Compute the size for a header of an incremental file containing a given\n * number of blocks. The header is rounded to a multiple of BLCKSZ, but\n * only if the file will store some block data.\n */",
      "description": "Compute the size for a header of an incremental file containing a given    number of blocks. The header is rounded to a multiple of BLCKSZ, but    only if the file will store some block data."
    },
    {
      "method_name": "GetIncrementalFileSize",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 898,
      "comment": "/*\n * Compute the size for an incremental file containing a given number of blocks.\n */",
      "description": "Compute the size for an incremental file containing a given number of blocks."
    },
    {
      "method_name": "hash_string_pointer",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 920,
      "comment": "/*\n * Helper function for filemap hash table.\n */",
      "description": "Helper function for filemap hash table."
    },
    {
      "method_name": "manifest_process_version",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 931,
      "comment": "/*\n * This callback to validate the manifest version for incremental backup.\n */",
      "description": "This callback to validate the manifest version for incremental backup."
    },
    {
      "method_name": "manifest_process_system_identifier",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 945,
      "comment": "/*\n * This callback to validate the manifest system identifier against the current\n * database server.\n */",
      "description": "This callback to validate the manifest system identifier against the current    database server."
    },
    {
      "method_name": "manifest_process_file",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 967,
      "comment": "/*\n * This callback is invoked for each file mentioned in the backup manifest.\n *\n * We store the path to each file and the size of each file for sanity-checking\n * purposes. For further details, see comments for IncrementalBackupInfo.\n */",
      "description": "This callback is invoked for each file mentioned in the backup manifest."
    },
    {
      "method_name": "manifest_process_wal_range",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 994,
      "comment": "/*\n * This callback is invoked for each WAL range mentioned in the backup\n * manifest.\n *\n * We're just interested in learning the oldest LSN and the corresponding TLI\n * that appear in any WAL range.\n */",
      "description": "This callback is invoked for each WAL range mentioned in the backup    manifest.       We're just interested in learning the oldest LSN and the corresponding TLI    that appear in any WAL range."
    },
    {
      "method_name": "manifest_report_error",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 1012,
      "comment": "/*\n * This callback is invoked if an error occurs while parsing the backup\n * manifest.\n */",
      "description": "This callback is invoked if an error occurs while parsing the backup    manifest."
    },
    {
      "method_name": "compare_block_numbers",
      "file_path": "backend/backup/basebackup_incremental.c",
      "line_number": 1039,
      "comment": "/*\n * Quicksort comparator for block numbers.\n */",
      "description": "Quicksort comparator for block numbers."
    },
    {
      "method_name": "bbsink_lz4_new",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 61,
      "comment": "/*\n * Create a new basebackup sink that performs lz4 compression.\n */",
      "description": "Create a new basebackup sink that performs lz4 compression."
    },
    {
      "method_name": "bbsink_lz4_begin_backup",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 92,
      "comment": "/*\n * Begin backup.\n */",
      "description": "Begin backup."
    },
    {
      "method_name": "bbsink_lz4_begin_archive",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 131,
      "comment": "/*\n * Prepare to compress the next archive.\n */",
      "description": "Prepare to compress the next archive."
    },
    {
      "method_name": "bbsink_lz4_archive_contents",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 179,
      "comment": "/*\n * Compress the input data to the output buffer until we run out of input\n * data. Each time the output buffer falls below the compression bound for\n * the input buffer, invoke the archive_contents() method for then next sink.\n *\n * Note that since we're compressing the input, it may very commonly happen\n * that we consume all the input data without filling the output buffer. In\n * that case, the compressed representation of the current input data won't\n * actually be sent to the next bbsink until a later call to this function,\n * or perhaps even not until bbsink_lz4_end_archive() is invoked.\n */",
      "description": "Compress the input data to the output buffer until we run out of input    data."
    },
    {
      "method_name": "bbsink_lz4_end_archive",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 227,
      "comment": "/*\n * There might be some data inside lz4's internal buffers; we need to get\n * that flushed out and also finalize the lz4 frame and then get that forwarded\n * to the successor sink as archive content.\n *\n * Then we can end processing for this archive.\n */",
      "description": "There might be some data inside lz4's internal buffers; we need to get    that flushed out and also finalize the lz4 frame and then get that forwarded    to the successor sink as archive content."
    },
    {
      "method_name": "bbsink_lz4_manifest_contents",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 273,
      "comment": "/*\n * Manifest contents are not compressed, but we do need to copy them into\n * the successor sink's buffer, because we have our own.\n */",
      "description": "Manifest contents are not compressed, but we do need to copy them into    the successor sink's buffer, because we have our own."
    },
    {
      "method_name": "bbsink_lz4_cleanup",
      "file_path": "backend/backup/basebackup_lz4.c",
      "line_number": 284,
      "comment": "/*\n * In case the backup fails, make sure we free the compression context by\n * calling LZ4F_freeCompressionContext() if needed to avoid memory leak.\n */",
      "description": "In case the backup fails, make sure we free the compression context by    calling LZ4F_freeCompressionContext() if needed to avoid memory leak."
    },
    {
      "method_name": "bbsink_progress_new",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 58,
      "comment": "/*\n * Create a new basebackup sink that performs progress tracking functions and\n * forwards data to a successor sink.\n */",
      "description": "Create a new basebackup sink that performs progress tracking functions and    forwards data to a successor sink."
    },
    {
      "method_name": "bbsink_progress_begin_backup",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 83,
      "comment": "/*\n * Progress reporting at start of backup.\n */",
      "description": "Progress reporting at start of backup."
    },
    {
      "method_name": "bbsink_progress_end_archive",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 113,
      "comment": "/*\n * End-of archive progress reporting.\n */",
      "description": "End-of archive progress reporting."
    },
    {
      "method_name": "bbsink_progress_archive_contents",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 149,
      "comment": "/*\n * Handle progress tracking for new archive contents.\n *\n * Increment the counter for the amount of data already streamed\n * by the given number of bytes, and update the progress report for\n * pg_stat_progress_basebackup.\n */",
      "description": "Handle progress tracking for new archive contents."
    },
    {
      "method_name": "basebackup_progress_wait_checkpoint",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 185,
      "comment": "/*\n * Advertise that we are waiting for the start-of-backup checkpoint.\n */",
      "description": "Advertise that we are waiting for the start-of-backup checkpoint."
    },
    {
      "method_name": "basebackup_progress_estimate_backup_size",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 195,
      "comment": "/*\n * Advertise that we are estimating the backup size.\n */",
      "description": "Advertise that we are estimating the backup size."
    },
    {
      "method_name": "basebackup_progress_wait_wal_archive",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 205,
      "comment": "/*\n * Advertise that we are waiting for WAL archiving at end-of-backup.\n */",
      "description": "Advertise that we are waiting for WAL archiving at end-of-backup."
    },
    {
      "method_name": "basebackup_progress_transfer_wal",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 228,
      "comment": "/*\n * Advertise that we are transferring WAL files into the final archive.\n */",
      "description": "Advertise that we are transferring WAL files into the final archive."
    },
    {
      "method_name": "basebackup_progress_done",
      "file_path": "backend/backup/basebackup_progress.c",
      "line_number": 238,
      "comment": "/*\n * Advertise that we are no longer performing a backup.\n */",
      "description": "Advertise that we are no longer performing a backup."
    },
    {
      "method_name": "bbsink_server_new",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 59,
      "comment": "/*\n * Create a new 'server' bbsink.\n */",
      "description": "Create a new 'server' bbsink."
    },
    {
      "method_name": "bbsink_server_begin_archive",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 133,
      "comment": "/*\n * Open the correct output file for this archive.\n */",
      "description": "Open the correct output file for this archive."
    },
    {
      "method_name": "bbsink_server_archive_contents",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 159,
      "comment": "/*\n * Write the data to the output file.\n */",
      "description": "Write the data to the output file."
    },
    {
      "method_name": "bbsink_server_end_archive",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 193,
      "comment": "/*\n * fsync and close the current output file.\n */",
      "description": "fsync and close the current output file."
    },
    {
      "method_name": "bbsink_server_begin_manifest",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 227,
      "comment": "/*\n * Open the output file to which we will write the manifest.\n *\n * Just like pg_basebackup, we write the manifest first under a temporary\n * name and then rename it into place after fsync. That way, if the manifest\n * is there and under the correct name, the user can be sure that the backup\n * completed.\n */",
      "description": "Open the output file to which we will write the manifest."
    },
    {
      "method_name": "bbsink_server_manifest_contents",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 252,
      "comment": "/*\n * Each chunk of manifest data is sent using a CopyData message.\n */",
      "description": "Each chunk of manifest data is sent using a CopyData message."
    },
    {
      "method_name": "bbsink_server_end_manifest",
      "file_path": "backend/backup/basebackup_server.c",
      "line_number": 286,
      "comment": "/*\n * fsync the backup manifest, close the file, and then rename it into place.\n */",
      "description": "fsync the backup manifest, close the file, and then rename it into place."
    },
    {
      "method_name": "bbsink_forward_begin_backup",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 23,
      "comment": "/*\n * Forward begin_backup callback.\n *\n * Only use this implementation if you want the bbsink you're implementing to\n * share a buffer with the successor bbsink.\n */",
      "description": "Forward begin_backup callback.       Only use this implementation if you want the bbsink you're implementing to    share a buffer with the successor bbsink."
    },
    {
      "method_name": "bbsink_forward_begin_archive",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 36,
      "comment": "/*\n * Forward begin_archive callback.\n */",
      "description": "Forward begin_archive callback."
    },
    {
      "method_name": "bbsink_forward_archive_contents",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 53,
      "comment": "/*\n * Forward archive_contents callback.\n *\n * Code that wants to use this should initialize its own bbs_buffer and\n * bbs_buffer_length fields to the values from the successor sink. In cases\n * where the buffer isn't shared, the data needs to be copied before forwarding\n * the callback. We don't do try to do that here, because there's really no\n * reason to have separately allocated buffers containing the same identical\n * data.\n */",
      "description": "Forward archive_contents callback."
    },
    {
      "method_name": "bbsink_forward_end_archive",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 65,
      "comment": "/*\n * Forward end_archive callback.\n */",
      "description": "Forward end_archive callback."
    },
    {
      "method_name": "bbsink_forward_begin_manifest",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 75,
      "comment": "/*\n * Forward begin_manifest callback.\n */",
      "description": "Forward begin_manifest callback."
    },
    {
      "method_name": "bbsink_forward_manifest_contents",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 88,
      "comment": "/*\n * Forward manifest_contents callback.\n *\n * As with the archive_contents callback, it's expected that the buffer is\n * shared.\n */",
      "description": "Forward manifest_contents callback.       As with the archive_contents callback, it's expected that the buffer is    shared."
    },
    {
      "method_name": "bbsink_forward_end_manifest",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 100,
      "comment": "/*\n * Forward end_manifest callback.\n */",
      "description": "Forward end_manifest callback."
    },
    {
      "method_name": "bbsink_forward_end_backup",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 110,
      "comment": "/*\n * Forward end_backup callback.\n */",
      "description": "Forward end_backup callback."
    },
    {
      "method_name": "bbsink_forward_cleanup",
      "file_path": "backend/backup/basebackup_sink.c",
      "line_number": 120,
      "comment": "/*\n * Forward cleanup callback.\n */",
      "description": "Forward cleanup callback."
    },
    {
      "method_name": "BaseBackupAddTarget",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 60,
      "comment": "/*\n * Add a new base backup target type.\n *\n * This is intended for use by server extensions.\n */",
      "description": "Add a new base backup target type.       This is intended for use by server extensions."
    },
    {
      "method_name": "BaseBackupGetTargetHandle",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 116,
      "comment": "/*\n * Look up a base backup target and validate the target_detail.\n *\n * Extensions that define new backup targets will probably define a new\n * type of bbsink to match. Validation of the target_detail can be performed\n * either in the check_detail routine called here, or in the bbsink\n * constructor, which will be called from BaseBackupGetSink. It's mostly\n * a matter of taste, but the check_detail function runs somewhat earlier.\n */",
      "description": "Look up a base backup target and validate the target_detail."
    },
    {
      "method_name": "BaseBackupGetSink",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 162,
      "comment": "/*\n * Construct a bbsink that will implement the backup target.\n *\n * The get_sink function does all the real work, so all we have to do here\n * is call it with the correct arguments. Whatever the check_detail function\n * returned is here passed through to the get_sink function. This lets those\n * two functions communicate with each other, if they wish. If not, the\n * check_detail function can simply return the target_detail and let the\n * get_sink function take it from there.\n */",
      "description": "Construct a bbsink that will implement the backup target."
    },
    {
      "method_name": "initialize_target_list",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 171,
      "comment": "/*\n * Load predefined target types into BaseBackupTargetTypeList.\n */",
      "description": "Load predefined target types into BaseBackupTargetTypeList."
    },
    {
      "method_name": "blackhole_get_sink",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 193,
      "comment": "/*\n * Normally, a get_sink function should construct and return a new bbsink that\n * implements the backup target, but the 'blackhole' target just throws the\n * data away. We could implement that by adding a bbsink that does nothing\n * but forward, but it's even cheaper to implement that by not adding a bbsink\n * at all.\n */",
      "description": "Normally, a get_sink function should construct and return a new bbsink that    implements the backup target, but the 'blackhole' target just throws the    data away."
    },
    {
      "method_name": "server_get_sink",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 202,
      "comment": "/*\n * Create a bbsink implementing a server-side backup.\n */",
      "description": "Create a bbsink implementing a server-side backup."
    },
    {
      "method_name": "reject_target_detail",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 212,
      "comment": "/*\n * Implement target-detail checking for a target that does not accept a\n * detail.\n */",
      "description": "Implement target-detail checking for a target that does not accept a    detail."
    },
    {
      "method_name": "server_check_detail",
      "file_path": "backend/backup/basebackup_target.c",
      "line_number": 231,
      "comment": "/*\n * Implement target-detail checking for a server-side backup.\n *\n * target_detail should be the name of the directory to which the backup\n * should be written, but we don't check that here. Rather, that check,\n * as well as the necessary permissions checking, happens in bbsink_server_new.\n */",
      "description": "Implement target-detail checking for a server-side backup."
    },
    {
      "method_name": "bbsink_throttle_new",
      "file_path": "backend/backup/basebackup_throttle.c",
      "line_number": 67,
      "comment": "/*\n * Create a new basebackup sink that performs throttling and forwards data\n * to a successor sink.\n */",
      "description": "Create a new basebackup sink that performs throttling and forwards data    to a successor sink."
    },
    {
      "method_name": "bbsink_throttle_begin_backup",
      "file_path": "backend/backup/basebackup_throttle.c",
      "line_number": 95,
      "comment": "/*\n * There's no real work to do here, but we need to record the current time so\n * that it can be used for future calculations.\n */",
      "description": "There's no real work to do here, but we need to record the current time so    that it can be used for future calculations."
    },
    {
      "method_name": "bbsink_throttle_archive_contents",
      "file_path": "backend/backup/basebackup_throttle.c",
      "line_number": 109,
      "comment": "/*\n * First throttle, and then pass archive contents to next sink.\n */",
      "description": "First throttle, and then pass archive contents to next sink."
    },
    {
      "method_name": "bbsink_throttle_manifest_contents",
      "file_path": "backend/backup/basebackup_throttle.c",
      "line_number": 120,
      "comment": "/*\n * First throttle, and then pass manifest contents to next sink.\n */",
      "description": "First throttle, and then pass manifest contents to next sink."
    },
    {
      "method_name": "throttle",
      "file_path": "backend/backup/basebackup_throttle.c",
      "line_number": 133,
      "comment": "/*\n * Increment the network transfer counter by the given number of bytes,\n * and sleep if necessary to comply with the requested network transfer\n * rate.\n */",
      "description": "Increment the network transfer counter by the given number of bytes,    and sleep if necessary to comply with the requested network transfer    rate."
    },
    {
      "method_name": "bbsink_zstd_new",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 60,
      "comment": "/*\n * Create a new basebackup sink that performs zstd compression.\n */",
      "description": "Create a new basebackup sink that performs zstd compression."
    },
    {
      "method_name": "bbsink_zstd_begin_backup",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 87,
      "comment": "/*\n * Begin backup.\n */",
      "description": "Begin backup."
    },
    {
      "method_name": "bbsink_zstd_begin_archive",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 157,
      "comment": "/*\n * Prepare to compress the next archive.\n */",
      "description": "Prepare to compress the next archive."
    },
    {
      "method_name": "bbsink_zstd_archive_contents",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 192,
      "comment": "/*\n * Compress the input data to the output buffer until we run out of input\n * data. Each time the output buffer falls below the compression bound for\n * the input buffer, invoke the archive_contents() method for the next sink.\n *\n * Note that since we're compressing the input, it may very commonly happen\n * that we consume all the input data without filling the output buffer. In\n * that case, the compressed representation of the current input data won't\n * actually be sent to the next bbsink until a later call to this function,\n * or perhaps even not until bbsink_zstd_end_archive() is invoked.\n */",
      "description": "Compress the input data to the output buffer until we run out of input    data."
    },
    {
      "method_name": "bbsink_zstd_end_archive",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 234,
      "comment": "/*\n * There might be some data inside zstd's internal buffers; we need to get that\n * flushed out, also end the zstd frame and then get that forwarded to the\n * successor sink as archive content.\n *\n * Then we can end processing for this archive.\n */",
      "description": "There might be some data inside zstd's internal buffers; we need to get that    flushed out, also end the zstd frame and then get that forwarded to the    successor sink as archive content."
    },
    {
      "method_name": "bbsink_zstd_end_backup",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 281,
      "comment": "/*\n * Free the resources and context.\n */",
      "description": "Free the resources and context."
    },
    {
      "method_name": "bbsink_zstd_manifest_contents",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 301,
      "comment": "/*\n * Manifest contents are not compressed, but we do need to copy them into\n * the successor sink's buffer, because we have our own.\n */",
      "description": "Manifest contents are not compressed, but we do need to copy them into    the successor sink's buffer, because we have our own."
    },
    {
      "method_name": "bbsink_zstd_cleanup",
      "file_path": "backend/backup/basebackup_zstd.c",
      "line_number": 312,
      "comment": "/*\n * In case the backup fails, make sure we free any compression context that\n * got allocated, so that we don't leak memory.\n */",
      "description": "In case the backup fails, make sure we free any compression context that    got allocated, so that we don't leak memory."
    },
    {
      "method_name": "GetWalSummaries",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 42,
      "comment": "/*\n * Get a list of WAL summaries.\n *\n * If tli != 0, only WAL summaries with the indicated TLI will be included.\n *\n * If start_lsn != InvalidXLogRecPtr, only summaries that end after the\n * indicated LSN will be included.\n *\n * If end_lsn != InvalidXLogRecPtr, only summaries that start before the\n * indicated LSN will be included.\n *\n * The intent is that you can call GetWalSummaries(tli, start_lsn, end_lsn)\n * to get all WAL summaries on the indicated timeline that overlap the\n * specified LSN range.\n */",
      "description": "Get a list of WAL summaries."
    },
    {
      "method_name": "FilterWalSummaries",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 99,
      "comment": "/*\n * Build a new list of WAL summaries based on an existing list, but filtering\n * out summaries that don't match the search parameters.\n *\n * If tli != 0, only WAL summaries with the indicated TLI will be included.\n *\n * If start_lsn != InvalidXLogRecPtr, only summaries that end after the\n * indicated LSN will be included.\n *\n * If end_lsn != InvalidXLogRecPtr, only summaries that start before the\n * indicated LSN will be included.\n */",
      "description": "Build a new list of WAL summaries based on an existing list, but filtering    out summaries that don't match the search parameters."
    },
    {
      "method_name": "WalSummariesAreComplete",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 137,
      "comment": "/*\n * Check whether the supplied list of WalSummaryFile objects covers the\n * whole range of LSNs from start_lsn to end_lsn. This function ignores\n * timelines, so the caller should probably filter using the appropriate\n * timeline before calling this.\n *\n * If the whole range of LSNs is covered, returns true, otherwise false.\n * If false is returned, *missing_lsn is set either to InvalidXLogRecPtr\n * if there are no WAL summary files in the input list, or to the first LSN\n * in the range that is not covered by a WAL summary file in the input list.\n */",
      "description": "Check whether the supplied list of WalSummaryFile objects covers the    whole range of LSNs from start_lsn to end_lsn."
    },
    {
      "method_name": "OpenWalSummaryFile",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 204,
      "comment": "/*\n * Open a WAL summary file.\n *\n * This will throw an error in case of trouble. As an exception, if\n * missing_ok = true and the trouble is specifically that the file does\n * not exist, it will not throw an error and will return a value less than 0.\n */",
      "description": "Open a WAL summary file."
    },
    {
      "method_name": "RemoveWalSummaryIfOlderThan",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 229,
      "comment": "/*\n * Remove a WAL summary file if the last modification time precedes the\n * cutoff time.\n */",
      "description": "Remove a WAL summary file if the last modification time precedes the    cutoff time."
    },
    {
      "method_name": "IsWalSummaryFilename",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 262,
      "comment": "/*\n * Test whether a filename looks like a WAL summary file.\n */",
      "description": "Test whether a filename looks like a WAL summary file."
    },
    {
      "method_name": "ReadWalSummary",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 272,
      "comment": "/*\n * Data read callback for use with CreateBlockRefTableReader.\n */",
      "description": "Data read callback for use with CreateBlockRefTableReader."
    },
    {
      "method_name": "WriteWalSummary",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 293,
      "comment": "/*\n * Data write callback for use with WriteBlockRefTable.\n */",
      "description": "Data write callback for use with WriteBlockRefTable."
    },
    {
      "method_name": "ReportWalSummaryError",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 321,
      "comment": "/*\n * Error-reporting callback for use with CreateBlockRefTableReader.\n */",
      "description": "Error-reporting callback for use with CreateBlockRefTableReader."
    },
    {
      "method_name": "ListComparatorForWalSummaryFiles",
      "file_path": "backend/backup/walsummary.c",
      "line_number": 346,
      "comment": "/*\n * Comparator to sort a List of WalSummaryFile objects by start_lsn.\n */",
      "description": "Comparator to sort a List of WalSummaryFile objects by start_lsn."
    },
    {
      "method_name": "pg_available_wal_summaries",
      "file_path": "backend/backup/walsummaryfuncs.c",
      "line_number": 31,
      "comment": "/*\n * List the WAL summary files available in pg_wal/summaries.\n */",
      "description": "List the WAL summary files available in pg_wal/summaries."
    },
    {
      "method_name": "pg_wal_summary_contents",
      "file_path": "backend/backup/walsummaryfuncs.c",
      "line_number": 68,
      "comment": "/*\n * List the contents of a WAL summary file identified by TLI, start LSN,\n * and end LSN.\n */",
      "description": "List the contents of a WAL summary file identified by TLI, start LSN,    and end LSN."
    },
    {
      "method_name": "pg_get_wal_summarizer_state",
      "file_path": "backend/backup/walsummaryfuncs.c",
      "line_number": 176,
      "comment": "/*\n * Returns information about the state of the WAL summarizer process.\n */",
      "description": "Returns information about the state of the WAL summarizer process."
    },
    {
      "method_name": "ExecGrantStmt_oids",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 601,
      "comment": "/*\n * ExecGrantStmt_oids\n *\n * Internal entry point for granting and revoking privileges.\n */",
      "description": "ExecGrantStmt_oids       Internal entry point for granting and revoking privileges."
    },
    {
      "method_name": "objectNamesToOids",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 668,
      "comment": "/*\n * objectNamesToOids\n *\n * Turn a list of object names of a given type into an Oid list.\n *\n * XXX: This function doesn't take any sort of locks on the objects whose\n * names it looks up.  In the face of concurrent DDL, we might easily latch\n * onto an old version of an object, causing the GRANT or REVOKE statement\n * to fail.\n */",
      "description": "objectNamesToOids       Turn a list of object names of a given type into an Oid list."
    },
    {
      "method_name": "objectsInSchemaToOids",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 848,
      "comment": "/*\n * objectsInSchemaToOids\n *\n * Find all objects of a given type in specified schemas, and make a list\n * of their Oids.  We check USAGE privilege on the schemas, but there is\n * no privilege checking on the individual objects here.\n */",
      "description": "objectsInSchemaToOids       Find all objects of a given type in specified schemas, and make a list    of their Oids."
    },
    {
      "method_name": "getRelationsInNamespace",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 937,
      "comment": "/*\n * getRelationsInNamespace\n *\n * Return Oid list of relations in given namespace filtered by relation kind\n */",
      "description": "getRelationsInNamespace       Return Oid list of relations in given namespace filtered by relation kind"
    },
    {
      "method_name": "ExecAlterDefaultPrivilegesStmt",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 975,
      "comment": "/*\n * ALTER DEFAULT PRIVILEGES statement\n */",
      "description": "ALTER DEFAULT PRIVILEGES statement"
    },
    {
      "method_name": "SetDefaultACLsInSchemas",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1160,
      "comment": "/*\n * Process ALTER DEFAULT PRIVILEGES for a list of target schemas\n *\n * All fields of *iacls except nspid were filled already\n */",
      "description": "Process ALTER DEFAULT PRIVILEGES for a list of target schemas       All fields of  iacls except nspid were filled already"
    },
    {
      "method_name": "SetDefaultACL",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1202,
      "comment": "/*\n * Create or update a pg_default_acl entry\n */",
      "description": "Create or update a pg_default_acl entry"
    },
    {
      "method_name": "RemoveRoleFromObjectACL",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1465,
      "comment": "/*\n * RemoveRoleFromObjectACL\n *\n * Used by shdepDropOwned to remove mentions of a role in ACLs.\n *\n * Notice that this doesn't accept an objsubid parameter, which is a bit bogus\n * since the pg_shdepend record that caused us to call it certainly had one.\n * If, for example, pg_shdepend records the existence of a permission on\n * mytable.mycol, this function will effectively issue a REVOKE ALL ON TABLE\n * mytable.  That gets the job done because (per SQL spec) such a REVOKE also\n * revokes per-column permissions.  We could not recreate a situation where\n * the role has table-level but not column-level permissions; but it's okay\n * (for now anyway) because this is only used when we're dropping the role\n * and so all its permissions everywhere must go away.  At worst it's a bit\n * inefficient if the role has column permissions on several columns of the\n * same table.\n */",
      "description": "RemoveRoleFromObjectACL       Used by shdepDropOwned to remove mentions of a role in ACLs."
    },
    {
      "method_name": "expand_col_privileges",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1600,
      "comment": "/*\n * expand_col_privileges\n *\n * OR the specified privilege(s) into per-column array entries for each\n * specified attribute.  The per-column array is indexed starting at\n * FirstLowInvalidHeapAttributeNumber, up to relation's last attribute.\n */",
      "description": "expand_col_privileges       OR the specified privilege(s) into per-column array entries for each    specified attribute."
    },
    {
      "method_name": "expand_all_col_privileges",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1633,
      "comment": "/*\n * expand_all_col_privileges\n *\n * OR the specified privilege(s) into per-column array entries for each valid\n * attribute of a relation.  The per-column array is indexed starting at\n * FirstLowInvalidHeapAttributeNumber, up to relation's last attribute.\n */",
      "description": "expand_all_col_privileges       OR the specified privilege(s) into per-column array entries for each valid    attribute of a relation."
    },
    {
      "method_name": "ExecGrant_Attribute",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1679,
      "comment": "/*\n *\tThis processes attributes, but expects to be called from\n *\tExecGrant_Relation, not directly from ExecuteGrantStmt.\n */",
      "description": "This processes attributes, but expects to be called from   \tExecGrant_Relation, not directly from ExecuteGrantStmt."
    },
    {
      "method_name": "ExecGrant_Relation",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 1824,
      "comment": "/*\n *\tThis processes both sequences and non-sequences.\n */",
      "description": "This processes both sequences and non-sequences."
    },
    {
      "method_name": "aclcheck_error",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 2704,
      "comment": "/*\n * Standardized reporting of aclcheck permissions failures.\n *\n * Note: we do not double-quote the %s's below, because many callers\n * supply strings that might be already quoted.\n */",
      "description": "Standardized reporting of aclcheck permissions failures.       Note: we do not double-quote the %s's below, because many callers    supply strings that might be already quoted."
    },
    {
      "method_name": "aclcheck_error_type",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3023,
      "comment": "/*\n * Special common handling for types: use element type instead of array type,\n * and format nicely\n */",
      "description": "Special common handling for types: use element type instead of array type,    and format nicely"
    },
    {
      "method_name": "pg_aclmask",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3035,
      "comment": "/*\n * Relay for the various pg_*_mask routines depending on object kind\n */",
      "description": "Relay for the various pg_ _mask routines depending on object kind"
    },
    {
      "method_name": "object_aclmask",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3100,
      "comment": "/*\n * Generic routine for examining a user's privileges for an object\n */",
      "description": "Generic routine for examining a user's privileges for an object"
    },
    {
      "method_name": "object_aclmask_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3111,
      "comment": "/*\n * Generic routine for examining a user's privileges for an object,\n * with is_missing\n */",
      "description": "Generic routine for examining a user's privileges for an object,    with is_missing"
    },
    {
      "method_name": "pg_attribute_aclmask",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3203,
      "comment": "/*\n * Routine for examining a user's privileges for a column\n *\n * Note: this considers only privileges granted specifically on the column.\n * It is caller's responsibility to take relation-level privileges into account\n * as appropriate.  (For the same reason, we have no special case for\n * superuser-ness here.)\n */",
      "description": "Routine for examining a user's privileges for a column       Note: this considers only privileges granted specifically on the column."
    },
    {
      "method_name": "pg_attribute_aclmask_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3214,
      "comment": "/*\n * Routine for examining a user's privileges for a column, with is_missing\n */",
      "description": "Routine for examining a user's privileges for a column, with is_missing"
    },
    {
      "method_name": "pg_class_aclmask",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3328,
      "comment": "/*\n * Exported routine for examining a user's privileges for a table\n */",
      "description": "Exported routine for examining a user's privileges for a table"
    },
    {
      "method_name": "pg_class_aclmask_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3338,
      "comment": "/*\n * Routine for examining a user's privileges for a table, with is_missing\n */",
      "description": "Routine for examining a user's privileges for a table, with is_missing"
    },
    {
      "method_name": "pg_parameter_aclmask",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3468,
      "comment": "/*\n * Routine for examining a user's privileges for a configuration\n * parameter (GUC), identified by GUC name.\n */",
      "description": "Routine for examining a user's privileges for a configuration    parameter (GUC), identified by GUC name."
    },
    {
      "method_name": "pg_parameter_acl_aclmask",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3532,
      "comment": "/*\n * Routine for examining a user's privileges for a configuration\n * parameter (GUC), identified by the OID of its pg_parameter_acl entry.\n */",
      "description": "Routine for examining a user's privileges for a configuration    parameter (GUC), identified by the OID of its pg_parameter_acl entry."
    },
    {
      "method_name": "pg_largeobject_aclmask_snapshot",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3591,
      "comment": "/*\n * Routine for examining a user's privileges for a largeobject\n *\n * When a large object is opened for reading, it is opened relative to the\n * caller's snapshot, but when it is opened for writing, a current\n * MVCC snapshot will be used.  See doc/src/sgml/lobj.sgml.  This function\n * takes a snapshot argument so that the permissions check can be made\n * relative to the same snapshot that will be used to read the underlying\n * data.  The caller will actually pass NULL for an instantaneous MVCC\n * snapshot, since all we do with the snapshot argument is pass it through\n * to systable_beginscan().\n */",
      "description": "Routine for examining a user's privileges for a largeobject       When a large object is opened for reading, it is opened relative to the    caller's snapshot, but when it is opened for writing, a current    MVCC snapshot will be used."
    },
    {
      "method_name": "pg_namespace_aclmask_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3664,
      "comment": "/*\n * Routine for examining a user's privileges for a namespace, with is_missing\n */",
      "description": "Routine for examining a user's privileges for a namespace, with is_missing"
    },
    {
      "method_name": "pg_type_aclmask_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3766,
      "comment": "/*\n * Routine for examining a user's privileges for a type, with is_missing\n */",
      "description": "Routine for examining a user's privileges for a type, with is_missing"
    },
    {
      "method_name": "object_aclcheck",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3892,
      "comment": "/*\n * Exported generic routine for checking a user's access privileges to an object\n */",
      "description": "Exported generic routine for checking a user's access privileges to an object"
    },
    {
      "method_name": "object_aclcheck_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3902,
      "comment": "/*\n * Exported generic routine for checking a user's access privileges to an\n * object, with is_missing\n */",
      "description": "Exported generic routine for checking a user's access privileges to an    object, with is_missing"
    },
    {
      "method_name": "pg_attribute_aclcheck",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3924,
      "comment": "/*\n * Exported routine for checking a user's access privileges to a column\n *\n * Returns ACLCHECK_OK if the user has any of the privileges identified by\n * 'mode'; otherwise returns a suitable error code (in practice, always\n * ACLCHECK_NO_PRIV).\n *\n * As with pg_attribute_aclmask, only privileges granted directly on the\n * column are considered here.\n */",
      "description": "Exported routine for checking a user's access privileges to a column       Returns ACLCHECK_OK if the user has any of the privileges identified by    'mode'; otherwise returns a suitable error code (in practice, always    ACLCHECK_NO_PRIV)."
    },
    {
      "method_name": "pg_attribute_aclcheck_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3936,
      "comment": "/*\n * Exported routine for checking a user's access privileges to a column,\n * with is_missing\n */",
      "description": "Exported routine for checking a user's access privileges to a column,    with is_missing"
    },
    {
      "method_name": "pg_attribute_aclcheck_all",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3966,
      "comment": "/*\n * Exported routine for checking a user's access privileges to any/all columns\n *\n * If 'how' is ACLMASK_ANY, then returns ACLCHECK_OK if user has any of the\n * privileges identified by 'mode' on any non-dropped column in the relation;\n * otherwise returns a suitable error code (in practice, always\n * ACLCHECK_NO_PRIV).\n *\n * If 'how' is ACLMASK_ALL, then returns ACLCHECK_OK if user has any of the\n * privileges identified by 'mode' on each non-dropped column in the relation\n * (and there must be at least one such column); otherwise returns a suitable\n * error code (in practice, always ACLCHECK_NO_PRIV).\n *\n * As with pg_attribute_aclmask, only privileges granted directly on the\n * column(s) are considered here.\n *\n * Note: system columns are not considered here; there are cases where that\n * might be appropriate but there are also cases where it wouldn't.\n */",
      "description": "Exported routine for checking a user's access privileges to any/all columns       If 'how' is ACLMASK_ANY, then returns ACLCHECK_OK if user has any of the    privileges identified by 'mode' on any non-dropped column in the relation;    otherwise returns a suitable error code (in practice, always    ACLCHECK_NO_PRIV)."
    },
    {
      "method_name": "pg_attribute_aclcheck_all_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 3977,
      "comment": "/*\n * Exported routine for checking a user's access privileges to any/all columns,\n * with is_missing\n */",
      "description": "Exported routine for checking a user's access privileges to any/all columns,    with is_missing"
    },
    {
      "method_name": "pg_class_aclcheck",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4095,
      "comment": "/*\n * Exported routine for checking a user's access privileges to a table\n *\n * Returns ACLCHECK_OK if the user has any of the privileges identified by\n * 'mode'; otherwise returns a suitable error code (in practice, always\n * ACLCHECK_NO_PRIV).\n */",
      "description": "Exported routine for checking a user's access privileges to a table       Returns ACLCHECK_OK if the user has any of the privileges identified by    'mode'; otherwise returns a suitable error code (in practice, always    ACLCHECK_NO_PRIV).."
    },
    {
      "method_name": "pg_class_aclcheck_ext",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4105,
      "comment": "/*\n * Exported routine for checking a user's access privileges to a table,\n * with is_missing\n */",
      "description": "Exported routine for checking a user's access privileges to a table,    with is_missing"
    },
    {
      "method_name": "pg_parameter_aclcheck",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4120,
      "comment": "/*\n * Exported routine for checking a user's access privileges to a configuration\n * parameter (GUC), identified by GUC name.\n */",
      "description": "Exported routine for checking a user's access privileges to a configuration    parameter (GUC), identified by GUC name."
    },
    {
      "method_name": "pg_largeobject_aclcheck_snapshot",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4132,
      "comment": "/*\n * Exported routine for checking a user's access privileges to a largeobject\n */",
      "description": "Exported routine for checking a user's access privileges to a largeobject"
    },
    {
      "method_name": "object_ownercheck",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4146,
      "comment": "/*\n * Generic ownership check for an object\n */",
      "description": "Generic ownership check for an object"
    },
    {
      "method_name": "has_createrole_privilege",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4227,
      "comment": "/*\n * Check whether specified role has CREATEROLE privilege (or is a superuser)\n *\n * Note: roles do not have owners per se; instead we use this test in\n * places where an ownership-like permissions test is needed for a role.\n * Be sure to apply it to the role trying to do the operation, not the\n * role being operated on!\tAlso note that this generally should not be\n * considered enough privilege if the target role is a superuser.\n * (We don't handle that consideration here because we want to give a\n * separate error message for such cases, so the caller has to deal with it.)\n */",
      "description": "Check whether specified role has CREATEROLE privilege (or is a superuser)       Note: roles do not have owners per se; instead we use this test in    places where an ownership-like permissions test is needed for a role."
    },
    {
      "method_name": "has_bypassrls_privilege",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4246,
      "comment": "/*\n * Check whether specified role has CREATEROLE privilege (or is a superuser)\n *\n * Note: roles do not have owners per se; instead we use this test in\n * places where an ownership-like permissions test is needed for a role.\n * Be sure to apply it to the role trying to do the operation, not the\n * role being operated on!\tAlso note that this generally should not be\n * considered enough privilege if the target role is a superuser.\n * (We don't handle that consideration here because we want to give a\n * separate error message for such cases, so the caller has to deal with it.)\n */",
      "description": "Check whether specified role has CREATEROLE privilege (or is a superuser)       Note: roles do not have owners per se; instead we use this test in    places where an ownership-like permissions test is needed for a role."
    },
    {
      "method_name": "get_default_acl_internal",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4270,
      "comment": "/*\n * Fetch pg_default_acl entry for given role, namespace and object type\n * (object type must be given in pg_default_acl's encoding).\n * Returns NULL if no such entry.\n */",
      "description": "Fetch pg_default_acl entry for given role, namespace and object type    (object type must be given in pg_default_acl's encoding).    Returns NULL if no such entry."
    },
    {
      "method_name": "get_user_default_acl",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4305,
      "comment": "/*\n * Get default permissions for newly created object within given schema\n *\n * Returns NULL if built-in system defaults should be used.\n *\n * If the result is not NULL, caller must call recordDependencyOnNewAcl\n * once the OID of the new object is known.\n */",
      "description": "Get default permissions for newly created object within given schema       Returns NULL if built-in system defaults should be used."
    },
    {
      "method_name": "recordDependencyOnNewAcl",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4381,
      "comment": "/*\n * Record dependencies on roles mentioned in a new object's ACL.\n */",
      "description": "Record dependencies on roles mentioned in a new object's ACL."
    },
    {
      "method_name": "recordExtObjInitPriv",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4408,
      "comment": "/*\n * Record initial privileges for the top-level object passed in.\n *\n * For the object passed in, this will record its ACL (if any) and the ACLs of\n * any sub-objects (eg: columns) into pg_init_privs.\n */",
      "description": "Record initial privileges for the top-level object passed in.       For the object passed in, this will record its ACL (if any) and the ACLs of    any sub-objects (eg: columns) into pg_init_privs."
    },
    {
      "method_name": "removeExtObjInitPriv",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4572,
      "comment": "/*\n * For the object passed in, remove its ACL and the ACLs of any object subIds\n * from pg_init_privs (via recordExtensionInitPrivWorker()).\n */",
      "description": "For the object passed in, remove its ACL and the ACLs of any object subIds    from pg_init_privs (via recordExtensionInitPrivWorker())."
    },
    {
      "method_name": "recordExtensionInitPriv",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4655,
      "comment": "/*\n * Record initial ACL for an extension object\n *\n * Can be called at any time, we check if 'creating_extension' is set and, if\n * not, exit immediately.\n *\n * Pass in the object OID, the OID of the class (the OID of the table which\n * the object is defined in) and the 'sub' id of the object (objsubid), if\n * any.  If there is no 'sub' id (they are currently only used for columns of\n * tables) then pass in '0'.  Finally, pass in the complete ACL to store.\n *\n * If an ACL already exists for this object/sub-object then we will replace\n * it with what is passed in.\n *\n * Passing in NULL for 'new_acl' will result in the entry for the object being\n * removed, if one is found.\n */",
      "description": "Record initial ACL for an extension object       Can be called at any time, we check if 'creating_extension' is set and, if    not, exit immediately."
    },
    {
      "method_name": "recordExtensionInitPrivWorker",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4684,
      "comment": "/*\n * Record initial ACL for an extension object, worker.\n *\n * This will perform a wholesale replacement of the entire ACL for the object\n * passed in, therefore be sure to pass in the complete new ACL to use.\n *\n * Generally speaking, do *not* use this function directly but instead use\n * recordExtensionInitPriv(), which checks if 'creating_extension' is set.\n * This function does *not* check if 'creating_extension' is set as it is also\n * used when an object is added to or removed from an extension via ALTER\n * EXTENSION ... ADD/DROP.\n */",
      "description": "Record initial ACL for an extension object, worker."
    },
    {
      "method_name": "ReplaceRoleInInitPriv",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4812,
      "comment": "/*\n * ReplaceRoleInInitPriv\n *\n * Used by shdepReassignOwned to replace mentions of a role in pg_init_privs.\n */",
      "description": "ReplaceRoleInInitPriv       Used by shdepReassignOwned to replace mentions of a role in pg_init_privs."
    },
    {
      "method_name": "RemoveRoleFromInitPriv",
      "file_path": "backend/catalog/aclchk.c",
      "line_number": 4921,
      "comment": "/*\n * RemoveRoleFromInitPriv\n *\n * Used by shdepDropOwned to remove mentions of a role in pg_init_privs.\n */",
      "description": "RemoveRoleFromInitPriv       Used by shdepDropOwned to remove mentions of a role in pg_init_privs."
    },
    {
      "method_name": "AddNewRelationTuple",
      "file_path": "backend/catalog/heap.c",
      "line_number": 968,
      "comment": "/* --------------------------------\n *\t\tAddNewRelationTuple\n *\n *\t\tthis registers the new relation in the catalogs by\n *\t\tadding a tuple to pg_class.\n * --------------------------------\n */",
      "description": "--------------------------------   \t\tAddNewRelationTuple      \t\tthis registers the new relation in the catalogs by   \t\tadding a tuple to pg_class.    --------------------------------"
    },
    {
      "method_name": "AddNewRelationType",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1026,
      "comment": "/* --------------------------------\n *\t\tAddNewRelationType -\n *\n *\t\tdefine a composite type corresponding to the new relation\n * --------------------------------\n */",
      "description": "--------------------------------   \t\tAddNewRelationType -      \t\tdefine a composite type corresponding to the new relation    --------------------------------"
    },
    {
      "method_name": "heap_create_with_catalog",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1104,
      "comment": "/* --------------------------------\n *\t\theap_create_with_catalog\n *\n *\t\tcreates a new cataloged relation.  see comments above.\n *\n * Arguments:\n *\trelname: name to give to new rel\n *\trelnamespace: OID of namespace it goes in\n *\treltablespace: OID of tablespace it goes in\n *\trelid: OID to assign to new rel, or InvalidOid to select a new OID\n *\treltypeid: OID to assign to rel's rowtype, or InvalidOid to select one\n *\treloftypeid: if a typed table, OID of underlying type; else InvalidOid\n *\townerid: OID of new rel's owner\n *\taccessmtd: OID of new rel's access method\n *\ttupdesc: tuple descriptor (source of column definitions)\n *\tcooked_constraints: list of precooked check constraints and defaults\n *\trelkind: relkind for new rel\n *\trelpersistence: rel's persistence status (permanent, temp, or unlogged)\n *\tshared_relation: true if it's to be a shared relation\n *\tmapped_relation: true if the relation will use the relfilenumber map\n *\toncommit: ON COMMIT marking (only relevant if it's a temp table)\n *\treloptions: reloptions in Datum form, or (Datum) 0 if none\n *\tuse_user_acl: true if should look for user-defined default permissions;\n *\t\tif false, relacl is always set NULL\n *\tallow_system_table_mods: true to allow creation in system namespaces\n *\tis_internal: is this a system-generated catalog?\n *\n * Output parameters:\n *\ttypaddress: if not null, gets the object address of the new pg_type entry\n *\t(this must be null if the relkind is one that doesn't get a pg_type entry)\n *\n * Returns the OID of the new relation\n * --------------------------------\n */",
      "description": "--------------------------------   \t\theap_create_with_catalog      \t\tcreates a new cataloged relation."
    },
    {
      "method_name": "RelationRemoveInheritance",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1525,
      "comment": "/*\n *\t\tRelationRemoveInheritance\n *\n * Formerly, this routine checked for child relations and aborted the\n * deletion if any were found.  Now we rely on the dependency mechanism\n * to check for or delete child relations.  By the time we get here,\n * there are no children and we need only remove any pg_inherits rows\n * linking this relation to its parent(s).\n */",
      "description": "RelationRemoveInheritance       Formerly, this routine checked for child relations and aborted the    deletion if any were found."
    },
    {
      "method_name": "DeleteRelationTuple",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1558,
      "comment": "/*\n *\t\tDeleteRelationTuple\n *\n * Remove pg_class row for the given relid.\n *\n * Note: this is shared by relation deletion and index deletion.  It's\n * not intended for use anyplace else.\n */",
      "description": "DeleteRelationTuple       Remove pg_class row for the given relid.       Note: this is shared by relation deletion and index deletion.  It's    not intended for use anyplace else."
    },
    {
      "method_name": "DeleteAttributeTuples",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1587,
      "comment": "/*\n *\t\tDeleteAttributeTuples\n *\n * Remove pg_attribute rows for the given relid.\n *\n * Note: this is shared by relation deletion and index deletion.  It's\n * not intended for use anyplace else.\n */",
      "description": "DeleteAttributeTuples       Remove pg_attribute rows for the given relid.       Note: this is shared by relation deletion and index deletion.  It's    not intended for use anyplace else."
    },
    {
      "method_name": "DeleteSystemAttributeTuples",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1624,
      "comment": "/*\n *\t\tDeleteSystemAttributeTuples\n *\n * Remove pg_attribute rows for system columns of the given relid.\n *\n * Note: this is only used when converting a table to a view.  Views don't\n * have system columns, so we should remove them from pg_attribute.\n */",
      "description": "DeleteSystemAttributeTuples       Remove pg_attribute rows for system columns of the given relid."
    },
    {
      "method_name": "RemoveAttributeById",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1665,
      "comment": "/*\n *\t\tRemoveAttributeById\n *\n * This is the guts of ALTER TABLE DROP COLUMN: actually mark the attribute\n * deleted in pg_attribute.  We also remove pg_statistic entries for it.\n * (Everything else needed, such as getting rid of any pg_attrdef entry,\n * is handled by dependency.c.)\n */",
      "description": "RemoveAttributeById       This is the guts of ALTER TABLE DROP COLUMN: actually mark the attribute    deleted in pg_attribute."
    },
    {
      "method_name": "heap_drop_with_catalog",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1766,
      "comment": "/*\n * heap_drop_with_catalog\t- removes specified relation from catalogs\n *\n * Note that this routine is not responsible for dropping objects that are\n * linked to the pg_class entry via dependencies (for example, indexes and\n * constraints).  Those are deleted by the dependency-tracing logic in\n * dependency.c before control gets here.  In general, therefore, this routine\n * should never be called directly; go through performDeletion() instead.\n */",
      "description": "heap_drop_with_catalog\t- removes specified relation from catalogs       Note that this routine is not responsible for dropping objects that are    linked to the pg_class entry via dependencies (for example, indexes and    constraints)."
    },
    {
      "method_name": "RelationClearMissing",
      "file_path": "backend/catalog/heap.c",
      "line_number": 1946,
      "comment": "/*\n * RelationClearMissing\n *\n * Set atthasmissing and attmissingval to false/null for all attributes\n * where they are currently set. This can be safely and usefully done if\n * the table is rewritten (e.g. by VACUUM FULL or CLUSTER) where we know there\n * are no rows left with less than a full complement of attributes.\n *\n * The caller must have an AccessExclusive lock on the relation.\n */",
      "description": "RelationClearMissing       Set atthasmissing and attmissingval to false/null for all attributes    where they are currently set."
    },
    {
      "method_name": "StoreAttrMissingVal",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2012,
      "comment": "/*\n * StoreAttrMissingVal\n *\n * Set the missing value of a single attribute.\n */",
      "description": "StoreAttrMissingVal       Set the missing value of a single attribute."
    },
    {
      "method_name": "SetAttrMissing",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2068,
      "comment": "/*\n * SetAttrMissing\n *\n * Set the missing value of a single attribute. This should only be used by\n * binary upgrade. Takes an AccessExclusive lock on the relation owning the\n * attribute.\n */",
      "description": "SetAttrMissing       Set the missing value of a single attribute. This should only be used by    binary upgrade. Takes an AccessExclusive lock on the relation owning the    attribute."
    },
    {
      "method_name": "StoreRelCheck",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2129,
      "comment": "/*\n * Store a check-constraint expression for the given relation.\n *\n * Caller is responsible for updating the count of constraints\n * in the pg_class entry for the relation.\n *\n * The OID of the new constraint is returned.\n */",
      "description": "Store a check-constraint expression for the given relation."
    },
    {
      "method_name": "StoreConstraints",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2239,
      "comment": "/*\n * Store defaults and constraints (passed as a list of CookedConstraint).\n *\n * Each CookedConstraint struct is modified to store the new catalog tuple OID.\n *\n * NOTE: only pre-cooked expressions will be passed this way, which is to\n * say expressions inherited from an existing relation.  Newly parsed\n * expressions can be added later, by direct calls to StoreAttrDefault\n * and StoreRelCheck (see AddRelationNewConstraints()).\n */",
      "description": "Store defaults and constraints (passed as a list of CookedConstraint)."
    },
    {
      "method_name": "AddRelationNewConstraints",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2313,
      "comment": "/*\n * AddRelationNewConstraints\n *\n * Add new column default expressions and/or constraint check expressions\n * to an existing relation.  This is defined to do both for efficiency in\n * DefineRelation, but of course you can do just one or the other by passing\n * empty lists.\n *\n * rel: relation to be modified\n * newColDefaults: list of RawColumnDefault structures\n * newConstraints: list of Constraint nodes\n * allow_merge: true if check constraints may be merged with existing ones\n * is_local: true if definition is local, false if it's inherited\n * is_internal: true if result of some internal process, not a user request\n * queryString: used during expression transformation of default values and\n *\t\tcooked CHECK constraints\n *\n * All entries in newColDefaults will be processed.  Entries in newConstraints\n * will be processed only if they are CONSTR_CHECK type.\n *\n * Returns a list of CookedConstraint nodes that shows the cooked form of\n * the default and constraint expressions added to the relation.\n *\n * NB: caller should have opened rel with some self-conflicting lock mode,\n * and should hold that lock till end of transaction; for normal cases that'll\n * be AccessExclusiveLock, but if caller knows that the constraint is already\n * enforced by some other means, it can be ShareUpdateExclusiveLock.  Also, we\n * assume the caller has done a CommandCounterIncrement if necessary to make\n * the relation's catalog tuples visible.\n */",
      "description": "AddRelationNewConstraints       Add new column default expressions and/or constraint check expressions    to an existing relation."
    },
    {
      "method_name": "MergeWithExistingConstraint",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2556,
      "comment": "/*\n * Check for a pre-existing check constraint that conflicts with a proposed\n * new one, and either adjust its conislocal/coninhcount settings or throw\n * error as needed.\n *\n * Returns true if merged (constraint is a duplicate), or false if it's\n * got a so-far-unique name, or throws error if conflict.\n *\n * XXX See MergeConstraintsIntoExisting too if you change this code.\n */",
      "description": "Check for a pre-existing check constraint that conflicts with a proposed    new one, and either adjust its conislocal/coninhcount settings or throw    error as needed."
    },
    {
      "method_name": "SetRelationNumChecks",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2711,
      "comment": "/*\n * Update the count of constraints in the relation's pg_class tuple.\n *\n * Caller had better hold exclusive lock on the relation.\n *\n * An important side effect is that a SI update message will be sent out for\n * the pg_class tuple, which will force other backends to rebuild their\n * relcache entries for the rel.  Also, this backend will rebuild its\n * own relcache entry at the next CommandCounterIncrement.\n */",
      "description": "Update the count of constraints in the relation's pg_class tuple."
    },
    {
      "method_name": "check_nested_generated_walker",
      "file_path": "backend/catalog/heap.c",
      "line_number": 2745,
      "comment": "/*\n * Check for references to generated columns\n */",
      "description": "Check for references to generated columns"
    },
    {
      "method_name": "get_object_address_defacl",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 1957,
      "comment": "/*\n * Find the ObjectAddress for a default ACL.\n */",
      "description": "Find the ObjectAddress for a default ACL."
    },
    {
      "method_name": "textarray_to_strvaluelist",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2073,
      "comment": "/*\n * Convert an array of TEXT into a List of string Values, as emitted by the\n * parser, which is what get_object_address uses as input.\n */",
      "description": "Convert an array of TEXT into a List of string Values, as emitted by the    parser, which is what get_object_address uses as input."
    },
    {
      "method_name": "pg_get_object_address",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2099,
      "comment": "/*\n * SQL-callable version of get_object_address\n */",
      "description": "SQL-callable version of get_object_address"
    },
    {
      "method_name": "check_object_ownership",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2381,
      "comment": "/*\n * Check ownership of an object previously identified by get_object_address.\n */",
      "description": "Check ownership of an object previously identified by get_object_address."
    },
    {
      "method_name": "get_object_namespace",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2563,
      "comment": "/*\n * get_object_namespace\n *\n * Find the schema containing the specified object.  For non-schema objects,\n * this function returns InvalidOid.\n */",
      "description": "get_object_namespace       Find the schema containing the specified object.  For non-schema objects,    this function returns InvalidOid."
    },
    {
      "method_name": "read_objtype_from_string",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2599,
      "comment": "/*\n * Return ObjectType for the given object type as given by\n * getObjectTypeDescription; if no valid ObjectType code exists, but it's a\n * possible output type from getObjectTypeDescription, return -1.\n * Otherwise, an error is thrown.\n */",
      "description": "Return ObjectType for the given object type as given by    getObjectTypeDescription; if no valid ObjectType code exists, but it's a    possible output type from getObjectTypeDescription, return -1."
    },
    {
      "method_name": "get_object_class_descr",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2619,
      "comment": "/*\n * Interfaces to reference fields of ObjectPropertyType\n */",
      "description": "Interfaces to reference fields of ObjectPropertyType"
    },
    {
      "method_name": "get_object_oid_index",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2627,
      "comment": "/*\n * Interfaces to reference fields of ObjectPropertyType\n */",
      "description": "Interfaces to reference fields of ObjectPropertyType"
    },
    {
      "method_name": "get_object_catcache_oid",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2635,
      "comment": "/*\n * Interfaces to reference fields of ObjectPropertyType\n */",
      "description": "Interfaces to reference fields of ObjectPropertyType"
    },
    {
      "method_name": "get_object_catcache_name",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2643,
      "comment": "/*\n * Interfaces to reference fields of ObjectPropertyType\n */",
      "description": "Interfaces to reference fields of ObjectPropertyType"
    },
    {
      "method_name": "get_object_type",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2698,
      "comment": "/*\n * get_object_type\n *\n * Return the object type associated with a given object.  This routine\n * is primarily used to determine the object type to mention in ACL check\n * error messages, so it's desirable for it to avoid failing.\n */",
      "description": "get_object_type       Return the object type associated with a given object."
    },
    {
      "method_name": "get_object_namensp_unique",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2716,
      "comment": "/*\n * get_object_type\n *\n * Return the object type associated with a given object.  This routine\n * is primarily used to determine the object type to mention in ACL check\n * error messages, so it's desirable for it to avoid failing.\n */",
      "description": "get_object_type       Return the object type associated with a given object."
    },
    {
      "method_name": "is_objectclass_supported",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2728,
      "comment": "/*\n * Return whether we have useful data for the given object class in the\n * ObjectProperty table.\n */",
      "description": "Return whether we have useful data for the given object class in the    ObjectProperty table."
    },
    {
      "method_name": "get_object_property_data",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2745,
      "comment": "/*\n * Find ObjectProperty structure by class_id.\n */",
      "description": "Find ObjectProperty structure by class_id."
    },
    {
      "method_name": "get_catalog_object_by_oid",
      "file_path": "backend/catalog/objectaddress.c",
      "line_number": 2780,
      "comment": "/*\n * Return a copy of the tuple for the object with the given object OID, from\n * the given catalog (which must have been opened by the caller and suitably\n * locked).  NULL is returned if the OID is not found.\n *\n * We try a syscache first, if available.\n */",
      "description": "Return a copy of the tuple for the object with the given object OID, from    the given catalog (which must have been opened by the caller and suitably    locked)."
    },
    {
      "method_name": "EnumUncommitted",
      "file_path": "backend/catalog/pg_enum.c",
      "line_number": 707,
      "comment": "/*\n * Test if the given enum value is in the table of uncommitted enum values.\n */",
      "description": "Test if the given enum value is in the table of uncommitted enum values."
    },
    {
      "method_name": "AtEOXact_Enum",
      "file_path": "backend/catalog/pg_enum.c",
      "line_number": 725,
      "comment": "/*\n * Clean up enum stuff after end of top-level transaction.\n */",
      "description": "Clean up enum stuff after end of top-level transaction."
    },
    {
      "method_name": "RenumberEnumType",
      "file_path": "backend/catalog/pg_enum.c",
      "line_number": 760,
      "comment": "/*\n * RenumberEnumType\n *\t\tRenumber existing enum elements to have sort positions 1..n.\n *\n * We avoid doing this unless absolutely necessary; in most installations\n * it will never happen.  The reason is that updating existing pg_enum\n * entries creates hazards for other backends that are concurrently reading\n * pg_enum.  Although system catalog scans now use MVCC semantics, the\n * syscache machinery might read different pg_enum entries under different\n * snapshots, so some other backend might get confused about the proper\n * ordering if a concurrent renumbering occurs.\n *\n * We therefore make the following choices:\n *\n * 1. Any code that is interested in the enumsortorder values MUST read\n * all the relevant pg_enum entries with a single MVCC snapshot, or else\n * acquire lock on the enum type to prevent concurrent execution of\n * AddEnumLabel().\n *\n * 2. Code that is not examining enumsortorder can use a syscache\n * (for example, enum_in and enum_out do so).\n */",
      "description": "RenumberEnumType   \t\tRenumber existing enum elements to have sort positions 1..n."
    },
    {
      "method_name": "sort_order_cmp",
      "file_path": "backend/catalog/pg_enum.c",
      "line_number": 796,
      "comment": "/* qsort comparison function for tuples by sort order */",
      "description": "qsort comparison function for tuples by sort order"
    },
    {
      "method_name": "EstimateUncommittedEnumsSpace",
      "file_path": "backend/catalog/pg_enum.c",
      "line_number": 812,
      "comment": "/* qsort comparison function for tuples by sort order */",
      "description": "qsort comparison function for tuples by sort order"
    },
    {
      "method_name": "SerializeUncommittedEnums",
      "file_path": "backend/catalog/pg_enum.c",
      "line_number": 826,
      "comment": "/* qsort comparison function for tuples by sort order */",
      "description": "qsort comparison function for tuples by sort order"
    },
    {
      "method_name": "find_inheritance_children",
      "file_path": "backend/catalog/pg_inherits.c",
      "line_number": 57,
      "comment": "/*\n * find_inheritance_children\n *\n * Returns a list containing the OIDs of all relations which\n * inherit *directly* from the relation with OID 'parentrelId'.\n *\n * The specified lock type is acquired on each child relation (but not on the\n * given rel; caller should already have locked it).  If lockmode is NoLock\n * then no locks are acquired, but caller must beware of race conditions\n * against possible DROPs of child relations.\n *\n * Partitions marked as being detached are omitted; see\n * find_inheritance_children_extended for details.\n */",
      "description": "find_inheritance_children       Returns a list containing the OIDs of all relations which    inherit  directly  from the relation with OID 'parentrelId'."
    },
    {
      "method_name": "HasSubscriptionRelations",
      "file_path": "backend/catalog/pg_subscription.c",
      "line_number": 490,
      "comment": "/*\n * Does the subscription have any relations?\n *\n * Use this function only to know true/false, and when you have no need for the\n * List returned by GetSubscriptionRelations.\n */",
      "description": "Does the subscription have any relations?       Use this function only to know true/false, and when you have no need for the    List returned by GetSubscriptionRelations."
    },
    {
      "method_name": "GetSubscriptionRelations",
      "file_path": "backend/catalog/pg_subscription.c",
      "line_number": 525,
      "comment": "/*\n * Get the relations for the subscription.\n *\n * If not_ready is true, return only the relations that are not in a ready\n * state, otherwise return all the relations of the subscription.  The\n * returned list is palloc'ed in the current memory context.\n */",
      "description": "Get the relations for the subscription."
    },
    {
      "method_name": "asyncQueueAddEntries",
      "file_path": "backend/commands/async.c",
      "line_number": 1355,
      "comment": "/*\n * Add pending notifications to the queue.\n *\n * We go page by page here, i.e. we stop once we have to go to a new page but\n * we will be called again and then fill that next page. If an entry does not\n * fit into the current page, we write a dummy entry with an InvalidOid as the\n * database OID in order to fill the page. So every page is always used up to\n * the last byte which simplifies reading the page later.\n *\n * We are passed the list cell (in pendingNotifies->events) containing the next\n * notification to write and return the first still-unwritten cell back.\n * Eventually we will return NULL indicating all is done.\n *\n * We are holding NotifyQueueLock already from the caller and grab\n * page specific SLRU bank lock locally in this function.\n */",
      "description": "Add pending notifications to the queue."
    },
    {
      "method_name": "pg_notification_queue_usage",
      "file_path": "backend/commands/async.c",
      "line_number": 1480,
      "comment": "/*\n * SQL function to return the fraction of the notification queue currently\n * occupied.\n */",
      "description": "SQL function to return the fraction of the notification queue currently    occupied."
    },
    {
      "method_name": "asyncQueueUsage",
      "file_path": "backend/commands/async.c",
      "line_number": 1505,
      "comment": "/*\n * Return the fraction of the queue that is currently occupied.\n *\n * The caller must hold NotifyQueueLock in (at least) shared mode.\n *\n * Note: we measure the distance to the logical tail page, not the physical\n * tail page.  In some sense that's wrong, but the relative position of the\n * physical tail is affected by details such as SLRU segment boundaries,\n * so that a result based on that is unpleasantly unstable.\n */",
      "description": "Return the fraction of the queue that is currently occupied."
    },
    {
      "method_name": "asyncQueueFillWarning",
      "file_path": "backend/commands/async.c",
      "line_number": 1526,
      "comment": "/*\n * Check whether the queue is at least half full, and emit a warning if so.\n *\n * This is unlikely given the size of the queue, but possible.\n * The warnings show up at most once every QUEUE_FULL_WARN_INTERVAL.\n *\n * Caller must hold exclusive NotifyQueueLock.\n */",
      "description": "Check whether the queue is at least half full, and emit a warning if so."
    },
    {
      "method_name": "SignalBackends",
      "file_path": "backend/commands/async.c",
      "line_number": 1580,
      "comment": "/*\n * Send signals to listening backends.\n *\n * Normally we signal only backends in our own database, since only those\n * backends could be interested in notifies we send.  However, if there's\n * notify traffic in our database but no traffic in another database that\n * does have listener(s), those listeners will fall further and further\n * behind.  Waken them anyway if they're far enough behind, so that they'll\n * advance their queue position pointers, allowing the global tail to advance.\n *\n * Since we know the ProcNumber and the Pid the signaling is quite cheap.\n *\n * This is called during CommitTransaction(), so it's important for it\n * to have very low probability of failure.\n */",
      "description": "Send signals to listening backends."
    },
    {
      "method_name": "AtAbort_Notify",
      "file_path": "backend/commands/async.c",
      "line_number": 1670,
      "comment": "/*\n * AtAbort_Notify\n *\n *\tThis is called at transaction abort.\n *\n *\tGets rid of pending actions and outbound notifies that we would have\n *\texecuted if the transaction got committed.\n */",
      "description": "AtAbort_Notify      \tThis is called at transaction abort.      \tGets rid of pending actions and outbound notifies that we would have   \texecuted if the transaction got committed."
    },
    {
      "method_name": "AtSubCommit_Notify",
      "file_path": "backend/commands/async.c",
      "line_number": 1690,
      "comment": "/*\n * AtSubCommit_Notify() --- Take care of subtransaction commit.\n *\n * Reassign all items in the pending lists to the parent transaction.\n */",
      "description": "AtSubCommit_Notify() --- Take care of subtransaction commit.       Reassign all items in the pending lists to the parent transaction."
    },
    {
      "method_name": "AtSubAbort_Notify",
      "file_path": "backend/commands/async.c",
      "line_number": 1760,
      "comment": "/*\n * AtSubAbort_Notify() --- Take care of subtransaction abort.\n */",
      "description": "AtSubAbort_Notify() --- Take care of subtransaction abort."
    },
    {
      "method_name": "HandleNotifyInterrupt",
      "file_path": "backend/commands/async.c",
      "line_number": 1803,
      "comment": "/*\n * HandleNotifyInterrupt\n *\n *\t\tSignal handler portion of interrupt handling. Let the backend know\n *\t\tthat there's a pending notify interrupt. If we're currently reading\n *\t\tfrom the client, this will interrupt the read and\n *\t\tProcessClientReadInterrupt() will call ProcessNotifyInterrupt().\n */",
      "description": "HandleNotifyInterrupt      \t\tSignal handler portion of interrupt handling."
    },
    {
      "method_name": "CopySendInt16",
      "file_path": "backend/commands/copyto.c",
      "line_number": 276,
      "comment": "/*\n * CopySendInt16 sends an int16 in network byte order\n */",
      "description": "CopySendInt16 sends an int16 in network byte order"
    },
    {
      "method_name": "ClosePipeToProgram",
      "file_path": "backend/commands/copyto.c",
      "line_number": 288,
      "comment": "/*\n * Closes the pipe to an external program, checking the pclose() return code.\n */",
      "description": "Closes the pipe to an external program, checking the pclose() return code."
    },
    {
      "method_name": "EndCopy",
      "file_path": "backend/commands/copyto.c",
      "line_number": 313,
      "comment": "/*\n * Release resources allocated in a cstate for COPY TO/FROM.\n */",
      "description": "Release resources allocated in a cstate for COPY TO/FROM."
    },
    {
      "method_name": "BeginCopyTo",
      "file_path": "backend/commands/copyto.c",
      "line_number": 349,
      "comment": "/*\n * Setup CopyToState to read tuples from a table or a query for COPY TO.\n *\n * 'rel': Relation to be copied\n * 'raw_query': Query whose results are to be copied\n * 'queryRelId': OID of base relation to convert to a query (for RLS)\n * 'filename': Name of server-local file to write, NULL for STDOUT\n * 'is_program': true if 'filename' is program to execute\n * 'data_dest_cb': Callback that processes the output data\n * 'attnamelist': List of char *, columns to include. NIL selects all cols.\n * 'options': List of DefElem. See copy_opt_item in gram.y for selections.\n *\n * Returns a CopyToState, to be passed to DoCopyTo() and related functions.\n */",
      "description": "Setup CopyToState to read tuples from a table or a query for COPY TO."
    },
    {
      "method_name": "EndCopyTo",
      "file_path": "backend/commands/copyto.c",
      "line_number": 725,
      "comment": "/*\n * Clean up storage and release resources for COPY TO.\n */",
      "description": "Clean up storage and release resources for COPY TO."
    },
    {
      "method_name": "DoCopyTo",
      "file_path": "backend/commands/copyto.c",
      "line_number": 746,
      "comment": "/*\n * Copy from relation or query TO file.\n *\n * Returns the number of rows processed.\n */",
      "description": "Copy from relation or query TO file.       Returns the number of rows processed."
    },
    {
      "method_name": "CopyOneRowTo",
      "file_path": "backend/commands/copyto.c",
      "line_number": 906,
      "comment": "/*\n * Emit one row during DoCopyTo().\n */",
      "description": "Emit one row during DoCopyTo()."
    },
    {
      "method_name": "CopyAttributeOutText",
      "file_path": "backend/commands/copyto.c",
      "line_number": 986,
      "comment": "/*\n * Send text representation of one attribute, with conversion and escaping\n */",
      "description": "Send text representation of one attribute, with conversion and escaping"
    },
    {
      "method_name": "CopyAttributeOutCSV",
      "file_path": "backend/commands/copyto.c",
      "line_number": 1139,
      "comment": "/*\n * Send text representation of one attribute, with conversion and\n * CSV-style escaping\n */",
      "description": "Send text representation of one attribute, with conversion and    CSV-style escaping"
    },
    {
      "method_name": "copy_dest_startup",
      "file_path": "backend/commands/copyto.c",
      "line_number": 1225,
      "comment": "/*\n * copy_dest_startup --- executor startup\n */",
      "description": "copy_dest_startup --- executor startup"
    },
    {
      "method_name": "copy_dest_receive",
      "file_path": "backend/commands/copyto.c",
      "line_number": 1234,
      "comment": "/*\n * copy_dest_receive --- receive one tuple\n */",
      "description": "copy_dest_receive --- receive one tuple"
    },
    {
      "method_name": "copy_dest_shutdown",
      "file_path": "backend/commands/copyto.c",
      "line_number": 1253,
      "comment": "/*\n * copy_dest_shutdown --- executor end\n */",
      "description": "copy_dest_shutdown --- executor end"
    },
    {
      "method_name": "copy_dest_destroy",
      "file_path": "backend/commands/copyto.c",
      "line_number": 1262,
      "comment": "/*\n * copy_dest_destroy --- release DestReceiver object\n */",
      "description": "copy_dest_destroy --- release DestReceiver object"
    },
    {
      "method_name": "CreateCopyDestReceiver",
      "file_path": "backend/commands/copyto.c",
      "line_number": 1271,
      "comment": "/*\n * CreateCopyDestReceiver -- create a suitable DestReceiver object\n */",
      "description": "CreateCopyDestReceiver -- create a suitable DestReceiver object"
    },
    {
      "method_name": "create_ctas_internal",
      "file_path": "backend/commands/createas.c",
      "line_number": 79,
      "comment": "/*\n * create_ctas_internal\n *\n * Internal utility used for the creation of the definition of a relation\n * created via CREATE TABLE AS or a materialized view.  Caller needs to\n * provide a list of attributes (ColumnDef nodes).\n */",
      "description": "create_ctas_internal       Internal utility used for the creation of the definition of a relation    created via CREATE TABLE AS or a materialized view."
    },
    {
      "method_name": "create_ctas_nodata",
      "file_path": "backend/commands/createas.c",
      "line_number": 152,
      "comment": "/*\n * create_ctas_nodata\n *\n * Create CTAS or materialized view when WITH NO DATA is used, starting from\n * the targetlist of the SELECT or view definition.\n */",
      "description": "create_ctas_nodata       Create CTAS or materialized view when WITH NO DATA is used, starting from    the targetlist of the SELECT or view definition."
    },
    {
      "method_name": "ExecCreateTableAs",
      "file_path": "backend/commands/createas.c",
      "line_number": 220,
      "comment": "/*\n * ExecCreateTableAs -- execute a CREATE TABLE AS command\n */",
      "description": "ExecCreateTableAs -- execute a CREATE TABLE AS command"
    },
    {
      "method_name": "GetIntoRelEFlags",
      "file_path": "backend/commands/createas.c",
      "line_number": 367,
      "comment": "/*\n * GetIntoRelEFlags --- compute executor flags needed for CREATE TABLE AS\n *\n * This is exported because EXPLAIN and PREPARE need it too.  (Note: those\n * callers still need to deal explicitly with the skipData flag; since they\n * use different methods for suppressing execution, it doesn't seem worth\n * trying to encapsulate that part.)\n */",
      "description": "GetIntoRelEFlags --- compute executor flags needed for CREATE TABLE AS       This is exported because EXPLAIN and PREPARE need it too."
    },
    {
      "method_name": "CreateTableAsRelExists",
      "file_path": "backend/commands/createas.c",
      "line_number": 385,
      "comment": "/*\n * CreateTableAsRelExists --- check existence of relation for CreateTableAsStmt\n *\n * Utility wrapper checking if the relation pending for creation in this\n * CreateTableAsStmt query already exists or not.  Returns true if the\n * relation exists, otherwise false.\n */",
      "description": "CreateTableAsRelExists --- check existence of relation for CreateTableAsStmt       Utility wrapper checking if the relation pending for creation in this    CreateTableAsStmt query already exists or not."
    },
    {
      "method_name": "CreateIntoRelDestReceiver",
      "file_path": "backend/commands/createas.c",
      "line_number": 432,
      "comment": "/*\n * CreateIntoRelDestReceiver -- create a suitable DestReceiver object\n *\n * intoClause will be NULL if called from CreateDestReceiver(), in which\n * case it has to be provided later.  However, it is convenient to allow\n * self->into to be filled in immediately for other callers.\n */",
      "description": "CreateIntoRelDestReceiver -- create a suitable DestReceiver object       intoClause will be NULL if called from CreateDestReceiver(), in which    case it has to be provided later."
    },
    {
      "method_name": "intorel_startup",
      "file_path": "backend/commands/createas.c",
      "line_number": 451,
      "comment": "/*\n * intorel_startup --- executor startup\n */",
      "description": "intorel_startup --- executor startup"
    },
    {
      "method_name": "intorel_receive",
      "file_path": "backend/commands/createas.c",
      "line_number": 575,
      "comment": "/*\n * intorel_receive --- receive one tuple\n */",
      "description": "intorel_receive --- receive one tuple"
    },
    {
      "method_name": "intorel_shutdown",
      "file_path": "backend/commands/createas.c",
      "line_number": 606,
      "comment": "/*\n * intorel_shutdown --- executor end\n */",
      "description": "intorel_shutdown --- executor end"
    },
    {
      "method_name": "intorel_destroy",
      "file_path": "backend/commands/createas.c",
      "line_number": 626,
      "comment": "/*\n * intorel_destroy --- release DestReceiver object\n */",
      "description": "intorel_destroy --- release DestReceiver object"
    },
    {
      "method_name": "CreateDatabaseUsingWalLog",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 147,
      "comment": "/*\n * Create a new database using the WAL_LOG strategy.\n *\n * Each copied block is separately written to the write-ahead log.\n */",
      "description": "Create a new database using the WAL_LOG strategy.       Each copied block is separately written to the write-ahead log."
    },
    {
      "method_name": "ScanSourceDatabasePgClass",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 249,
      "comment": "/*\n * Scan the pg_class table in the source database to identify the relations\n * that need to be copied to the destination database.\n *\n * This is an exception to the usual rule that cross-database access is\n * not possible. We can make it work here because we know that there are no\n * connections to the source database and (since there can't be prepared\n * transactions touching that database) no in-doubt tuples either. This\n * means that we don't need to worry about pruning removing anything from\n * under us, and we don't need to be too picky about our snapshot either.\n * As long as it sees all previously-committed XIDs as committed and all\n * aborted XIDs as aborted, we should be fine: nothing else is possible\n * here.\n *\n * We can't rely on the relcache for anything here, because that only knows\n * about the database to which we are connected, and can't handle access to\n * other databases. That also means we can't rely on the heap scan\n * infrastructure, which would be a bad idea anyway since it might try\n * to do things like HOT pruning which we definitely can't do safely in\n * a database to which we're not even connected.\n */",
      "description": "Scan the pg_class table in the source database to identify the relations    that need to be copied to the destination database."
    },
    {
      "method_name": "ScanSourceDatabasePgClassPage",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 327,
      "comment": "/*\n * Scan one page of the source database's pg_class relation and add relevant\n * entries to rlocatorlist. The return value is the updated list.\n */",
      "description": "Scan one page of the source database's pg_class relation and add relevant    entries to rlocatorlist. The return value is the updated list."
    },
    {
      "method_name": "ScanSourceDatabasePgClassTuple",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 390,
      "comment": "/*\n * Decide whether a certain pg_class tuple represents something that\n * needs to be copied from the source database to the destination database,\n * and if so, construct a CreateDBRelInfo for it.\n *\n * Visibility checks are handled by the caller, so our job here is just\n * to assess the data stored in the tuple.\n */",
      "description": "Decide whether a certain pg_class tuple represents something that    needs to be copied from the source database to the destination database,    and if so, construct a CreateDBRelInfo for it."
    },
    {
      "method_name": "CreateDirAndVersionFile",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 455,
      "comment": "/*\n * Create database directory and write out the PG_VERSION file in the database\n * path.  If isRedo is true, it's okay for the database directory to exist\n * already.\n */",
      "description": "Create database directory and write out the PG_VERSION file in the database    path.  If isRedo is true, it's okay for the database directory to exist    already."
    },
    {
      "method_name": "CreateDatabaseUsingFileCopy",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 549,
      "comment": "/*\n * Create a new database using the FILE_COPY strategy.\n *\n * Copy each tablespace at the filesystem level, and log a single WAL record\n * for each tablespace copied.  This requires a checkpoint before and after the\n * copy, which may be expensive, but it does greatly reduce WAL generation\n * if the copied database is large.\n */",
      "description": "Create a new database using the FILE_COPY strategy."
    },
    {
      "method_name": "createdb",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 669,
      "comment": "/*\n * CREATE DATABASE\n */",
      "description": "CREATE DATABASE"
    },
    {
      "method_name": "check_encoding_locale_matches",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 1556,
      "comment": "/*\n * Check whether chosen encoding matches chosen locale settings.  This\n * restriction is necessary because libc's locale-specific code usually\n * fails when presented with data in an encoding it's not expecting. We\n * allow mismatch in four cases:\n *\n * 1. locale encoding = SQL_ASCII, which means that the locale is C/POSIX\n * which works with any encoding.\n *\n * 2. locale encoding = -1, which means that we couldn't determine the\n * locale's encoding and have to trust the user to get it right.\n *\n * 3. selected encoding is UTF8 and platform is win32. This is because\n * UTF8 is a pseudo codepage that is supported in all locales since it's\n * converted to UTF16 before being used.\n *\n * 4. selected encoding is SQL_ASCII, but only if you're a superuser. This\n * is risky but we have historically allowed it --- notably, the\n * regression tests require it.\n *\n * Note: if you change this policy, fix initdb to match.\n */",
      "description": "Check whether chosen encoding matches chosen locale settings."
    },
    {
      "method_name": "createdb_failure_callback",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 1594,
      "comment": "/* Error cleanup callback for createdb */",
      "description": "Error cleanup callback for createdb"
    },
    {
      "method_name": "dropdb",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 1633,
      "comment": "/*\n * DROP DATABASE\n */",
      "description": "DROP DATABASE"
    },
    {
      "method_name": "RenameDatabase",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 1862,
      "comment": "/*\n * Rename database\n */",
      "description": "Rename database"
    },
    {
      "method_name": "movedb",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 1963,
      "comment": "/*\n * ALTER DATABASE SET TABLESPACE\n */",
      "description": "ALTER DATABASE SET TABLESPACE"
    },
    {
      "method_name": "movedb_failure_callback",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 2285,
      "comment": "/* Error cleanup callback for movedb */",
      "description": "Error cleanup callback for movedb"
    },
    {
      "method_name": "DropDatabase",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 2302,
      "comment": "/*\n * Process options and call dropdb function.\n */",
      "description": "Process options and call dropdb function."
    },
    {
      "method_name": "AlterDatabase",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 2327,
      "comment": "/*\n * ALTER DATABASE name ...\n */",
      "description": "ALTER DATABASE name ..."
    },
    {
      "method_name": "AlterDatabaseRefreshColl",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 2500,
      "comment": "/*\n * ALTER DATABASE name REFRESH COLLATION VERSION\n */",
      "description": "ALTER DATABASE name REFRESH COLLATION VERSION"
    },
    {
      "method_name": "AlterDatabaseSet",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 2597,
      "comment": "/*\n * ALTER DATABASE name SET ...\n */",
      "description": "ALTER DATABASE name SET ..."
    },
    {
      "method_name": "AlterDatabaseOwner",
      "file_path": "backend/commands/dbcommands.c",
      "line_number": 2623,
      "comment": "/*\n * ALTER DATABASE name OWNER TO newowner\n */",
      "description": "ALTER DATABASE name OWNER TO newowner"
    },
    {
      "method_name": "EventTriggerInhibitCommandCollection",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1553,
      "comment": "/*\n * Inhibit DDL command collection.\n */",
      "description": "Inhibit DDL command collection."
    },
    {
      "method_name": "EventTriggerUndoInhibitCommandCollection",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1565,
      "comment": "/*\n * Re-establish DDL command collection.\n */",
      "description": "Re-establish DDL command collection."
    },
    {
      "method_name": "EventTriggerCollectSimpleCommand",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1587,
      "comment": "/*\n * EventTriggerCollectSimpleCommand\n *\t\tSave data about a simple DDL command that was just executed\n *\n * address identifies the object being operated on.  secondaryObject is an\n * object address that was related in some way to the executed command; its\n * meaning is command-specific.\n *\n * For instance, for an ALTER obj SET SCHEMA command, objtype is the type of\n * object being moved, objectId is its OID, and secondaryOid is the OID of the\n * old schema.  (The destination schema OID can be obtained by catalog lookup\n * of the object.)\n */",
      "description": "EventTriggerCollectSimpleCommand   \t\tSave data about a simple DDL command that was just executed       address identifies the object being operated on."
    },
    {
      "method_name": "EventTriggerAlterTableStart",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1625,
      "comment": "/*\n * EventTriggerAlterTableStart\n *\t\tPrepare to receive data on an ALTER TABLE command about to be executed\n *\n * Note we don't collect the command immediately; instead we keep it in\n * currentCommand, and only when we're done processing the subcommands we will\n * add it to the command list.\n */",
      "description": "EventTriggerAlterTableStart   \t\tPrepare to receive data on an ALTER TABLE command about to be executed       Note we don't collect the command immediately; instead we keep it in    currentCommand, and only when we're done processing the subcommands we will    add it to the command list.."
    },
    {
      "method_name": "EventTriggerAlterTableRelid",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1659,
      "comment": "/*\n * Remember the OID of the object being affected by an ALTER TABLE.\n *\n * This is needed because in some cases we don't know the OID until later.\n */",
      "description": "Remember the OID of the object being affected by an ALTER TABLE.       This is needed because in some cases we don't know the OID until later."
    },
    {
      "method_name": "EventTriggerCollectAlterTableSubcmd",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1677,
      "comment": "/*\n * EventTriggerCollectAlterTableSubcmd\n *\t\tSave data about a single part of an ALTER TABLE.\n *\n * Several different commands go through this path, but apart from ALTER TABLE\n * itself, they are all concerned with AlterTableCmd nodes that are generated\n * internally, so that's all that this code needs to handle at the moment.\n */",
      "description": "EventTriggerCollectAlterTableSubcmd   \t\tSave data about a single part of an ALTER TABLE."
    },
    {
      "method_name": "EventTriggerAlterTableEnd",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1712,
      "comment": "/*\n * EventTriggerAlterTableEnd\n *\t\tFinish up saving an ALTER TABLE command, and add it to command list.\n *\n * FIXME this API isn't considering the possibility that an xact/subxact is\n * aborted partway through.  Probably it's best to add an\n * AtEOSubXact_EventTriggers() to fix this.\n */",
      "description": "EventTriggerAlterTableEnd   \t\tFinish up saving an ALTER TABLE command, and add it to command list."
    },
    {
      "method_name": "EventTriggerCollectGrant",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1750,
      "comment": "/*\n * EventTriggerCollectGrant\n *\t\tSave data about a GRANT/REVOKE command being executed\n *\n * This function creates a copy of the InternalGrant, as the original might\n * not have the right lifetime.\n */",
      "description": "EventTriggerCollectGrant   \t\tSave data about a GRANT/REVOKE command being executed       This function creates a copy of the InternalGrant, as the original might    not have the right lifetime."
    },
    {
      "method_name": "EventTriggerCollectAlterOpFam",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1794,
      "comment": "/*\n * EventTriggerCollectAlterOpFam\n *\t\tSave data about an ALTER OPERATOR FAMILY ADD/DROP command being\n *\t\texecuted\n */",
      "description": "EventTriggerCollectAlterOpFam   \t\tSave data about an ALTER OPERATOR FAMILY ADD/DROP command being   \t\texecuted"
    },
    {
      "method_name": "EventTriggerCollectCreateOpClass",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1827,
      "comment": "/*\n * EventTriggerCollectCreateOpClass\n *\t\tSave data about a CREATE OPERATOR CLASS command being executed\n */",
      "description": "EventTriggerCollectCreateOpClass   \t\tSave data about a CREATE OPERATOR CLASS command being executed"
    },
    {
      "method_name": "EventTriggerCollectAlterTSConfig",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1861,
      "comment": "/*\n * EventTriggerCollectAlterTSConfig\n *\t\tSave data about an ALTER TEXT SEARCH CONFIGURATION command being\n *\t\texecuted\n */",
      "description": "EventTriggerCollectAlterTSConfig   \t\tSave data about an ALTER TEXT SEARCH CONFIGURATION command being   \t\texecuted"
    },
    {
      "method_name": "EventTriggerCollectAlterDefPrivs",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1896,
      "comment": "/*\n * EventTriggerCollectAlterDefPrivs\n *\t\tSave data about an ALTER DEFAULT PRIVILEGES command being\n *\t\texecuted\n */",
      "description": "EventTriggerCollectAlterDefPrivs   \t\tSave data about an ALTER DEFAULT PRIVILEGES command being   \t\texecuted"
    },
    {
      "method_name": "pg_event_trigger_ddl_commands",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 1924,
      "comment": "/*\n * In a ddl_command_end event trigger, this function reports the DDL commands\n * being run.\n */",
      "description": "In a ddl_command_end event trigger, this function reports the DDL commands    being run."
    },
    {
      "method_name": "stringify_grant_objtype",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 2120,
      "comment": "/*\n * Return the ObjectType as a string, as it would appear in GRANT and\n * REVOKE commands.\n */",
      "description": "Return the ObjectType as a string, as it would appear in GRANT and    REVOKE commands."
    },
    {
      "method_name": "stringify_adefprivs_objtype",
      "file_path": "backend/commands/event_trigger.c",
      "line_number": 2205,
      "comment": "/*\n * Return the ObjectType as a string; as above, but use the spelling\n * in ALTER DEFAULT PRIVILEGES commands instead.  Generally this is just\n * the plural.\n */",
      "description": "Return the ObjectType as a string; as above, but use the spelling    in ALTER DEFAULT PRIVILEGES commands instead.  Generally this is just    the plural."
    },
    {
      "method_name": "ExplainQuery",
      "file_path": "backend/commands/explain.c",
      "line_number": 182,
      "comment": "/*\n * ExplainQuery -\n *\t  execute an EXPLAIN command\n */",
      "description": "ExplainQuery -   \t  execute an EXPLAIN command"
    },
    {
      "method_name": "NewExplainState",
      "file_path": "backend/commands/explain.c",
      "line_number": 371,
      "comment": "/*\n * Create a new ExplainState struct initialized with default options.\n */",
      "description": "Create a new ExplainState struct initialized with default options."
    },
    {
      "method_name": "ExplainResultDesc",
      "file_path": "backend/commands/explain.c",
      "line_number": 388,
      "comment": "/*\n * ExplainResultDesc -\n *\t  construct the result tupledesc for an EXPLAIN\n */",
      "description": "ExplainResultDesc -   \t  construct the result tupledesc for an EXPLAIN"
    }
  ],
  "stats": {
    "total_method_docs": 638,
    "total_documentation_entries": 638,
    "batches_processed": 33,
    "final_offset": 3300
  }
}